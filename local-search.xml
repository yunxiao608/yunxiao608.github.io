<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>5月上旬问题汇总</title>
    <link href="/2022/05/16/tip-2022-5-16/"/>
    <url>/2022/05/16/tip-2022-5-16/</url>
    
    <content type="html"><![CDATA[<p>1：</p><p>5月上旬问题列表</p><p>附带：</p><p>tensorflow-gpu清华源离线<a href="https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow-gpu/">下载地址</a></p><p>pytorch和torchvision离线<a href="http://download.pytorch.org/whl/torch_stable.html">下载地址</a></p><hr><p>1：</p><ul><li><p>描述：关于<code>OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized</code></p></li><li><p>原因：主要是因为torch包中包含了名为<strong>libiomp5md.dll</strong>的文件，与Anaconda环境中的同一个文件出现了某种冲突，所以需要删除一个。</p></li><li><p>解决方案：删除<code>Anaconda/Library/bin</code>下的<strong>libiomp5md.dll</strong>文件</p></li></ul><p>2：</p><ul><li><p>描述：出现<code>Could not load dynamic library ‘cudart64_110.dll‘； dlerror: cudart64_110.dll not found</code></p></li><li><p>原因：tensorflow版本较高，dll文件缺失导致。</p></li><li><p>解决方案：在<a href="https://cn.dll-files.com/%E7%BD%91%E7%AB%99%E4%B8%8A%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E5%8D%B3%E5%8F%AF%E3%80%82%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%EF%BC%8C%E5%88%99%E8%A6%81%E8%80%83%E8%99%91%E9%99%8D%E4%BD%8Etensorflow%E7%9A%84%E7%89%88%E6%9C%AC%E3%80%82%E6%9C%AC%E6%9C%BA%E7%9A%84cuda%E7%89%88%E6%9C%AC%E6%98%AF**11.2**%EF%BC%8C%E9%80%82%E5%90%88%E7%9A%84tensorflow%E6%98%AF2.6%E5%92%8C2.5%EF%BC%8C%E4%B9%8B%E5%89%8D%E8%A3%85%E7%9A%84%E6%98%AF2.7%EF%BC%8C%E7%89%88%E6%9C%AC%E8%BF%87%E9%AB%98%E3%80%82cuda%E7%89%88%E6%9C%AC%E4%B8%8Etensorflow%E7%9A%84%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB%E5%8F%82%E8%A7%81[TensorFlow%E5%AE%98%E7%BD%91](https://www.tensorflow.org/install/source_windows)%E3%80%82">https://cn.dll-files.com/网站上直接下载即可。如果没有，则要考虑降低tensorflow的版本。本机的cuda版本是**11.2**，适合的tensorflow是2.6和2.5，之前装的是2.7，版本过高。cuda版本与tensorflow的版本对应关系参见[TensorFlow官网](https://www.tensorflow.org/install/source_windows)。</a></p></li></ul><p>3：</p><ul><li><p>描述：采用自制数据集训练Yolov5项目时出现警告<code>non-normalized or out of bounds coordinate labels</code></p></li><li><p>原因：yolo标注txt文件里面的后四个参数即目标中心点的坐标（x ，y， w， h）存在大于1的情况，训练时会自动忽略警告图片。</p></li><li><p>解决方案：对四个参数进行0到1之间的归一化，满足：<code>assert (l[:, 1:] ＜= 1).all()</code></p></li></ul><pre><code class=" mermaid">gantttitle 甘特图dateFormat  YYYY-MM-DDsection 项目A任务1           :a1, 2018-06-06, 30d任务2     :after a1  , 20dsection 项目B任务3      :2018-06-12  , 12d任务4      : 24d</code></pre>]]></content>
    
    
    <categories>
      
      <category>目标识别</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>YoloV5</tag>
      
      <tag>tensorboard</tag>
      
      <tag>tensorflow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>锦城故事-第一章-飞临</title>
    <link href="/2021/10/20/jincheng-gushi-chap1/"/>
    <url>/2021/10/20/jincheng-gushi-chap1/</url>
    
    <content type="html"><![CDATA[<h1 id="锦城故事"><a href="#锦城故事" class="headerlink" title="锦城故事"></a>锦城故事</h1><h3 id="第一章：飞临"><a href="#第一章：飞临" class="headerlink" title="第一章：飞临"></a>第一章：飞临</h3><p>因为疫情原因，我们迟迟才返回学校，五天的时间弄好所有毕业手续，整理好行李寄回家，这可真是一件件费神费脑的事儿。打算买火车票的时候，发现600多的动车票已经售罄，高铁票还得贵上二百，何不第一次尝试做飞机？然而，我既想坐飞机又畏惧坐飞机，内心很矛盾，想的原因是我身边大部分亲朋好友都没做过飞机，我是第一个，这样我会嘚瑟一些。不得不说，研二下才做过高铁，第一次做高铁还慌张得不行。不想的原因是害怕，觉得做飞机手续复杂，怕什么东西丢掉。<strong>哎，我这个人啊，真是杞人忧天，患得患失，嗟乎！</strong>最终，我还是订了一张600多的飞机多，从上海浦东国际机场出发，大约是晚上8点半左右起飞，11点15分降落成都双流机场。</p><p>拿到双证，办完离校手续，回到家，只有三天的时间就要去上海了。还记得去上海的前一天，父亲知道我此行之不易，傍晚还带我去街上买熟食。自小成长于普通家庭的我，习惯了平平淡淡的食物，再加上想减肥，对于熟食啥的不是那么上心。</p><p>回到家后，大舅打来电话，说外婆让我和爸妈去她家吃晚饭。而我还有许多东西没有收拾好，虽然舅舅他们一再坚持，我还是拒绝了，后来想起来有点惭愧，毕竟，外婆他们也是一片好心啊！那天晚上，早早且草草地吃完饭，我一遍又一遍地检查所带的东西，是否有遗漏。晚上的月亮格外地皎洁圆满，还没去成都，我就有点思家了。我打开喜马拉雅FM，听着温柔的男声，想着去遥远的成都我会遇到哪些人，经历哪些事儿，久久才入眠。</p><p>第二天，辞别了亲人，赶早从镇上做大巴去上海汽车站。大巴在路上足足走了大半个上午，经苏通大桥，常熟，太仓，嘉定，最后到达上海汽车总站。马不停蹄地做地铁去浦东机场，期间我还做错了列车。因为上海地铁和苏州地铁不一样，一条铁轨可能两班不同的列车前后行驶。上海真是精致城市，地铁上的年轻人穿得精致简约，落落大方，一点不花里胡哨。到了浦东机场的时候，大概是上午10点钟，我知道来早了。但是赶早不敢晚，我习惯做个笨人，用笨方法，像曾文正公<strong>结硬寨，打呆仗</strong>一样，这样稳妥，心安理得。</p><p>在机场是无聊的，就这样站来走去，用手里的老式Kindle打发时间。期间有个男人想借我手机打电话，一开始我装作没听到，毕竟一个人在外要学会提高警惕。他再次出声的时候，我说我来帮他拨号，拨完他接后电话那头没反应，他说了声谢谢扬长而去。</p><p>下午五点钟，我意识到可以进去检票了，排长队办好大行李托运，拿到机票，再到安检处检查手提小行李，就去了登机口，去登机口是做机场地铁线去的。到了登机口，还是坐在位置上无聊地等待。本来8点半起飞的飞机还晚点了半个小时，大概是快九点才起飞。登机后，长队熙熙攘攘，这是我第一次坐飞机，一切都显得十分神奇。空姐也化了浓妆，看起来像四川女子，身材细小苗条，声音带点清脆和尖。飞机起飞的时候，噪音很大，升空的时候更是心提到了嗓子眼。我的座位靠玻璃窗，随着飞机的缓缓升空，地下的那些灯光璀璨逐渐渺小，直到成为一颗颗小点点。飞机到了正空后，受气流影响，忽左忽右地颠簸摆动，搞得我一次次绷紧神经。</p><p><img src="/images/chengdu/QQ%E5%9B%BE%E7%89%8720211020205013.jpg"></p><p>​                ▲ 我的登机口</p><p>期间，空乘人员发了餐食，虽然觉得不怎么好吃，但四川航空的服务比我后来回南通的东海航空明显质量好些。还有半个小时就到达成都双流国际机场，飞机的广播里发出提示。到飞机缓缓下降的时候，我才知道这次飞行飞了上千公里，想想南宋时期四川制置使范成大从蜀地回吴县，坐船乘江顺流而下，走走停停花了五个多月。</p><p><img src="/images/chengdu/QQ%E5%9B%BE%E7%89%8720211020204615.jpg"></p><p>​                ▲ 入住双流机场附近的旅馆</p><p>落地后，广播里放起赵雷那首熟悉的《成都》，据说，成都慢悠悠又极具人情味儿和生活气息的感觉，让赵雷特别喜欢这座城市，成都因此成为赵雷热爱的第二故乡。出于想表达对成都的记录和留恋，赵雷创作了该曲送给成都的情歌。伴随着广播里介绍成都的人文历史，一边介绍一边轻乐飞扬，在夏夜的静谧下显得格外舒服可人：</p><blockquote><p>让我掉下眼泪的</p><p>不止昨夜的酒</p><p>让我依依不舍的</p><p>不止你的温柔</p><p>余路还要走多久</p><p>你攥着我的手</p><p>让我感到为难的</p><p>是挣扎的自由</p><p>分别总是在九月</p><p>回忆是思念的愁</p><p>深秋嫩绿的垂柳</p><p>亲吻着我额头</p><p>在那座阴雨的小城里</p><p>我从未忘记你</p><p>成都带不走的只有你</p><p>和我在成都的街头走一走</p><p>直到所有的灯都熄灭了也不停留</p><p>你会挽着我的衣袖</p><p>我会把手揣进裤兜</p><p>走到玉林路的尽头</p><p>坐在小酒馆的门口</p><p>分别总是在九月</p><p>回忆是思念的愁</p><p>深秋嫩绿的垂柳</p><p>亲吻着我额头</p><p>在那座阴雨的小城里</p><p>我从未忘记你</p><p>成都带不走的只有你</p><p>和我在成都的街头走一走</p><p>直到所有的灯都熄灭了也不停留</p><p>你会挽着我的衣袖</p><p>我会把手揣进裤兜</p><p>走到玉林路的尽头</p><p>坐在小酒馆的门口</p><p>和我在成都的街头走一走</p><p>直到所有的灯都熄灭了也不停留</p><p>和我在成都的街头走一走</p><p>直到所有的灯都熄灭了也不停留</p><p>你会挽着我的衣袖</p><p>我会把手揣进裤兜</p><p>走到玉林路的尽头</p><p>走过小酒馆的门口</p></blockquote><p>我在想，哪一天我彻底离开成都，这首音乐会不会听起来很伤感，想罢不禁泪沾襟。</p><p>成都，我来了！</p><p>本章<strong>1911</strong>字，欲知后事，且听下回叙述。</p>]]></content>
    
    
    <categories>
      
      <category>成都</category>
      
    </categories>
    
    
    <tags>
      
      <tag>游记</tag>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅淡地理环境对地域发展的影响</title>
    <link href="/2021/10/16/dili-huanjing-yingxiang/"/>
    <url>/2021/10/16/dili-huanjing-yingxiang/</url>
    
    <content type="html"><![CDATA[<h3 id="浅淡地理环境对地域发展的影响"><a href="#浅淡地理环境对地域发展的影响" class="headerlink" title="浅淡地理环境对地域发展的影响"></a>浅淡地理环境对地域发展的影响</h3><p>​        中国古代，东边和南边是大海，北边是蒙古高原和西伯利亚，西北是戈壁，西南是青藏高原和喜马拉雅山。过去，中原王朝的主要军事精力都放在北边的游牧民族和渔猎民族上，例如匈奴、鲜卑、羌、契丹、党项、女真、渤海等等。而在王朝内部，世代的农耕生活一直在祖祖辈辈，世世代代地传承下去，这些因素的千年积累形成了华夏民族的保守性格，这一点和希腊的海洋文明截然不同。中国古代有“<strong>君要臣死，臣不得不死；父要子亡，子不得不亡</strong>”的论句，而希腊文明则出现了<strong>弑父</strong>的文化，体现在敢于向上级和神教权力挑战。</p><h4 id="天府之国"><a href="#天府之国" class="headerlink" title="天府之国"></a>天府之国</h4><p>​        但其实，在中国内部，由于各个地区的地理环境不同，发展也各有差异。我们知道，四川常被称为天府之国，但其实严格来说应该是成都平原，也称<strong>川西坝子</strong>，包括成都市各区县及周围几个地市的部分区域，总面积不过1.881万平方公里，占全省面积48万平方公里的比例极小。但成都平原历来是王朝的主要纳税和进贡的地区，不管是汉朝的<strong>五都</strong>和<strong>织锦</strong>，还是唐朝的“<strong>扬一益二</strong>”，还是宋朝的第二大工商业城市。直至南宋晚期，因蜀地为蒙古鞑靼所占，山河破碎，民生凋敝，临安朝廷的财政收入大打折扣，入不敷出，逐渐濒临破产。</p><p><img src="/images/dili_pic/dufu.jpg"></p><p>​            ▲ 成都文化标志之一，杜甫草堂前的诗圣雕像</p><p>​        除了成都平原，川内的其他地市皆多山，尤其是位于今广元的剑阁，此入蜀之必经关隘，想当年邓艾大军偷渡阴平，兵贵神速，直捣成都，可见此地之重要性。南宋后期，蒙古游骑首次出现在成都城内时，成都官民还以为是外地商队，可见蜀地承平日久，防守薄弱，不识兵革久矣。 然而，成都平原易于被蒙古军占领，但山地自有其好处，晚宋名臣余阶受理宗皇帝任命，出任四川安抚制置使，他在蜀时期，构筑了后世闻名的<strong>山城防御体系</strong>，筑青居（<em>今四川南充南</em>）、大获（<em>今四川苍溪东南</em>）、钓鱼（<em>今四川合川东</em>）、云顶（<em>今四川金堂南</em>）等十余城，将川内各府衙县所搬迁到易守难攻的山城。后来著名的<strong>钓鱼城保卫战</strong>就得益于这种防御体系。蒙古骑兵纵横欧亚大陆，所向披靡，无所顾忌，但在四川却鏖兵近半个世纪，期间还阵亡了一位大汗（蒙哥汗）和王子（阔端，大汗窝阔台的次子）。蜀地的山城体系延缓了南宋荆湖、两淮战场的压力，延续了宋祚数十年，殊为不易。以名将王坚、张珏、王立为代表的蜀地军民更是可歌可泣，让人击节赞叹。</p><p>​        民国时期，山城模式成了川内各个军阀混战割据的地理优势。到了现代，四川省明智地走向了做大做强成都的策略。</p><h4 id="苏湖熟，天下足"><a href="#苏湖熟，天下足" class="headerlink" title="苏湖熟，天下足"></a>苏湖熟，天下足</h4><p>​        再看看江苏，众所周知，苏南是江苏最富庶繁华，文化也最昌盛的地区。这得益于苏南的地理环境优越性。在上古时期，吴地沼泽遍布，水网密集，以至于今天的苏州一带许多地名都叫某某浜，例如常熟的沙家浜和吴中的徐家浜，甚至当今苏州的诸校区也冠以某某湖之名，例如独墅湖校区，阳澄湖校区，石湖校区，东湖校区等等。除了浜和湖以外，苏南还有泾和塘等常见的地名。有了许多湖泊和水库，再加上东边是大海，又靠长江，从古至今，很少听到苏南地区有洪水泛滥的见闻，而且也不像浙南地区多山，有什么山体滑坡，地震等自然灾害。所以农作物能得到很好的生长，虽说河南和湖北（江陵）也是产粮大省，但比之于苏南环境和气候的稳定性，则差矣。南宋时期，更有“<strong>苏湖熟，天下足</strong>”的美谚。也就是说，苏州和湖州（一说常州）的粮食可以通过大运河供应全国。因此，吴地士子能够专心从事生产和读书，耕读之家全国最盛，明清以来苏州府出过的进士位列全国第一。毕竟只有吃饱了肚子，有了稳定的收入才能去追求功名。</p><p><img src="/images/dili_pic/gusufanhua.jpg"></p><p>​            ▲ 《姑苏繁华图》阖门部分，是清代宫廷画家徐扬创作的一幅纸本画作</p><h4 id="骑鹤下扬州"><a href="#骑鹤下扬州" class="headerlink" title="骑鹤下扬州"></a>骑鹤下扬州</h4><p>​        江苏苏中一带，是吴越文化和淮扬文化的交接区，方言也是苏南话和北方官话的融合。苏中的扬州和泰州，在历史上也创造了灿烂的文明，扬州自不必说，天下九州之一，古云“<strong>腰缠十万贯，骑鹤下扬州</strong>”，明清更是靠漕运和盐业冠绝东南。泰州亦有<strong>汉唐故郡</strong>的雅称，著名的<strong>泰州学派</strong>就发源于此，《水浒传》的作者施耐庵便是泰州人。而第三个城市南通，历史渊源比之扬泰较短，隋唐时期，南通市区还是沙洲，史称<strong>胡逗洲</strong>，到后周显德年间才建城。但南通下辖的县级市如皋早年由扬州府管辖，在三国时期就崭露头角，孙吴重臣吕岱便是海陵如皋人。南通在隋唐以降是朝廷著名的盐场（《宋史•宁宗本纪》载：”<em>八月乙亥，罢通州天赐盐场</em>“）。随着近代中国的对外开放，南通凭借毗邻上海的优势迅速崛起，在状元企业家张謇先生的带领下，实现了多个第一，被誉为<strong>近代第一城</strong>。如此看来，苏中文化稍逊苏南一筹，但也是长江两岸的交流中心。另外，泰州的靖江，南通的启东、海门、通州区域语系因为历史原因属于吴越语系。</p><p><img src="/images/dili_pic/yangzhou.jpg"></p><p>​            ▲ 扬州园林代表何园</p><h4 id="九省通衢"><a href="#九省通衢" class="headerlink" title="九省通衢"></a>九省通衢</h4><p>​        至于以徐州为中心的淮海地区，虽隶属江苏，但在民风上更接近北方。徐州古称彭城，号称<strong>九省通衢</strong>，与山东，安徽，河南接壤，自古为兵家必争之地，历史上曾建有淮海省而脱离江苏。比起苏南的细致婉约，苏中的敦厚宽容，苏北的习气更加豪爽。徐州是江苏仅次于南京的第二个帝王之都，出过西楚霸王项羽（宿迁），汉高祖刘邦，宋武帝刘裕，南唐先主李昪。因此，按政治地位排名，徐州是仅次于南京的。</p><hr><p>​        接下来我们把视野放到国际上去。近代以来，相继出现了葡萄牙、西班牙、荷兰、法国、英国、德国、美国、沙俄、日本等强国。</p><p>​        西班牙和葡萄牙虽然开启了大航海时代，但目的却是掠夺殖民地的黄金香料，供上流社会挥霍，因此没有将资本的原始积累充分运用到发展工业技术上来。更重要的原因是，西葡二国远离欧洲的腹地，文化传播和交通不便，与法国也隔着比利牛斯山脉，国土大部分是戈壁，尤其是西班牙，他的地理环境类似于北非地中海气候，所以说难以形成像英德法那样的核心工业区。西国的工业区寥寥无几，只分布在沿海的<strong>巴斯克</strong>和<strong>巴塞罗那</strong>等地，全国大部分人口从事农业，文盲率较高。</p><p><img src="/images/dili_pic/spain.jpg"></p><p>​            ▲ 西班牙地形图</p><p>​        荷兰虽然是资本主义近代强国，出过的文艺科学巨匠远胜西国，但国土面积太小，且国土大部分低于海平面，国内资本市场有限，无法形成大气候。两次大战期间无力守卫疆土，殖民地印尼陷于日人之手，究其原因，还是体量问题。</p><p>​        英国和日本很像，孤悬海外，只需要保持一支强大的海军即可。英国奉行大陆均势的外交策略，联合欧洲大陆的老二干倒老大。但日本非要向陆权国家德俄的模式学习，侵略中国和东南亚甚至印度，最终把自己拖死。这一点上，其战略智慧和格局远不及英国。</p><p>​        最后谈谈美国，美国南北无强敌，东西皆大洋，这为其本国的经济发展提供了有利的便宜，可以两耳不闻国际事，一心谋发展，因此两次世界大战，凭借本国巨大的体量优势和本土没有遭受战争的打击，很快在战后超过英国，一跃成为世界资本主义头号强国。</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>地理</tag>
      
      <tag>历史</tag>
      
      <tag>人文</tag>
      
      <tag>四川</tag>
      
      <tag>苏南</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>echarts使用中的跨域问题</title>
    <link href="/2020/12/11/echart-question-all/"/>
    <url>/2020/12/11/echart-question-all/</url>
    
    <content type="html"><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在运行Les-Miserables示例时，出现了浏览器一直<em>loading</em>不显示图表的问题。折腾了一天半，终于解决了问题的一般，为什么是一半呢？且听我娓娓道来。</p><span id="more"></span><h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><p>根据 <a href="https://segmentfault.com/a/1190000022173139">博客1</a> 的经验：</p><ul><li>引入工具包</li></ul><p>需要三个工具包，<strong>echarts、jquery、dataTool</strong>。前两个直接通过<strong>cdn</strong>引入即可，dataTool则去github上面复制下来自己新建一个即可。<br><code>dataTool.min.js</code>下载网址：(<a href="https://github.com/apache/incubator-echarts/blob/master/dist/extension/dataTool.min.js)%EF%BC%8C%E4%B8%8B%E8%BD%BD%E5%AE%8C%E5%90%8E%E5%B0%86%60dataTool.min.js%60%E6%94%BE%E5%9C%A8%60js%60%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E3%80%82">https://github.com/apache/incubator-echarts/blob/master/dist/extension/dataTool.min.js)，下载完后将`dataTool.min.js`放在`js`文件夹下。</a></p><p><code>test.html</code>中引用上述工具包代码如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">&lt;!-- 三个工具包缺一不可 --&gt;<br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.bootcss.com/echarts/4.1.0.rc2/echarts.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span> <br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span><br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;js/dataTool.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span>   <br></code></pre></td></tr></table></figure><ul><li>引入<code>les_miserables.gexf</code>数据文件</li></ul><p>该文件的在线url：<a href="https://www.echartsjs.com/examples/data/asset/data/les-miserables.gexf">https://www.echartsjs.com/examples/data/asset/data/les-miserables.gexf</a></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">$.<span class="hljs-title function_">get</span>(<span class="hljs-string">&#x27;在线url&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">xml</span>) <span class="hljs-comment">// url为les_miserables.gexf在线路径</span><br></code></pre></td></tr></table></figure><ul><li>完整代码</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><code class="hljs javascript">&lt;!<span class="hljs-variable constant_">DOCTYPE</span> html&gt;<br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span></span><br><span class="language-xml">    <span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="language-xml">        <span class="hljs-comment">&lt;!-- 三个工具包缺一不可 --&gt;</span></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.bootcss.com/echarts/4.1.0.rc2/echarts.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span> </span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;js/dataTool.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>                                         </span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Les Miserables<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span></span><br><span class="language-xml">    <span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span></span><br><span class="language-xml">    <span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span></span><br><span class="language-xml"></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;main&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width: 1000px;height: 1000px;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span><br><span class="language-xml">    </span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text/javascript&quot;</span>&gt;</span><span class="language-javascript"></span></span><br><span class="language-javascript"><span class="language-xml">                    <span class="hljs-comment">// 基于准备好的dom，初始化echarts实例</span></span></span><br><span class="language-javascript"><span class="language-xml">                    <span class="hljs-keyword">var</span> myChart = echarts.<span class="hljs-title function_">init</span>(<span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;main&#x27;</span>));</span></span><br><span class="language-javascript"><span class="language-xml">                    <span class="hljs-keyword">var</span> option;</span></span><br><span class="language-javascript"><span class="language-xml">                    myChart.<span class="hljs-title function_">showLoading</span>();</span></span><br><span class="language-javascript"><span class="language-xml">                    </span></span><br><span class="language-javascript"><span class="language-xml">                    $.<span class="hljs-title function_">get</span>(<span class="hljs-string">&#x27;https://www.echartsjs.com/examples/data/asset/data/les-miserables.gexf&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">xml</span>) &#123;   <span class="hljs-comment">//读取本地文件</span></span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">&#x27;读取到数据文件&#x27;</span>) </span></span><br><span class="language-javascript"><span class="language-xml">                        myChart.<span class="hljs-title function_">hideLoading</span>();</span></span><br><span class="language-javascript"><span class="language-xml">        </span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-keyword">var</span> graph = echarts.<span class="hljs-property">dataTool</span>.<span class="hljs-property">gexf</span>.<span class="hljs-title function_">parse</span>(xml);</span></span><br><span class="language-javascript"><span class="language-xml">                        </span></span><br><span class="language-javascript"><span class="language-xml">                        </span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-keyword">var</span> categories = [];</span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span>; i++) &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                            categories[i] = &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;类目&#x27;</span> + i</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;;</span></span><br><span class="language-javascript"><span class="language-xml">                        &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                        graph.<span class="hljs-property">nodes</span>.<span class="hljs-title function_">forEach</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params">node</span>) &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">itemStyle</span> = <span class="hljs-literal">null</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">value</span> = node.<span class="hljs-property">symbolSize</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">symbolSize</span> /= <span class="hljs-number">1.5</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">label</span> = &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">normal</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">show</span>: node.<span class="hljs-property">symbolSize</span> &gt; <span class="hljs-number">30</span></span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">category</span> = node.<span class="hljs-property">attributes</span>.<span class="hljs-property">modularity_class</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                        &#125;);</span></span><br><span class="language-javascript"><span class="language-xml">                        option = &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">title</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">text</span>: <span class="hljs-string">&#x27;Les Miserables&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">subtext</span>: <span class="hljs-string">&#x27;Default layout&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">top</span>: <span class="hljs-string">&#x27;bottom&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">left</span>: <span class="hljs-string">&#x27;right&#x27;</span></span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">tooltip</span>: &#123;&#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">legend</span>: [&#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-comment">// selectedMode: &#x27;single&#x27;,</span></span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">data</span>: categories.<span class="hljs-title function_">map</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params">a</span>) &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-keyword">return</span> a.<span class="hljs-property">name</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;)</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;],</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">animationDuration</span>: <span class="hljs-number">1500</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">animationEasingUpdate</span>: <span class="hljs-string">&#x27;quinticInOut&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">series</span>: [&#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;Les Miserables&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">type</span>: <span class="hljs-string">&#x27;graph&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">layout</span>: <span class="hljs-string">&#x27;none&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">data</span>: graph.<span class="hljs-property">nodes</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">links</span>: graph.<span class="hljs-property">links</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">categories</span>: categories,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">roam</span>: <span class="hljs-literal">true</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">focusNodeAdjacency</span>: <span class="hljs-literal">true</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">itemStyle</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">normal</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">borderColor</span>: <span class="hljs-string">&#x27;#fff&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">borderWidth</span>: <span class="hljs-number">1</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">shadowBlur</span>: <span class="hljs-number">10</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">shadowColor</span>: <span class="hljs-string">&#x27;rgba(0, 0, 0, 0.3)&#x27;</span></span></span><br><span class="language-javascript"><span class="language-xml">                                    &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">label</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">position</span>: <span class="hljs-string">&#x27;right&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">formatter</span>: <span class="hljs-string">&#x27;&#123;b&#125;&#x27;</span></span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">lineStyle</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">color</span>: <span class="hljs-string">&#x27;source&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">curveness</span>: <span class="hljs-number">0.3</span></span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">emphasis</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">lineStyle</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">width</span>: <span class="hljs-number">10</span></span></span><br><span class="language-javascript"><span class="language-xml">                                    &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;]</span></span><br><span class="language-javascript"><span class="language-xml">                        &#125;;</span></span><br><span class="language-javascript"><span class="language-xml">        </span></span><br><span class="language-javascript"><span class="language-xml">                        myChart.<span class="hljs-title function_">setOption</span>(option);</span></span><br><span class="language-javascript"><span class="language-xml">                    &#125;, <span class="hljs-string">&#x27;xml&#x27;</span>);</span></span><br><span class="language-javascript"><span class="language-xml">        </span></span><br><span class="language-javascript"><span class="language-xml">                </span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span><br><span class="language-xml"></span><br><span class="language-xml">    <span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span></span><br><span class="language-xml"><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span></span><br></code></pre></td></tr></table></figure><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>但是按照上述方法还是会出现浏览器一直<em>loading</em>无法显示图标的问题。表现在：</p><p>引用在线的<code>les_miserables.gexf</code>文件的url，图表可以在IE浏览器中正常显示，但是在谷歌和火狐浏览器中则一直加载不出来，出现 <u>跨域问题</u>：</p><p><code>has been blocked by CORS policy: No &#39;Access-Control-Allow-Origin&#39; header is present</code></p><p>若将<code>les_miserables.gexf</code>文件下载下来，放在目录<code>&#39;data/les_miserables.gexf&#39;</code>，并在代码中写成：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">$.<span class="hljs-title function_">get</span>(<span class="hljs-string">&#x27;data/les_miserables.gexf&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">xml</span>)<br></code></pre></td></tr></table></figure><p>在这种情况下，不管什么浏览器，都无法加载出图表，故头疼中。。。</p><h3 id="办法"><a href="#办法" class="headerlink" title="办法"></a>办法</h3><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>根据<a href="https://blog.csdn.net/chenmoupeng/article/details/107317247">博客2</a><code>解决Cross origin requests are only supported for protocol schemes的三种办法</code> 中第三种方法的启发，我们使用<code>anywhere插件</code>，使得项目得以在服务器端而不是本地端运行。</p><h5 id="全局安装anywhere插件"><a href="#全局安装anywhere插件" class="headerlink" title="全局安装anywhere插件"></a>全局安装anywhere插件</h5><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">$ npm <span class="hljs-keyword">install</span> anywhere -g <br></code></pre></td></tr></table></figure><h5 id="然后切换到html文件所在的文件夹，运行"><a href="#然后切换到html文件所在的文件夹，运行" class="headerlink" title="然后切换到html文件所在的文件夹，运行"></a>然后切换到html文件所在的文件夹，运行</h5><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>anywhere <br></code></pre></td></tr></table></figure><p>运行后一般会自动跳转到浏览器(默认谷歌浏览器)上，终端上会显示一个运行的网址。下图是我的跳转后的效果(仅供参考)：</p><p><img src="/images/echarts_qs/pic1.png"></p><p align = 'center'>图1.1 我的work directory</p><p><img src="/images/echarts_qs/pic2.png"></p><p align = 'center'>图1.2 浏览器跳转后的界面</p><p>点击<code>test.html</code>文件，图表完美呈现，棒极了！</p><p><img src="/images/echarts_qs/pic3.png"></p><p align = 'center'>图1.3 图表界面</p><p>但是这个方法还是要依赖<code>anywhere插件</code>图表才能执行。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>echarts</tag>
      
      <tag>跨域</tag>
      
      <tag>javascript</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch的常用张量操作</title>
    <link href="/2020/07/30/pytorch_operation/"/>
    <url>/2020/07/30/pytorch_operation/</url>
    
    <content type="html"><![CDATA[<h3 id="1：torch-masked-select"><a href="#1：torch-masked-select" class="headerlink" title="1：torch.masked_select"></a>1：torch.masked_select</h3><p>用法：<code>torch.masked_select(x, mask)</code>，mask必须转化成torch.ByteTensor类型。</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.Tensor([[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">8</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])<br>b = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]]).<span class="hljs-built_in">type</span>(torch.ByteTensor)<br>c = torch.masked_select(a,b)<br><span class="hljs-built_in">print</span>(c)<br></code></pre></td></tr></table></figure><h3 id="2-torch-gather-x2F-scatter"><a href="#2-torch-gather-x2F-scatter" class="headerlink" title="2: torch.gather&#x2F;scatter_"></a>2: torch.gather&#x2F;scatter_</h3><p>说明：dim&#x3D;0（按照竖直方向操作，即↓），dim&#x3D;1（按照水平方向操作，即→）</p><p>gather是取的意思，scatter_是放的意思。</p><blockquote><p>用法：<code>output=torch.gather(input, dim, index)</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])<br>b = torch.gather(a, <span class="hljs-number">1</span>, torch.LongTensor([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]]))<br><span class="hljs-built_in">print</span>(b) <br></code></pre></td></tr></table></figure><blockquote><p>用法：<code>output = torch.Tensor.scatter_(dim, index, src)</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(a)<br>b = torch.zeros(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>).scatter_(<span class="hljs-number">0</span>, torch.tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]]), a)<br><span class="hljs-built_in">print</span>(b) <br></code></pre></td></tr></table></figure><h3 id="3-torch-cat与torch-chunk"><a href="#3-torch-cat与torch-chunk" class="headerlink" title="3: torch.cat与torch.chunk"></a>3: torch.cat与torch.chunk</h3><p>用法：</p><blockquote><ul><li><code>torch.cat ( (A, B), dim=0)</code>接受一个由两个（或多个）tensor组成的元组，按行拼接，所以两个（多个）tensor的列数要相同。</li><li><code>torch.cat ( (A, B), dim=1)</code>是按列拼接，所以两个tensor的行数要相同。</li><li><code>torch.chunk(tensor, chunk_num, dim)</code>与torch.cat()原理相反，它是将tensor按dim（行    或列）分割成chunk_num个tensor块，返回的是一个元组。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>]])<br>b = torch.Tensor([[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">8</span>], [<span class="hljs-number">9</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]])<br>c = torch.cat((a,b), dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(c)<br><span class="hljs-built_in">print</span>(c.size())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;********************&#x27;</span>)<br>d = torch.chunk(c,<span class="hljs-number">4</span>,dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(d)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(d))<br></code></pre></td></tr></table></figure><h3 id="4-torch-unsqueeze-x2F-squeeze"><a href="#4-torch-unsqueeze-x2F-squeeze" class="headerlink" title="4: torch.unsqueeze&#x2F;squeeze"></a>4: torch.unsqueeze&#x2F;squeeze</h3><p>注意：维均从0开始计数</p><p>用法：</p><p><strong>unsqueeze:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = t.Tensor([[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">7</span>], [<span class="hljs-number">6</span>, <span class="hljs-number">9</span>]]) <span class="hljs-comment"># 3*2</span><br>y1 = x.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># 1*3*2</span><br><span class="hljs-built_in">print</span>(y1.size())<br>y2 = x.unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># 3*1*2</span><br><span class="hljs-built_in">print</span>(y2.size())<br>y3 = x.unsqueeze(<span class="hljs-number">2</span>) <span class="hljs-comment"># 3*2*1`</span><br><span class="hljs-built_in">print</span>(y3.size())`<br></code></pre></td></tr></table></figure><p><strong>squeeze:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = t.ones(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br>y1 = x.squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># 1*2*3*1</span><br><span class="hljs-built_in">print</span>(y1.size())<br>y2 = x.squeeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># 1*2*3*1</span><br><span class="hljs-built_in">print</span>(y2.size())<br>y3 = x.squeeze() <span class="hljs-comment"># 2*3</span><br><span class="hljs-built_in">print</span>(y3.size())<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>张量计算</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>张量操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>二叉树的建立与遍历（C语言实现）</title>
    <link href="/2020/07/30/er-cha-shu-de-jian-li-yu-bian-li-c-yu-yan-shi-xian/"/>
    <url>/2020/07/30/er-cha-shu-de-jian-li-yu-bian-li-c-yu-yan-shi-xian/</url>
    
    <content type="html"><![CDATA[<p>1：二叉树结点的定义：</p><span id="more"></span><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span></span><br><span class="hljs-class">&#123;</span><br><span class="hljs-type">int</span> data;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">pleft</span>;</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">pright</span>;</span><br>&#125;Node;<br></code></pre></td></tr></table></figure><p>2：二叉树创造一个结点的函数，返回值是指向该节点的指针：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">struct</span> Node *<span class="hljs-title function_">createnode</span><span class="hljs-params">(<span class="hljs-type">int</span> value)</span><br>&#123;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">pnode</span> =</span> (<span class="hljs-keyword">struct</span> Node *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">struct</span> Node));<br>pnode-&gt;data = value;<br>pnode-&gt;pleft = pnode-&gt;pright = <span class="hljs-literal">NULL</span>;<br><span class="hljs-keyword">return</span> pnode;<br>&#125;<br></code></pre></td></tr></table></figure><p>3：二叉树插入结点的函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">struct</span> Node *<span class="hljs-title function_">addnode</span><span class="hljs-params">(<span class="hljs-type">int</span> value, <span class="hljs-keyword">struct</span> Node *pnode)</span><br>&#123;<br><span class="hljs-keyword">if</span>(pnode == <span class="hljs-literal">NULL</span>)<br><span class="hljs-keyword">return</span> createnode(value);<br><br><span class="hljs-keyword">if</span>(value == pnode-&gt;data)<br>&#123;<br><span class="hljs-keyword">return</span> pnode;<br>&#125;<br><br><span class="hljs-keyword">if</span>(value &lt; pnode-&gt;data)<br>&#123;<br><span class="hljs-keyword">if</span>(pnode-&gt;pleft == <span class="hljs-literal">NULL</span>)<br>&#123;<br>pnode-&gt;pleft = createnode(value);<br><span class="hljs-keyword">return</span> pnode-&gt;pleft;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br><span class="hljs-keyword">return</span> addnode(value, pnode-&gt;pleft);<br>&#125;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br><span class="hljs-keyword">if</span>(pnode-&gt;pright == <span class="hljs-literal">NULL</span>)<br>&#123;<br>pnode-&gt;pright = createnode(value);<br><span class="hljs-keyword">return</span> pnode-&gt;pright;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br><span class="hljs-keyword">return</span> addnode(value, pnode-&gt;pright);<br>&#125;<br><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>4：二叉树的遍历（三种，此处为中序遍历），用到了递归：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">listnodes</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Node *pnode)</span><br>&#123;<br><span class="hljs-keyword">if</span>(pnode != <span class="hljs-literal">NULL</span>)<br>&#123;<br>listnodes(pnode-&gt;pleft);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, pnode-&gt;data);<br>listnodes(pnode-&gt;pright);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>5：求二叉树的深度，递归：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> <span class="hljs-title function_">Treeheight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Node *pnode)</span><br>&#123;<br><span class="hljs-type">int</span> LD, RD;<br><span class="hljs-keyword">if</span>(pnode == <span class="hljs-literal">NULL</span>)<br>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>LD = Treeheight(pnode-&gt;pleft);<br>RD = Treeheight(pnode-&gt;pright);<br><span class="hljs-keyword">return</span> (LD &gt;= RD? LD:RD) + <span class="hljs-number">1</span>;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>6：主函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br><span class="hljs-type">int</span> newvalue = <span class="hljs-number">0</span>;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">proot</span> =</span> <span class="hljs-literal">NULL</span>;<br><span class="hljs-type">char</span> answer = <span class="hljs-string">&#x27;n&#x27;</span>;<br><span class="hljs-keyword">do</span><br>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Enter the node value:\n&quot;</span>);<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;newvalue);<br><span class="hljs-keyword">if</span>(proot == <span class="hljs-literal">NULL</span>)<br>&#123;<br>proot = createnode(newvalue);<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>addnode(newvalue, proot);<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\nDo you want to enter another (y or n)? &quot;</span>);<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot; %c&quot;</span>, &amp;answer);<br>&#125; <span class="hljs-keyword">while</span>(<span class="hljs-built_in">tolower</span>(answer) == <span class="hljs-string">&#x27;y&#x27;</span>);<br><br>listnodes(proot);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\nThe height of tree is %d!&quot;</span>, Treeheight(proot));<br><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>7：需要添加的头文件：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;ctype.h&gt;</span></span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C语言</tag>
      
      <tag>数据结构</tag>
      
      <tag>二叉树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C语言实现排序算法</title>
    <link href="/2020/07/30/c-yu-yan-shi-xian-mou-pao-pai-xu/"/>
    <url>/2020/07/30/c-yu-yan-shi-xian-mou-pao-pai-xu/</url>
    
    <content type="html"><![CDATA[<h3 id="1：冒泡排序"><a href="#1：冒泡排序" class="headerlink" title="1：冒泡排序"></a>1：冒泡排序</h3><p>冒泡排序函数定义（参数是一个整型数组和一个整型数）：</p><span id="more"></span><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">bubblesort</span><span class="hljs-params">(<span class="hljs-type">int</span> a[], <span class="hljs-type">int</span> n)</span><br>&#123;<br><span class="hljs-type">int</span> temp, i, j, flag, k;<br><span class="hljs-keyword">for</span>(j = n - <span class="hljs-number">1</span>; j &gt; <span class="hljs-number">1</span>; j--)<br>&#123;<br>flag = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; j; i++)<br>&#123;<br><span class="hljs-keyword">if</span>(a[i] &gt; a[i+<span class="hljs-number">1</span>])<br>&#123;<br>flag = <span class="hljs-number">1</span>;<br>temp = a[i];<br>a[i] = a[i+<span class="hljs-number">1</span>];<br>a[i+<span class="hljs-number">1</span>] = temp;<br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span>(flag == <span class="hljs-number">0</span>)<br>&#123;<br><span class="hljs-comment">// 如果这次子排序没有发生元素交换，则冒泡排序结束。</span><br><span class="hljs-keyword">break</span>;<br>&#125;<br>&#125;<br><span class="hljs-comment">// print the array that has been sorted</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;The final array is as follows:\n&quot;</span>);<br><span class="hljs-keyword">for</span>(k = <span class="hljs-number">0</span>; k &lt; n; k++)<br>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, a[k]);<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>注意点：冒泡排序的结束条件是某次子排序没有发生元素互换。<br>主函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> <br>&#123;<br><span class="hljs-type">void</span> <span class="hljs-title function_">bubblesort</span><span class="hljs-params">(<span class="hljs-type">int</span> a[], <span class="hljs-type">int</span> n)</span>;<br><span class="hljs-type">int</span> length, count;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Please input the number of your array!\n&quot;</span>);<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;length);<br><span class="hljs-type">int</span> test[length];<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Please input each element of your array!\n&quot;</span>);<br><span class="hljs-keyword">for</span>(count = <span class="hljs-number">0</span>; count &lt; length; count++)<br>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;test[count]);<br>&#125;<br>bubblesort(test, length);<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2：快速排序"><a href="#2：快速排序" class="headerlink" title="2：快速排序"></a>2：快速排序</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span>  *<span class="hljs-title function_">QuickSort</span><span class="hljs-params">(<span class="hljs-type">int</span> R[], <span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span><br>&#123;<br><span class="hljs-type">int</span> temp;<br><span class="hljs-type">int</span> i = l, j = r;<br><span class="hljs-keyword">if</span>(l &lt; r)<br>&#123;<br>temp = R[l];<br><span class="hljs-keyword">while</span>(i != j)<br>&#123;<br><span class="hljs-keyword">while</span>(i &lt;j &amp;&amp; R[j] &gt; temp)<br>&#123;<br>j--;<br>&#125;<br><span class="hljs-keyword">if</span>(i &lt; j)<br>&#123;<br>R[i] = R[j];<br>i++;<br>&#125;<br><span class="hljs-keyword">while</span>(i &lt;j &amp;&amp; R[i] &lt; temp)<br>&#123;<br>i++;<br>&#125;<br><span class="hljs-keyword">if</span>(i &lt; j)<br>&#123;<br>R[j] = R[i];<br>j--;<br>&#125;<br>&#125;<br>R[i] = temp;<br>QuickSort(R, <span class="hljs-number">1</span>, i<span class="hljs-number">-1</span>);<br>QuickSort(R, i+<span class="hljs-number">1</span>, r);<br>&#125;<br><span class="hljs-type">int</span> *p = &amp;R[<span class="hljs-number">0</span>];<br><span class="hljs-keyword">return</span> p;<br>&#125;<br></code></pre></td></tr></table></figure><p>主函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> <br>&#123;<br><span class="hljs-type">int</span>  *<span class="hljs-title function_">QuickSort</span><span class="hljs-params">(<span class="hljs-type">int</span> R[], <span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span>;<br><span class="hljs-type">int</span> length, count1, count2, *q;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Please input the number of your array!\n&quot;</span>);<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;length);<br><span class="hljs-type">int</span> test[length];<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Please input each element of your array!\n&quot;</span>);<br><span class="hljs-keyword">for</span>(count1 = <span class="hljs-number">0</span>; count1 &lt; length; count1++)<br>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;test[count1]);<br>&#125;<br><span class="hljs-comment">// q = &amp;test[0]</span><br>q = QuickSort(test, <span class="hljs-number">0</span>, length<span class="hljs-number">-1</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;The element of the final array is as follows:\n&quot;</span>);<br><span class="hljs-keyword">for</span>(count2 = <span class="hljs-number">0</span>; count2 &lt; length; count2++)<br>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, *(q + count2));<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3：希尔排序"><a href="#3：希尔排序" class="headerlink" title="3：希尔排序"></a>3：希尔排序</h3><p>未完待续。。。</p>]]></content>
    
    
    <categories>
      
      <category>算法分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>排序</tag>
      
      <tag>C语言</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读-The Numerics of GANs</title>
    <link href="/2018/03/31/the-numerics-of-gans/"/>
    <url>/2018/03/31/the-numerics-of-gans/</url>
    
    <content type="html"><![CDATA[<h3 id="论文标题"><a href="#论文标题" class="headerlink" title="论文标题"></a>论文标题</h3><p><strong>The Numerics of GANs</strong></p><span id="more"></span><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="实对称矩阵"><a href="#实对称矩阵" class="headerlink" title="实对称矩阵"></a>实对称矩阵</h4><p>如果一个矩阵是实对称矩阵，那么其所有的特征值是实数。如果它不是实对称矩阵，那么其特征值一般是复数：包含实部（real-part），虚部（imaginary-part）。</p><h4 id="正定矩阵"><a href="#正定矩阵" class="headerlink" title="正定矩阵"></a>正定矩阵</h4><ul><li><p>正定矩阵：对于任何非零向量X，都有 $ X^{T}AX &gt; 0 $，则称矩阵A为正定阵。</p></li><li><p>负定矩阵：对于任何非零向量X，都有 $ X^{T}AX &lt; 0 $，则称矩阵A为负定阵。</p></li><li><p>半正定矩阵：对于任何非零向量X，都有 $ X^{T}AX &gt;&#x3D; 0 $，则称矩阵A为半正定阵。</p></li><li><p>半负定矩阵：对于任何非零向量X，都有 $ X^{T}AX &lt;&#x3D; 0 $，则称矩阵A为半负定阵。</p></li></ul><h4 id="雅克比矩阵"><a href="#雅克比矩阵" class="headerlink" title="雅克比矩阵"></a>雅克比矩阵</h4><p>雅可比矩阵类似于单变数函数的导数。 假设 $F: R_{n} \rightarrow R_{m}$是一个从n维欧氏空间映射到到m维欧氏空间的函数。这个函数由m个实函数组成：$y_{1}\left(x_{1}, \ldots, x_{n}\right), \ldots y_{m}\left(x_{1}, \ldots, x_{n}\right)$ 。这些函数的偏导数(如果存在)可以组成一个m行n列的矩阵，这个矩阵就是所谓的雅可比矩阵：<br>$$<br>{<br>\left[\begin{array}{ccc}\frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}} \ \vdots &amp; \ddots &amp; \vdots \ \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}\end{array}\right]<br>}<br>$$</p><p>此外，雅克比矩阵的行列式称为雅克比行列式。</p><h4 id="黑塞矩阵"><a href="#黑塞矩阵" class="headerlink" title="黑塞矩阵"></a>黑塞矩阵</h4><p>黑塞矩阵（Hessian Matrix）与雅克比矩阵的不同之处在于，它是一个多元函数的二阶偏导数构成的方阵。<br>$$<br>{<br>H(f)&#x3D;\left[\begin{array}{cccc}\frac{\partial^{2} f}{\partial x_{1}^{2}} &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{n}} \ \frac{\partial^{2} f}{\partial x_{2} \partial x_{1}} &amp; \frac{\partial^{2} f}{\partial x_{2}^{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{2} \partial x_{n}} \ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \ \frac{\partial^{2} f}{\partial x_{n} \partial x_{1}} &amp; \frac{\partial^{2} f}{\partial x_{n} \partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{n}^{2}}\end{array}\right]<br>}<br>$$</p><p>通用计算公式：<br>$$<br>{<br>H_{i, j}&#x3D;\frac{\partial^{2} f}{\partial x_{i} \partial x_{j}} \tag{1.1}<br>}<br>$$</p><p>i和j分别表示行数和列数（均从1开始计数）。</p><h4 id="纳什均衡"><a href="#纳什均衡" class="headerlink" title="纳什均衡"></a>纳什均衡</h4><p>假设有n个局中人参与博弈，如果某情况下无一参与者可以独自行动而增加收益（即为了自身利益的最大化，没有任何单独的一方愿意改变其策略），则此策略组合被称为纳什均衡。</p><p>这篇论文中，作者分析了训练GAN的普通算法的数值。通过使用平滑双人游戏的方式，分析了GAN训练对象的关联梯度向量场。当前算法的收敛性受到两个因素的影响：i）具有零实部的梯度矢量场的雅可比矩阵的特征值的存在，以及ii）具有大的虚部的特征值。 利用这些发现，作者设计了一种克服了这些局限性并具有更好收敛特性的新算法。 通过实验，证明了其在训练普通GAN的结构的优越性并且展示了难以训练的GAN结构的收敛性。</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>GAN自从被提出以后已经成功地应用于各种领域任务，包括图像到图像的翻译，图像超分辨率，图像绘画域适应，概率推理等等。尽管如此，GAN还是普遍认为难以被训练。标准的策略使训练稳定的方法是仔细设计模型，要不就是改变结构，要不就是选择一个容易优化的函数。</p><p>作者从理论上证明，阻止算法收敛的主要因素是相关梯度矢量场的雅可比阵特征值的存在性，其中零实部和大的虚部的特征值。作者设计了一种克服这些问题的新算法。</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="散度方法和GANS"><a href="#散度方法和GANS" class="headerlink" title="散度方法和GANS"></a>散度方法和GANS</h4><p>给出一个函数D，其输入是一对概率分布，其输出是一个大于等于0的元素。并且对于所有的分布p，满足$D(p,p)&#x3D;0$。</p><p>假定给出一个目标概率分布 $p_{0}$，一个分布 $q_{θ}$（实际上被应用于一个神经网络，这个网络作用于一个取样自已知分布的的隐代码z，网络的输出是一个来自目标空间的元素）。我们的目标是：</p><p>$$<br>{<br>\min <em>{\theta} D\left(p</em>{0}, q_{\theta}\right)<br>}<br>$$<br>大部分实际应用的散度被表达成如下的式子：</p><p>$$<br>{<br>D(p, q)&#x3D;\max <em>{f \in F} E</em>{x \sim q}\left[g_{1}(f(x))\right]-E_{x \sim p}\left[g_{2}(f(x))\right] \tag{1.2}<br>}<br>$$<br>结合公式（1.2）和（1.3），最终得到最小最大化问题：</p><p>$$<br>{<br>\min <em>{\theta} \max <em>{f \in F} E</em>{x \sim q</em>{\theta}}\left[g_{1}(f(x))\right]-E_{x \sim p_{0}}\left[g_{2}(f(x))\right] \tag{1.3}<br>}<br>$$<br>函数类F近似于一个参数系列的函数，由一个神经网络参数化。</p><h4 id="平滑二玩家游戏"><a href="#平滑二玩家游戏" class="headerlink" title="平滑二玩家游戏"></a>平滑二玩家游戏</h4><p>一个可微分的二类游戏由两个效用函数$f(φ,θ)$和$g(φ,θ)$定义，基于一个普通空间<br>$$<br>{<br>(\varphi, \theta) \in \Omega_{1} \times \Omega_{2}<br>}<br>$$<br> 其中，Ω1对应玩家1的可能性动作，在GAN中是生成器的可能参数集。玩家1的目标是最大化函数f。Ω2对应玩家2的可能性动作，在GAN中是判别器的可能参数集，玩家2的目标是最大化函数g。当$f + g&#x3D;0$的时候，这就是一个零和游戏的状态。</p><p>我们的目标是找到这个游戏的一个纳什均衡点，即<br>$$<br>{<br>\bar{x}&#x3D;(\bar{\varphi}, \bar{\theta}) \tag{1.4}<br>}<br>$$</p><p>$$<br>{<br>\bar{\varphi} \in \underset{\varphi}{\arg \max } f(\varphi, \bar{\theta})<br>}<br>$$</p><p>$$<br>{<br>\bar{\theta} \in \underset{\theta}{\arg \max } g(\bar{\varphi}, \theta)<br>}<br>$$</p><p>定义一个向量场：</p><p>$$<br>{<br>v(\phi, \theta)&#x3D;\left(\begin{array}{c}\nabla_{\phi} f(\phi, \theta) \ \nabla_{\theta} g(\phi, \theta)\end{array}\right) \tag{1.5}<br>}<br>$$<br>在零和游戏的情况下再对其求导：</p><p>$$<br>{<br>v^{\prime}(\phi, \theta)&#x3D;\left(\begin{array}{cc}\nabla_{\phi}^{2} f(\phi, \theta) &amp; \nabla_{\phi, \theta} f(\phi, \theta) \ -\nabla_{\phi, \theta} f(\phi, \theta) &amp; -\nabla_{\theta}^{2} f(\phi, \theta)\end{array}\right) \tag{1.6}<br>}<br>$$</p><h4 id="同时梯度下降"><a href="#同时梯度下降" class="headerlink" title="同时梯度下降"></a>同时梯度下降</h4><p>该算法迭代更新两个玩家的参数，同时对两个玩家的效用函数应用梯度上升。</p><p>如果两个参与者的黑塞矩阵都是负定的，并且学习率足够小，那么同时梯度上升就会局部收敛到零和博弈的纳什均衡。</p><h3 id="收敛性理论"><a href="#收敛性理论" class="headerlink" title="收敛性理论"></a>收敛性理论</h3><p>这一节分析了最常用的训练GANs同时梯度上升方法的收敛性。证明这个算法的两个主要失效原因是具有零实部的相关梯度矢量场的雅可比阵的特征值以及具有大的虚部的特征值。</p><h4 id="Proposition-3"><a href="#Proposition-3" class="headerlink" title="Proposition 3"></a>Proposition 3</h4><p>$\Omega \in \mathbb{R}^{n}$ ，函数F： $\Omega \rightarrow \Omega$是一个连续的可微函数，$\bar{x}\in \Omega$</p><p>1：$F(\bar{x}) &#x3D; \bar{x} \tag{1.7}$</p><p>2：雅克比矩阵$F^{‘}(\bar{x})$的所有特征值的绝对值均小于1</p><p>设$\bar{x}$的某一领域为$U$，$x_{0} \in U$，$F^{(k)}(x_{0})$收敛于$\bar{x}$</p><p>误差$\left|F^{(k)}\left(x_{0}\right)-\bar{x}\right|$在$\mathcal{O}\left(\left|\lambda_{\max }\right|^{k}\right)$内，$k\rightarrow \infty$ ，并且$\lambda_{\max }$ 为$F^{‘}(\bar{x})$所有特征值的绝对值的最大值。</p><p>考虑以下函数形式：<br>$$<br>{<br>F(x)&#x3D;x+hG(x) \tag{1.8}<br>}<br>$$<br>求导：<br>$$<br>{<br>F^{‘}(x)&#x3D;I+hG^{‘}(x) \tag{1.9}<br>}<br>$$<br>$F^{‘}(x)$和$G^{‘}(x)$都不是对称的，故它们有复杂的特征值。</p><h4 id="Lemma-4"><a href="#Lemma-4" class="headerlink" title="Lemma 4"></a>Lemma 4</h4><p>矩阵A的特征值拥有负实部，并且让$h&gt;0$<br>$$<br>{<br>h&lt;\frac{1}{|\Re(\lambda)|} \frac{2}{1+\left(\frac{\Im(\lambda)}{\Re(\lambda)}\right)^{2}}<br>} \tag{2.0}<br>$$<br>上式表明有两个主要因子影响了h的最大可能值，即：</p><p>（1）$\Re(\lambda)$的最大值</p><p>（2）$|\Im(\lambda) &#x2F; \Re(\lambda)|$的最大值q</p><h3 id="一致性优化"><a href="#一致性优化" class="headerlink" title="一致性优化"></a>一致性优化</h3><h4 id="Derivation"><a href="#Derivation" class="headerlink" title="Derivation"></a>Derivation</h4><p>寻找向量场$v(x)$的稳定点等同于解方程<br>$$<br>{<br>v(x)&#x3D;0 \tag{2.1}<br>}<br>$$<br>在二类游戏的内容里意味着解一对方程<br>$$<br>{<br>\nabla_{\phi} f(\phi, \theta)&#x3D;0 \tag{2.2}<br>}<br>$$</p><p>$$<br>{<br>\nabla_{\theta} g(\phi, \theta)&#x3D;0 \tag{2.3}<br>}<br>$$</p><p>寻找类似稳定点的一个简单策略是最小化<br>$$<br>{<br>L(x)&#x3D;\frac{1}{2}|v(x)|^{2} \tag{2.4}<br>}<br>$$<br>但这可能会导致局部最小值。</p><p>现考虑一个修改过的向量场$w(x)$，它尽可能接近原始向量场$v(x)$，即<br>$$<br>{<br>w(x)&#x3D;v(x)-\gamma \nabla L(x) \tag{2.5}<br>}<br>$$</p><p>$$<br>{<br>\nabla L(x)&#x3D;v^{\prime}(x)^{\mathrm{T}} v(x) \tag{2.6}<br>}<br>$$</p><p>该向量场是由两个修改的效用函数给出的修改的双人游戏相关联的梯度向量场<br>$$<br>{<br>\tilde{f}(\phi, \theta)&#x3D;f(\phi, \theta)-\gamma L(\phi, \theta) \tag{2.7}<br>}<br>$$</p><p>$$<br>{<br>\tilde{g}(\phi, \theta)&#x3D;g(\phi, \theta)-\gamma L(\phi, \theta) \tag{2.8}<br>}<br>$$</p><p>其中正则化项$L(\phi, \theta)$鼓励两个玩家达成一致，因此称之为Consensus Optimization。</p><h4 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h4><p>考虑一个迭代使用函数F的算法<br>$$<br>{<br>F(x)&#x3D;x+hA(x)v(x) \tag{2.9}<br>}<br>$$<br>其中$h&gt;0$，$A(x)$是可逆矩阵。</p><p>Consensus优化是该算法在<br>$$<br>{<br>A(x)&#x3D;I-\gamma v^{\prime}(x)^{\top} \tag{3.0}<br>}<br>$$<br>的特殊情形。假定 $\frac{1}{\gamma}$不是 的特征值，所以$A(x)$是可逆的。</p><h5 id="Lemma-6"><a href="#Lemma-6" class="headerlink" title="Lemma 6"></a>Lemma 6</h5><p>假定$h&gt;0$且$A(x)$是可逆阵，$\bar{x}$是固定点，并且他是$v$的稳定点，我们有<br>$$<br>{<br>F^{\prime}(\bar{x})&#x3D;I+h A(\bar{x}) v^{\prime}(\bar{x}) \tag{3.1}<br>}<br>$$</p><h5 id="Lemma-7"><a href="#Lemma-7" class="headerlink" title="Lemma 7"></a>Lemma 7</h5><p>设<br>$$<br>{<br>A(x)&#x3D;I-\gamma v^{\prime}(x)^{\top} \tag{3.2}<br>}<br>$$<br>并假定$v^{\prime}(\bar{x})$是半负定且可逆的，所以$A(\bar{x}) v^{\prime}(\bar{x})$是负定的。</p><h5 id="Lemma-9"><a href="#Lemma-9" class="headerlink" title="Lemma 9"></a>Lemma 9</h5><p>假定$A\in \mathbb{R}^{n*n}$是半负定阵，$q(\gamma )$ 是 $\frac{|\mathfrak{G}(\lambda)|}{|\Re(\lambda)|}$的最大值。</p><p>$\lambda$表示$A-\lambda A^{T}A$的特征值，$\Re(\lambda)$和$\mathfrak{G}(\lambda)$分别表示特征值$\lambda$的实部与虚部。此外，假定A是可逆的，有$|Av|&gt;&#x3D;p|v|$，此时$p&gt;0$</p><p>令<br>$$<br>{<br>c&#x3D;\min _{v \in \mathbb{S}\left(\mathbb{C}^{n}\right)} \frac{\left|\bar{v}^{\top}\left(A+A^{\top}\right) v\right|}{\left|\bar{v}^{\top}\left(A-A^{\top}\right) v\right|} \tag{3.3}<br>}<br>$$<br>$S(C^{n})$表示在$C^{n}$中的单位球体，然后有：<br>$$<br>{<br>q(\gamma) \leq \frac{1}{c+2 \rho^{2} \gamma} \tag{3.4}<br>}<br>$$</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>第一个实验通过一个简单的二维实例来评估我们的方法，其中目标是学习8个标准差等于10的-2次方的高斯混合物。但即使在这样简单的示例中，训练GAN的算法也往往无法收敛，由于没有对体系结构和超参数进行微调。</p><p>对于生成器和评论家，两者都使用具有4个隐藏层的全连接神经网络，并且每层有16个隐藏单元。 对于所有的层，使用RELU非线性激活函数。对隐变量z使用16维高斯先验，并使用一个效用函数来设置生成器和评论者之间的游戏。为了测试方法，运行SimGA和RMSProp，一共是20000步，学习率为10的-4次方。 对于我们的方法，使用γ&#x3D; 10的正则化参数。</p><p>对SimGA方法和我们的方法进行0, 5000, 10000和20000次迭代的结果，虽然SimGA跳过分布模式并且未能收敛，但我们的方法平滑地收敛到目标分布。</p><p>实验结果还显示了$v(x)$的雅可比行列式和正则化向量场$w(x)$的特征值的经验分布，其中<br>$$<br>{<br>w(x)&#x3D;v(x)-\gamma \nabla L(x) \tag{3.5}<br>}<br>$$<br>在纳什均衡附近，大多数特征值确实非常接近虚轴，并且在一致优化中使用的向量场的所提出的修改将特征值向左移动。</p><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p>在第二个实验中，将我们的方法应用于cifar-10和celebAdatasets，在发生器或鉴别器中没有批量归一化的情况下使用类似DC-GAN的架构。 对于celebA，另外在每一层中使用恒定数量的<strong>滤波器</strong>并添加额外的RESNET层，与使用交替梯度上升不同，在训练期间，发生器和鉴别器损失几乎保持不变。</p><h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>在讨论中，作者认为之前的分析不能解释为什么训练期间发生器和鉴别器损失几乎保持不变。另外在实践中，如果正则化参数选择为高，提出的方法可能使梯度矢量场的以前不稳定的稳定点稳定。作者还发现，提出的方法对于更深的体系结构变得不太稳定，作者认为这种体系结构中梯度可能具有非常不同的尺度，所以第4节中的简单L2惩罚需要相应地重新调整。提出的方法可以认为是对隐式欧拉方法的积分梯度向量场的近似，还可以看作是二阶方法。</p><h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p><strong>鞍点问题</strong>不仅出现在训练GAN的情况下。在强化学习中流行的行动者 - 评论者模型也是鞍点问题的特例。</p><p>寻找稳定的GAN训练算法是一个长期存在的问题，并提出了多种解决方案。展开的GAN展开关于评论家的优化，从而为生成器提供更多信息性梯度。尽管展示优化被证明可以稳定训练，但实施起来可能很麻烦，并且还会产生一个很大的模型。所以工作重点是稳定各种架构和发散功能的训练。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从GAN目标函数出发，作者分析了在平滑双人游戏中寻找局部纳什均衡的主要难点。作者确定了当前最先进的算法中出现的主要数值问题，提出了一种用于训练生成对抗网络的新算法。</p><p>这个新算法在理论和实践上具有良好的性质：从理论的角度来看，即使雅可比矩阵的特征值存在问题，也能证明它是局部收敛于纳什均衡的。从实践的角度来看，新算法可以与任何GAN架构结合使用，其目标可以被定义为双人游戏以稳定训练。</p><p>最后作者通过实验证明了新算法能够稳定训练并成功地解决了<strong>模型崩溃</strong>等训练问题。</p>]]></content>
    
    
    <categories>
      
      <category>GANs</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GANs</tag>
      
      <tag>线性代数</tag>
      
      <tag>纳什均衡</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读-GANs用于离散序列生成</title>
    <link href="/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/"/>
    <url>/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/</url>
    
    <content type="html"><![CDATA[<p><strong>篇名</strong>：<em>GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution</em></p><p><strong>概要中提出的问题</strong>：当目标是生成离散元素构成的序列时 GAN 是存在限制的。</p><p><strong>出现问题的原因</strong> ：是来自服从离散对象分布的样本，例如多项式关于分布参数是不可区分的。</p><p><strong>解决方法</strong>：作者提出使用 Gumbel-softmax 分布可以避免这个问题，该分布是对 softmax 函数参数化的多项分布的连续逼近。</p><p><strong>本文所做的工作</strong>：评估基于 GS 输出分布的递归神经网络的GAN在生成离散元素组成的序列这一任务中的性能如何。</p><span id="more"></span><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p> GAN通过从鉴别器产生的样本后向传播到生成器来工作。如果产生的样本是连续的，例如图像生成的例子，这是可行的。但是如果大量数据以离散的形式存在，比如文本中的句子，以 SMILE语言编码的分子等。在这些情况下，离散数据是不可微分的（由高等数学的知识，可微一定连续，连续不一定可微，所以不连续一定不可微），反向传播的梯度总是0。</p><p>使用独热编码表示离散数据。这样就可以从多项分布中采样，其概率由softmax函数的输出给出。</p><p>用一个简单的例子来说明独热编码。例如有三个特征：</p><p>性别：[“男”，“女”] 爱好：[“篮球”，“足球”，“羽毛球”，“排球”]</p><p>国家：[“中国”，“美国”，“英国”，“俄罗斯”，“法国”]</p><p>对于某样本[“女”，“羽毛球”，“法国”]，用独热编码表示就是[01 0010 00001]。</p><p>何为softmax函数？</p><p>对于二分类问题，我们一般使用sigmoid函数将输入映射到 (0,1) 的区间中，从而得到某个类别的概率。推广到多类问题，我们使用softmax函数对输出的值归一化为概率值。</p><p>例如，假设输入数据是维度为 $d$ 的向量$\textbf {h}$，那么经过softmax函数的输出也是一个 $d$维度的向量 ，里面$\textbf {p}$的值都在0到1之间，也就是概率值。所以理解为一个归一化的指数函数：</p><p>$$<br>{<br>[s o f t \max (h)]<em>{i}&#x3D;\frac{e^{h</em>{i}}}{\sum_{j&#x3D;1}^{d} e^{z_{j}}} \tag{1.1}<br>}<br>$$</p><p>其中$ i \in (1, d) $ ；</p><p>观察上述公式，还可以得到：</p><p>$$<br>{<br>\sum_{i&#x3D;1}^{d}[s o f t \max (h)]_{i}&#x3D;1 \tag{1.2}<br>}<br>$$<br>个人通俗理解就是，先用指数函数 $ y&#x3D;e^{x} $ 作用于 $C$ 维输入向量中分量的每个值，得到一串新值。再将这些新值加起来。用每个新值除以这个和就是经过softmax函数处理后对应的输出向量分量的对应值。</p><p>现在又提出了在离散序列上训练 GAN 的另一种方法。 该方法将离散序列的生成建模为强化学习中的随机策略，并通过直接执行梯度策略更新来绕过生成器区分问题。</p><h4 id="Gumbel-softmax分布"><a href="#Gumbel-softmax分布" class="headerlink" title="Gumbel-softmax分布"></a>Gumbel-softmax分布</h4><p>上面我已经介绍了 softmax函数，然后引入 Gumbel-softmax分布：<br>$$<br>{<br>y &#x3D; onehot \left(\arg \max <em>{i}\left(h</em>{i}+g_{i}\right)\right) \tag{1.3}<br>}<br>$$<br>其中 $ g_{i} $ 是独立的并且遵循 Gumbel分布，具有零位和单位尺度。<br>$$<br>{<br>y&#x3D;\operatorname{soft} \max (1 &#x2F; \Gamma(h+g)) \tag{1.4}<br>}<br>$$<br>$\Gamma$是一个逆向温度参数。当它趋于0时，由公式（1.4）生成的样本和公式（1.3）生成的样本有着相同的分布。而当它趋于无穷时，样本总是一致的概率向量。对于${\Gamma}$的正值和有限值，由（1.4）生成的样本相对于是平$\textbf {h}$滑和可微的。</p><p>公式（1.4）的概率分布就叫Gumbel-softmax分布。一个基于离散数据的GAN可以用（1.4）来训练了，从一些比较大的$\Gamma$开始，然后在训练期间将其回零。</p><h4 id="离散序列的递归神经网络"><a href="#离散序列的递归神经网络" class="headerlink" title="离散序列的递归神经网络"></a>离散序列的递归神经网络</h4><p>这个部分描述的是怎样建立一个能够从随机的噪音样本中生成文本的GAN模型。将给出一个简单的算法。</p><p>$$<br>{<br> S \rightarrow x|S+S| S-S|S * S| S &#x2F; S \tag{1.5}<br>}<br>$$<br>上面这个公式用来描述学习生成简单的单变量算术序列。两竖线用来划分语法的可能产生。</p><p>生成模型基于LSTM循环神经网络，它被训练用来在每个时间步预测一个隐藏状态的向量 $\textbf {h}$，然后再对这个向量使用softmax函数归一化。训练结束后，网络通过从softmax分布中取样来生成数据。</p><p>训练LSTM模型以预测未来特征的一种方法是通过最大似然估计（MLE）将softmax分布与输入数据的独热编码进行匹配。构建一个离散序列的生成模型，通过LSTM进行采样来完成。生成模型以一个样本对为输入，有效地替换了初始细胞和隐藏状态。生成器通过连续地将其预测作为输入反馈到下面的LSTM单元来构建序列。目标是设计一种方法来训练这个生成器来产生真实的离散序列。</p><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-1.png"></p><p align = 'center'>图 1.1 一个经典的LSTM模型</p><p>上图是一个经典的LSTM模型，每个LSTM单元（蓝色盒子）根据过去看到的输入进行预测，然后这个预测被用作下一个单元的输入，以此类推。</p><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-2.png"></p><p align = 'center'>图 1.2 离散序列的生成模型</p><p>上图是离散序列的生成模型。一开始画一对样本并将它们送入网络，代替初始单元状态$C_{0}$ 和隐藏状态$h_{0}$ 。训练好的网络取这些样本并且使用它们生成一个初始特征，这个生成的特征被送到LSTM的下一个单元作为输入，以此类推。</p><h3 id="对抗生成模型"><a href="#对抗生成模型" class="headerlink" title="对抗生成模型"></a>对抗生成模型</h3><p>给出一个由$n$个独立同分布的数据点组成的集合，它们服从$d$维分布$p(x)$。对抗模型的目标就是学习一个$q(x)$分布，该分布能精确接近 $p(x)$ 分布。生成对抗模型的架构是迫使$q(x)$生成真实的样本点。首先，学习一个将服从简单已知分布的样本（例如均匀或高斯分布）转换为接近$p(x)$的样本的模型，称之为生成器 <em>G</em> 。我们定义$q(x):&#x3D;G(\textbf{z})$，$\textbf{z}$服从（0,1）均匀分布。 <strong>这段话的意思就是说生成器的随机输入向量 z 服从均匀分布（也可以是高斯分布或者其他简单分布），我们的目标就是要通过生成器<em>G</em>的作用将其变为一个十分接近真实数据 <em>p(x)</em> 分布的分布 <em>q(x)</em> ，显然 <em>q(x)</em> 分布相对来说应该比 <em>z</em> 初始分布复杂得多。</strong>  其次，鉴别器的是将任何真实的$d$维向量作为输入，并且它能预测输入是否服从$p(x)$的概率。同时生成器也被训练以愚弄鉴别器。一开始，鉴别器能够很容易区别真假数据，但是随着训练的不断进行生成器采用来自鉴别器发出的信号决定如何生成更真实的数据。最终，生成器生成的数据太过逼真以至于鉴别器会对生成数据是否真实给出一个随意的猜测。以上就是 GAN的核心思想，虽然在本文中提到，但我再顺便回顾加深一下。</p><h4 id="使用GS分布"><a href="#使用GS分布" class="headerlink" title="使用GS分布"></a>使用<em>GS</em>分布</h4><p>G和D分别采用服从参数<em>Θ</em>和<em>Φ</em>的LSTM。目的是通过采样输入$x$和生成点$z$学习<em>G</em>和<em>D</em>，并且最小化<em>G</em>和<em>D</em>更新参数<em>Θ</em>和<em>Φ</em>的可微分的损失函数。不幸的是，采样生成点$z$对于隐藏态$h$是不可微的。所以需要使用公式（1.4）提出的策略。步骤在下面的算法中阐述，这个算法的目标是最小化$q(z)$和$p(x)$之间的KL散度。</p><h5 id="算法1：生成对抗网络"><a href="#算法1：生成对抗网络" class="headerlink" title="算法1：生成对抗网络"></a>算法1：生成对抗网络</h5><p>1：服从 $p(x)$ 分布的数据集 $\left\lbrace x_{1},\ldots x_{n} \right \rbrace$</p><p>2：生成器采用携带参数 <em>Θ</em> 的LSTM网络</p><p>3：鉴别器采用携带参数 <em>Φ</em> 的LSTM网络</p><p>4：一直循环迭代直到收敛</p><p>{</p><p style="text-indent:2em">4.1：小批量样本输入集*B*，*B*中样本个数为 *m* ，即  $\left \lbrace x_{B_{1}}, \ldots x_{B_{m}} \right \rbrace$</p><p style="text-indent:2em">4.2：样本噪声*N* :   $\left \lbrace z_{N_{1}}, \ldots z_{N_{m}} \right \rbrace$</p><p style="text-indent:2em">4.3：更新鉴别器参数 *Φ*</p><p style="text-indent:2em">4.4：更新生成器参数 *Θ* </p><p>}</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-3.png"></p><p align = 'center'>图 1.3 生成loss和判别loss的变化</p><p>上图是训练过程中生成损失和鉴别损失随迭代次数的变化。理想情况下鉴别器的损失应当提高而生成器的损失应当减小正如生成器在接近真实数据时表现得更好。（a）图是使用GS温度训练的神经网络。（b）图和前一张图设定一样但是将生成样本的大小扩大到1000，可以看到这张图中鉴别器的损失有小于生成器的损失了。(c) 图仅改变了输入向量温度值，可以看到生成器的损失在几乎所有迭代下是大于鉴别器的损失的。（d）只将随机噪声引入隐藏状态并且允许网络学习一个初始的细胞状态。</p><h4 id="学习一个CFG"><a href="#学习一个CFG" class="headerlink" title="学习一个CFG"></a>学习一个<em>CFG</em></h4><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-4.png"></p><p align = 'center'>图 1.4 MLE模型生成的结果</p><p>上图中第一幅图是MLE模型生成的文本。（a）到（d）对应实验部分第一张图的四个GAN模型生成文本的样例。每一行都是来自任意模型的样本，每一行包含12个特征（如果少于12个特征则用空格把缺少的特征补上）。我们将MLE LSTM作为GAN LSTM的参考。可以观察到，（a）图中第4,10,17行显示样本十分接近训练数据。</p><p>最后，作者认为结合最近GANs的进展，如使用变分散最小化训练GANs或通过密度比估计可以进一步的改善它。</p>]]></content>
    
    
    <categories>
      
      <category>文本生成</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GANs</tag>
      
      <tag>Gumbel-softmax分布</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读-对抗训练文本生成</title>
    <link href="/2018/01/21/Text-Generation-using-Generative-Adversarial-Training/"/>
    <url>/2018/01/21/Text-Generation-using-Generative-Adversarial-Training/</url>
    
    <content type="html"><![CDATA[<h2 id="论文名："><a href="#论文名：" class="headerlink" title="论文名："></a>论文名：</h2><p><em>Text Generation using Generative Adversarial Training</em></p><ul><li><p>LSTM初步学习</p></li><li><p>一种改进的GAN</p></li></ul><span id="more"></span><h3 id="Wasserstein-GANs"><a href="#Wasserstein-GANs" class="headerlink" title="Wasserstein GANs"></a>Wasserstein GANs</h3><p>由于原始GANs存在着训练困难、生成器和鉴别器的loss无法指示训练进程、生成样本缺乏多样性等问题，所以提出了WGANs的概念。它的优点有：彻底解决了GANs训练不稳定的问题；确保了生成样本的多样性；训练过程中有一个可以指示训练进程的数值；不需要精心设计的网络架构，最简单的多层全连接网络就可以做到。</p><p>实际上，对比原始GANs算法，WGANs做了如下改进：</p><ol><li><p>鉴别器最后一层不使用sigmoid激活函数</p></li><li><p>生成器和鉴别器的loss不取log</p></li><li><p>每次更新鉴别器的参数之后把它们的绝对值截断到不超过一个固定常数c</p></li><li><p>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</p></li></ol><h3 id="LSTMs"><a href="#LSTMs" class="headerlink" title="LSTMs"></a>LSTMs</h3><p><strong>LSTMs</strong>是一种特别的RNNs，比标准的 RNNs 在很多的任务上都表现得更好。</p><p>如果相关信息和当前预测位置之间的间隔不断增加得相当大，RNNs 会丧失学习到连接如此远的信息的能力。但是LSTMs并不存在这样的问题，它可以学习长期依赖信息。</p><p>LSTMs的核心是元胞，a它是一条穿过LSTMs图表的水平线。也可以将元胞理解为一条链，信息能够很容易流过这个链并且不发生大的改变。</p><p>LSTMs有能力对元胞添加或删除信息，这个行为由一个叫做“门”的结构来控制。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-1.png"></p><p>$$图1.1 \qquad LSTM元胞的门结构$$</p><p>上图称为LSTMs中称为“门”的结构，是一种让信息选择性通过的方法，它包含一个sigmoid神经网络层和一个pointwise乘法操作。</p><p>Sigmoid 层输出 0 到 1 之间的数值，描述每个部分有多少量可以通过。0代表“不许任何量通过”，1 就指“允许任意量通过”！一般情况下，LSTMs 拥有三个类似门，以保护和控制细胞状态。</p><h4 id="分布详解LSTM"><a href="#分布详解LSTM" class="headerlink" title="分布详解LSTM"></a>分布详解LSTM</h4><p>第一步是决定需要从元胞忽略掉什么样的信息，该决定由一个叫做“遗忘门”的sigmoid层控制。它观察$h_{t-1}$和$x_{t}$这两个值，并且对于元胞状态$C_{t-1}$中的每个数字输出一个介于01之间的值。1表示完全保留信息，0表示完全丢弃信息，即：</p><p>$f_{t}&#x3D;\sigma\left(W_{f} \cdot\left[h_{t-1}, x_{t}\right]+b_{f}\right) \tag{1.1}$</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-2.png"></p><p align = 'center'>图1.2</p><p>下一步是决定我们将会把哪些新信息存储到元胞状态中。这步分为两部分。首先，有一个叫做“输入门”的Sigmoid层决定我们要更新哪些信息。接下来，一个tanh层创造了一个新的候选值$\tilde{C}_{t}$。该值可能被加入到元胞状态中。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-3.png"></p><p align = 'center'>图1.3</p><p>$i_{t}&#x3D;\sigma\left(W_{i} \cdot\left[h_{t-1}, x_{t}\right]+b_{i}\right. \tag{1.2}$</p><p>$\tilde{C}<em>{t}&#x3D;\tanh \left(W</em>{C} \cdot\left[h_{t-1}, x_{t}\right]+b_{C}\right) \tag{1.3}$</p><p>第三步：</p><p>按照之前的决定，扔掉了旧的主语的性别信息，并且添加了新的信息。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-4.png"></p><p align = 'center'>图1.4</p><p>$C_{t}&#x3D;f_{t} * C_{t-1}+i_{t} * \tilde{C}_{t} \tag{1.4}$</p><p>最后一步，需要决定最终的输出。首先建立一个Sigmoid层的输出门，来决定我们将输出元胞的哪些部分。然后将元胞状态通过tanh之后（使得输出值在-1到1之间），与输出门相乘，这样只会输出我们想输出的部分。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-5.png"></p><p align = 'center'>图1.5</p><p>$o_{t}&#x3D;\sigma\left(W_{o}\left[h_{t-1}, x_{t}\right]+b_{o}\right) \tag{1.5}$</p><p>$h_{t}&#x3D;o_{t} * \tanh \left(C_{t}\right) \tag{1.6}$</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>基于RNN的模型已经被广泛应用于语言建模，机器翻译，语音识别和图像字幕等类似的生成任务中。<strong>RNNs最显著的能力是获取时间序列中的重要特征</strong>。(查阅资料知，时序数据是同一种现象在不同时间上的相继观察值排列而成的一组数字值序列，其时间轴上的采样值通常又被称为特征。一般情况下，对时序的特征提取是在分类前对数据时间采样值上进行适量的归约，以达到减少数据量同时提高分类准确率。而RNNs对于时序重要特征的提取十分方便。)</p><p>在生成好的RNNs模型中，来自前一时间步的单词被迭代到下一个时间步，但是，由于训练期间只有训练数据被模型看到，而且在优化过程中可能出现采样过程中的偏移，这会导致生成的句子在语法上有误。</p><p>论文提出的<strong>问题是通过GANs中的对抗训练策略是否会应用于文本的生成，抑或是改进文本的生成</strong>。作者研究了生成器和鉴别器的不同结构，并且最终会<strong>根据生成的文本来评估训练的得到的模型</strong>。</p><h3 id="需要做的工作"><a href="#需要做的工作" class="headerlink" title="需要做的工作"></a>需要做的工作</h3><p>GANs相比较其他深度生成模型具有一些优势，例如，与玻尔兹曼机（简称BM，是一种随机递归神经网络，其样本分布遵循玻尔兹曼分布。它由二值神经元构成，每个神经元只取0或1两种状态，1表示接通，0表示断开。）和非线性独立分量分析对比，GANs对生成器功能的限制较少，它不需要马尔科夫链。还有，变分自动编码器对模型的假设较弱，而GANs被设计为无偏的，最起码在视觉领域它生成的样本质量更好。</p><p>基于RNNs的语言模型可以获得长期的依赖关系。 使用门控循环单元（GRUs）作为发生器和鉴别器来训练GANs，与vanilla RNNs相比。由于图像数据是一堆像素的乘积，而文本生成本质上是离散的，因为文本是由一系列字词标点组成，这使得来自鉴别器的梯度难以反向传播到生成器。</p><p>现在提出了一种使用对抗目标训练RNNs的技术。对抗目标具有正则化效应，并且有助于RNNs训练的收敛。</p><p>SeqGANs将数据生成器建模为强化学习中的随机策略，奖励信号来自在完整序列上判断的鉴别器，并使用蒙特卡洛搜索传递到中间状态步骤。WGANs提供了严格的理论分析并且通过使用EM距离来提高GANs的表现。训练WGANs的优点是不需要对网络结构仔细设计的要求。我们的目标就是平衡生成器和鉴别器两者，防止他们一个压制另一个。</p><h3 id="具体方法"><a href="#具体方法" class="headerlink" title="具体方法"></a>具体方法</h3><h4 id="训练设置"><a href="#训练设置" class="headerlink" title="训练设置"></a>训练设置</h4><p>主要使用GRUs作为构建块，并使用vanilla RNNs作为比较。GRUs在计算上比LSTMs便宜，但在对序列建模中具有相当的性能。</p><p><strong>更新门</strong>：</p><p>$z_{t}&#x3D;\sigma\left(W_{t} x_{t}+U_{z} h_{t-1}\right) \tag{1.7}$</p><p><strong>重置门</strong>：</p><p>$r_{t}&#x3D;\sigma\left(W_{r} x_{t}+U_{r} h_{t-1}\right) \tag{1.8}$</p><p><strong>新记忆</strong>：</p><p>$\tilde{h}<em>{t}&#x3D;\tanh \left(r</em>{t} \circ U h_{t-1}+W x_{t}\right) \tag{1.9}$</p><p><strong>隐藏状态</strong>：</p><p>$h_{t}&#x3D;\left(1-z_{t}\right) \circ \tilde{h}<em>{t}+z</em>{t} \circ h_{t-1} \tag{2.0}$</p><p>在循环模型的每个时间步，网络从输入序列中取出$x_{t}$，并且从先前时间步的输出序列中取出$y_{t}$，然后更新隐藏态$h_{t}$作为之前隐藏态$h_{t-1}$以及$(x_{t},y_{t})$对的函数。然后计算一个以前面元素为先验条件的下一个元素的概率分布。通过在隐藏状态之上添加softmax层来生成离散输出。输出序列$Y$由生成器通过一个根据分布$P_{\theta_{g}}(y \mid x)$的输入序列$X$生成。</p><p>添加一个总结函数$B\left(x, y, \theta_{g}\right)$在生成器和输入嵌入的隐藏状态之上，并且该函数的输出是鉴别器的输入。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-6.png"></p><p align = 'center'>图1.6 G和D都为RNNs</p><p>上图的是一个生成器和鉴别器的结构都使用RNNs的GANs。$H$代表隐藏层。G中的$b$代表在隐藏状态上$B$的输出。而D中的$b$代表在$x$上的$B$和来自训练的$y$的输出。</p><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><p>当生成器的训练损耗低于一个明确的数值时，生成器的训练暂停，鉴别器的训练开始。反之，当鉴别器的训练损耗低于一个明确的值时，鉴别器的训练停止，生成器的训练开始。这一过程不断重复直到一批具有明确数量的时间戳到达。</p><p>在不同的实验背景下，生成器和鉴别器既可以由GRUs组成，也可以由RNNs组成。生成器和鉴别器拥有可比性的大小规模。鉴别器在隐藏层之顶有一个充分连接层，还有一个针对输出概率的sigmoid层。两者都通过<strong>Adam优化</strong>（Adam是一种可以替代传统随机梯度下降过程的一阶优化算法，它能基于训练数据迭代地更新神经网络权重。）以小批次随机梯度下降来训练。这些工作都在TensorFlow下完成。</p><h4 id="具体的实验"><a href="#具体的实验" class="headerlink" title="具体的实验"></a>具体的实验</h4><h5 id="有关数据集"><a href="#有关数据集" class="headerlink" title="有关数据集"></a>有关数据集</h5><p>预备的数据集包含2万到3万用来训练的单词，还有5万用来测试的单词。在数据集被分离前句子被随意混杂在一起。模型是单词-标准的模型。在预处理阶段，各种各样的标记被清除。</p><h5 id="超参数调整"><a href="#超参数调整" class="headerlink" title="超参数调整"></a>超参数调整</h5><p>如果G和D采用的是GRUs或者RNNs，那么这样的组合有4中情况：</p><table><thead><tr><th align="center">生成器</th><th align="center">结构</th><th align="center">判别器</th><th align="center">结构</th></tr></thead><tbody><tr><td align="center">G</td><td align="center">GRUs</td><td align="center">D</td><td align="center">GRUs</td></tr><tr><td align="center">G</td><td align="center">GRUs</td><td align="center">D</td><td align="center">RNNs</td></tr><tr><td align="center">G</td><td align="center">RNNs</td><td align="center">D</td><td align="center">RNNs</td></tr><tr><td align="center">G</td><td align="center">RNNs</td><td align="center">D</td><td align="center">GRUs</td></tr></tbody></table><p>如果加上不同的隐藏层的总层数或者总词汇大小，则类似的组合数会更多。可以从论文的Table1中看到这一结果。</p><p><strong>采用GRUs的结构总体上比采用RNNs的结构要表现得更好，而来自GANs的生成内容总体上比没有对抗训练表现得更好。在大批量的训练数据下，通过GANs方法的生成文本更加结构化。而如果隐藏层数非常少，那么这一现象表现得就不明显了。</strong></p><p>设定循环模型的层数固定为2.，batch size为50，序列长度为30。学习率开始时为0.02，并且以90%的衰减率不断减小。Adam策略决定了合适的学习率。生成器的损耗低于0.5时停止训练，而鉴别器的损耗低于0.3时就停止训练。所有的训练终止于50次epochs后。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-7.png"></p><p align = 'center'>图1.7</p><p>可以看到，有监督生成损失随着迭代次数的不断增加逐渐变小，个人猜测20000次以后趋于0.</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-8.png"></p><p align = 'center'>图1.8 生成器和鉴别器loss随迭代次数增长的变化</p><p>这是GANs中生成器和鉴别器随迭代次数增长的变化。可以看到，监督模型的训练接近收敛，不像我之前看到的第一幅图那样曲线呈下坡的样子。 GANs中鉴别器和发生器的损耗曲线由于损耗限幅而不太平滑。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这个项目中生成器和鉴别器都是循环的模型，并且生成器被一个通过监督学习训练过的模型初始化。通过GANs产生的文本具有合理的语法和逻辑性，这比没有对抗训练的情况要表现得好。</p><p>当前的训练集仍然很小对比生成文本来说，并且可以添加更多的超参数，最后，强化学习和WGANs可以被进一步研究以用于生成文本。</p>]]></content>
    
    
    <categories>
      
      <category>文本生成</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GANs</tag>
      
      <tag>零和博弈</tag>
      
      <tag>LSTMs</tag>
      
      <tag>GRUs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Skip-gram模型之训练理解</title>
    <link href="/2018/01/18/skip-gram-model/"/>
    <url>/2018/01/18/skip-gram-model/</url>
    
    <content type="html"><![CDATA[<p><strong>Skip-gram模型的训练步骤：</strong></p><p>训练样本的形式是（input word,output word），其中output word 是input word 的上下文。首先进行采样，剔除停用词等噪声因素。</p><span id="more"></span><ol><li><strong>首先要清洗数据</strong>。删除任何标点、数字，并将医疗文本拆分为单个单词。通过创建一个单词到int字典来将每个单词映射到int。</li><li>进行<strong>抽样</strong>，剔除高频的停用词来减少模型的噪音，并加速训练。通过以下公式来计算每个单词被剔除的概率大小：</li></ol><p>$P\left(w_{i}\right)&#x3D;1-\sqrt{\frac{t}{f\left(w_{i}\right)}} \tag{1.1}$</p><p>​其中，$f(w_{i})$代表单词$w_{i}$出现的频次，$t$代表阈值，介于1e-3到1e-5之间。</p><p>​通过计算每一个单词被删除的概率，并且基于概率进行采样，得到采样过的单词列表。</p><ol start="3"><li><p>设定<em>skip_window</em> &#x3D; 2，对于句子”He has been a cancer patient for about two months”。那么单词for的上下文就是[cancer, patient, about, two]。如果设定<em>batch_size</em> &#x3D; 1，则一个batch中包含4个训练样本，分别是[for, cancer], [for, patient], [for, about], [for, two]。</p><p>首先定义一个函数，它接收一个单词的索引号，然后根据这个索引号去查找单词表中对应的上下文。然后根据这些上下文构建<em>batch</em>。</p></li><li><p><strong>构建模型</strong>，采用负采样方式进行权重更新。通过以下公式得到每个单词被选为“negative words”的概率：</p></li></ol><p>$p\left(w_{i}\right)&#x3D;\frac{f\left(w_{i}\right)^{3 &#x2F; 4}}{\sum_{j&#x3D;0}^{n}\left(f\left(w_{j}\right)^{3 &#x2F; 4}\right)} \tag{1.2}$</p><p>​对于输入层到隐层的权重矩阵，设置<em>embeding_size</em>为300。最后Softmax的维度为词汇表大小乘以    <em>embedding_size</em>。</p><ol start="5"><li><strong>训练结束后保存模型</strong>。</li></ol>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>语言模型</tag>
      
      <tag>skip-gram</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Q学习算法探究及迷宫应用</title>
    <link href="/2017/12/25/q-xuexi-migong/"/>
    <url>/2017/12/25/q-xuexi-migong/</url>
    
    <content type="html"><![CDATA[<h3 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a><strong>摘要：</strong></h3><p>强化学习是一种不同于监督学习和无监督学习的学习技术，它将学习看成一个试探评估的过程。一般来说，一个智能体感知环境状态，并且采取某个action作用于环境，环境接受到这个action后再给出一个reward反馈给学习系统，智能体根据reward再判断下一个动作，如此进行下去。</p><p>Q-learning是强化学习的主要算法，它属于无模型的学习算法。它在博弈论，围棋，国际象棋等方面应用较广。</p><p>本文将首先介绍Q-learning算法的具体步骤，最后通过一个绵羊走迷宫的小例子来更直观地理解该算法,并且给出实现的代码。</p><p><strong>关键词：</strong> 强化学习； 无监督学习； Q-learning； 走迷宫</p><span id="more"></span><h4 id="1-Q-learning算法介绍"><a href="#1-Q-learning算法介绍" class="headerlink" title="1.  Q-learning算法介绍"></a><strong>1.  Q-learning算法介绍</strong></h4><p>强化学习领域一个最重要的突破就是一种叫做Q-learning的off-policy TD控制方法（SARSA方法是on-policy TD控制方法），它是由Watkins于1989年提出。它的最简单的形式，例如单步的Q-learning，被定义为如下：</p><p>$Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{i}\right)+\alpha\left[R_{t+1}+\gamma \max_{a} Q\left(S_{t+1}, a\right)-Q\left(S_{t}, A_{t}\right)\right] \tag{1.1}$</p><p>有的时候也被简写为(本篇后面的例子以这个公式为准)：</p><p>$Q(s, a)&#x3D;R(s, a)+\gamma \max _{a^{\prime}}\left\lbrace Q\left(s^{\prime}, a^{\prime} \right)\right \rbrace \tag{1.2}$</p><p>Q-Learning算法下，目标是达到目标状态(Goal State)并获取最高收益，一旦到达目标状态，最终收益保持不变。因此，目标状态又称之为吸收态。</p><p>Q-Learning算法下的agent，不知道整体的环境，知道当前状态下可以选择哪些动作。</p><p>通常，我们需要构建一个即时奖励矩阵<em>R</em>，用于表示从状态<em>s</em>到下一个状态<em>s’</em></p><p>的动作奖励值。由即时奖励矩阵<em>R</em>计算得出指导agent行动的<em>Q</em>矩阵。Q矩阵是agent的大脑。</p><p>初始时，Q矩阵元素全部初始化为0，表示当前的agent大脑一片空白，什么也不知道。具体算法步骤见下文：</p><p>任意初始化 $Q(s,a)$</p><p><em><strong>Repeat</strong></em>（对每个情节）：</p><p style="text-indent:4em">初始化 *s*</p><p style="text-indent:4em">***Repeat***（对情节的每一步）：</p><p style="text-indent:6em">用源自*Q*中的策略（例如$\varepsilon$ -greedy）在*s*中选择 *a*</p><p>​<p style="text-indent:6em">采用动作 <em>a</em>，观察<em>r</em>，<em>s’</em></p></p><p style="text-indent:6em">$Q(s, a)=R(s, a)+\gamma \max \lbrace Q(s^{\prime}, a^{\prime})\rbrace$</p><p>​<p style="text-indent:4em">$s \leftarrow s^{\prime}$</p></p><p><em><strong>Until</strong></em> <em>s</em>是终止状态</p><h5 id="具体步骤："><a href="#具体步骤：" class="headerlink" title="具体步骤："></a>具体步骤：</h5><ol><li>初始化Q-table矩阵</li><li>选择起始状态<em>s</em></li><li>选择当前状态<em>s</em>下的一个可能动作<em>a</em></li><li>选择动作<em>a​</em>后转移到下一个状态<em>s’</em></li><li>使用Bellman Equation（贝尔曼方程），更新Q-table</li><li>将下一个状态作为当前state，直到达到目标状态，一个episode结束</li><li>迭代尽可能无限多次episode，就可以得到最终收敛的Q矩阵了。</li></ol><p>Q-learning的核心是Q-table。Q-table的行和列分别表示state和action的值，Q-table的值 $Q(s,a)$衡量当前state采取action到底有多好。</p><h4 id="2-绵羊走迷宫"><a href="#2-绵羊走迷宫" class="headerlink" title="2.  绵羊走迷宫"></a><strong>2.  绵羊走迷宫</strong></h4><h5 id="2-1-初始条件"><a href="#2-1-初始条件" class="headerlink" title="2.1  初始条件"></a><strong>2.1  初始条件</strong></h5><p>这个例子描述了一个利用无监督训练学习未知环境的agent。现在假设一个迷宫有5个房间，房间之间通过门相连，将这五个房间按照从0至4进行编号，且迷宫的外围是一个大的房间（里面是草地），编号为5。因绵羊要吃草，设定5号房间为绵羊的目标房间。房间结构如下：</p><p><img src="/images/Q_learning/pic2_1.png"></p><p align = 'center'>图2.1 房间结构​</p><p>现在通过一个图来表示，用房间来表示节点，如果两个房间有门相连，那么两个节点之间对应一条边。如下图所示。</p><p><img src="/images/Q_learning/pic2_2.png"></p><p align = 'center'>图2.2 用直观图表示房间结构</p><p>接下来先将绵羊放在迷宫中的任意一个房间，然后从该房间开始走到目标房间（即5号房间）。接着为每一扇门（即对应的边）设定一个奖赏（reward）值。直接连接到5号房间的奖赏值为100，其他门的奖赏值为0。然后我们可以在每个箭头上表注权重，这个权重就是奖赏值。</p><p>值得留意的是5号房间有一个指向其本身的箭头，奖赏值为100，其他所有指向5号房间的奖赏值也为100。我们这个例子的目标是使绵羊达到奖赏值最大的状态，故而绵羊到达5号房间后将一直停在那里。</p><p>在这个例子中，我们将一个房间对应于一种<strong>状态</strong>，将绵羊从一个房间走到另外一个房间，即从一个状态达到另外一个状态称为一个<strong>行为。</strong></p><p>比如绵羊现在处于状态2，它可以转到状态0，但是不能转到状态1。</p><p>因此，同样地，我们有：</p><p>从状态0，只能转到状态4；从状态1，可以转到状态3或者状态5；从状态3，可以转到状态1和4，也可以转到状态2；从状态4，可以转到状态0,5或者3。</p><p>上面的内容都是这个实例的初始条件以及需要做的一些简要工作。接下来就是要将Q-learning算法应用于这个实例，我们将一步一步迭代几个episode。</p><h5 id="2-2-算法应用"><a href="#2-2-算法应用" class="headerlink" title="2.2 算法应用"></a><strong>2.2 算法应用</strong></h5><p>先令学习参数 $γ &#x3D; 0.8$，初始state为1号房间，如何将Q初始化为一个零矩阵。</p><p><img src="/images/Q_learning/pic2_3.png"></p><p align = 'center'>图2.3 初始化Q为一个零矩阵</p><p><img src="/images/Q_learning/pic2_4.png"></p><p align = 'center'>图2.4  奖赏矩阵</p><p>注意到矩阵R的第二行（state1），它有两个非负值，也就是说，状态1的下一步动作有两种选择：转向状态3或者状态5。此时我们选择状态5。假象绵羊位于状态5以后，观察R的第六行，它有三种可能的行为选择：转向状态1或4或5。由第一节的公式：</p><p>$Q(1,5)&#x3D;R(1,5)+0.8 * \max \lbrace Q(5,1), Q(5,4), Q(5,5) \rbrace &#x3D; 100 \tag{1.3}$</p><p>现在状态5变成了当前状态，而且达到了目标状态，完成了一次episode，矩阵Q也相应地更新了！</p><p><img src="/images/Q_learning/pic2_5.png"></p><p align = 'center'>图2.5  一次episode后的Q</p><p>接下来选取3为初始状态，它有转向1或2或4的三种动作选择。我们随机地选择转向状态1。而状态1有可能转向状态3或者5。由第一节公式：</p><p>$Q(3,1)&#x3D;R(3,1)+0.8 * \max \lbrace Q(1,3), Q(1,5)\rbrace &#x3D;80 \tag{1.4}$</p><p>同样地，刷新Q(3,1)。</p><p><img src="/images/Q_learning/pic2_6.png"></p><p align = 'center'>图2.6  刷新 Q(1,3)</p><p>由于状态1还不是目标状态，因此第二次episode还没有结束。现在在状态1，有两种动作选择：转向3或5。假定我们运气好，选择了状态5。由前面的分析，我们有：$Q(1,5) &#x3D; 100$。刷新矩阵Q，但是Q没有发生变化。第二次episode结束啦！</p><p>基于我们分析的两个episode过程的经验，还可以继续执行更多的episode。最终Q将收敛成如下一个矩阵：</p><p><img src="/images/Q_learning/pic2_7.png"></p><p align = 'center'>图2.7  最终的Q</p><p>最后对Q进行规范化，每个非零元素除以Q中最大的元素（这里省略了百分号）。</p><p><img src="/images/Q_learning/pic2_8.png"></p><p align = 'center'>图2.8  规范化后的Q</p><p>我们可以更改箭头的权重得到我们最终想要的图了：</p><p><img src="/images/Q_learning/pic2_9.png"></p><p align = 'center'>图2.9 最终得到的路径图</p><p>如果以3号房间为初始状态，根据Q表，reward最大的路径是3-﹥1-﹥5或者3-﹥4-﹥5，总的reward都为100。</p><p>总结一下，这个例子是Q-learning算法的简单应用。事实上，实际中的情况要更加复杂，例如可能是两个，三个甚至多个绵羊。本例中我们简化了奖赏矩阵R，实际上那些奖赏设为0的奖赏可以为其他大于0的数，为了方便计算，故而将它们设为0。</p><h5 id="2-3-代码实现"><a href="#2-3-代码实现" class="headerlink" title="2.3 代码实现"></a><strong>2.3 代码实现</strong></h5><p><strong>2.3.1 首先训练数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 学习率</span><br>rate = <span class="hljs-number">0.8</span><br><br><span class="hljs-comment"># 初始化Q矩阵为零矩阵并初始化奖赏矩阵R</span><br>q = np.zeros((<span class="hljs-number">6</span>, <span class="hljs-number">6</span>))<br>q = np.matrix(q)<br><br>r = np.array([[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">100</span>], <br>[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], <br>[<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">100</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">100</span>]])<br>r = np.matrix(r)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br><span class="hljs-comment"># 随机选取一个初始状态</span><br>state = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>)<br><span class="hljs-comment"># state不能为目标状态</span><br><span class="hljs-keyword">while</span> state != <span class="hljs-number">5</span>:<br><span class="hljs-comment"># 选取r表中第state行非负的值</span><br>r_pos_action = []<br><span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>            <span class="hljs-keyword">if</span> r[state, action] &gt;= <span class="hljs-number">0</span>:<br>next_state = r_pos_action[random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(r_pos_action)-<span class="hljs-number">1</span>)]<br>q[state, next_state] = r[state, next_state] + rate*q[next_state].<span class="hljs-built_in">max</span>()<br>state = next_state<br><br><span class="hljs-built_in">print</span>(q)<br></code></pre></td></tr></table></figure><p><strong>下图是训练好的<em>Q</em>表（最终<em>Q</em>表收敛）</strong></p><p><img src="/images/Q_learning/pic2_11.png"></p><p align = 'center'>图2.10</p><p><strong>2.3.2 再根据<em>Q</em>表进行路径选择</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第&#123;&#125;次验证&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br><br>state = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;绵羊处于状态&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(state))<br>count = <span class="hljs-number">0</span><br><span class="hljs-keyword">while</span> state != <span class="hljs-number">5</span>:<br><span class="hljs-keyword">if</span> count &gt; <span class="hljs-number">20</span>:<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;fail&#x27;</span>)<br><span class="hljs-keyword">break</span><br><span class="hljs-comment"># 选择最大的q_max</span><br>q_max = q[state].<span class="hljs-built_in">max</span>()<br><br>q_max_action = []<br><span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br><span class="hljs-keyword">if</span> q[state, action] == q_max:<br>q_max_action.append(action)<br><br>next_state = q_max_action[random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(q_max_action) - <span class="hljs-number">1</span>)]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;the sheep goes to &quot;</span> + <span class="hljs-built_in">str</span>(next_state) + <span class="hljs-string">&#x27;.&#x27;</span>)<br>state = next_state<br>count += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>2.3.3 选择后的结果</strong></p><p><img src="/images/Q_learning/pic2_13.png"></p><p align = 'center'>图2.11</p><h4 id="3-总结与反思"><a href="#3-总结与反思" class="headerlink" title="3.  总结与反思"></a><strong>3.  总结与反思</strong></h4><p>本篇小论文首先简单介绍了Q-learning算法，再通过一个小例子实现了该算法的简单应用。我们通过1000多次训练数据使得Q表收敛，接着再验证我们的训练结果。事实上，Q-learning算法是一种off-policy TD 控制算法，与之相对的是Sarsa算法，一种on-policy TD控制算法，它是基于每一步一个总结，探索时较为“保守”，与之相对的则是Q-learning较为“勇敢”。</p><p>但是，Q-learning也存在着学习时间过长、收敛速度慢的缺陷的特征。但是可以通过从环境中提取特征，借助人的经验和问题的背景知识可以很好的设计启发函数并融入到强化学习中，提高算法的学习效率，加快算法的收敛，可以改进智能体从环境中学习知识的能力，最后再进行仿真验证即可。</p><h4 id="4-相关应用"><a href="#4-相关应用" class="headerlink" title="4.  相关应用"></a><strong>4.  相关应用</strong></h4><p>近年来，该算法应用也较为广泛，主要是基于博弈论方面的，例如：围棋，国际象棋等。比方说，我们可以在上下文老虎机问题中利用Q函数学习过的代理预估长期在特定行为的值。</p><p>Q-Learning算法从90年代被提出至今，它已经历了一系列重大的改进，Q学习可被应用于更加多变的动态场景中。例如与神经网络的结合，Deepmind的深度Q网络的一个主要示例，就是用于学习直接从像素中进行几十种不同的ATARI游戏，像这里仅用一个查找表根本不可能实现的壮举。为了实现这个目标，他们用到了一个由Deep Neural Network(DNN)网络控制的代理。通过神经网络，它可以学习将广义Q函数应用于完全不可见的状态，例如显示器上少见的像素组合。</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>强化学习</tag>
      
      <tag>Q学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
