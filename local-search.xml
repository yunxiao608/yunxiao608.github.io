<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>echarts解决多个图层缩放拖拽不同步问题</title>
    <link href="/2024/10/19/2024-10-19-03/"/>
    <url>/2024/10/19/2024-10-19-03/</url>
    
    <content type="html"><![CDATA[<p>添加如下代码：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs js">myChart.<span class="hljs-title function_">on</span>(<span class="hljs-string">&quot;georoam&quot;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">params</span>) &#123;<br>                    <span class="hljs-keyword">var</span> option = myChart.<span class="hljs-title function_">getOption</span>(); <span class="hljs-comment">//获得option对象</span><br>                    <span class="hljs-keyword">if</span> (params.<span class="hljs-property">zoom</span> != <span class="hljs-literal">null</span> &amp;&amp; params.<span class="hljs-property">zoom</span> != <span class="hljs-literal">undefined</span>) &#123;<br>                        <span class="hljs-comment">//捕捉到缩放时</span><br>                        option.<span class="hljs-property">geo</span>[<span class="hljs-number">0</span>].<span class="hljs-property">zoom</span> = option.<span class="hljs-property">series</span>[<span class="hljs-number">0</span>].<span class="hljs-property">zoom</span>; <span class="hljs-comment">//下层geo的缩放等级跟着上层的geo一起改变</span><br>                        option.<span class="hljs-property">geo</span>[<span class="hljs-number">0</span>].<span class="hljs-property">center</span> = option.<span class="hljs-property">series</span>[<span class="hljs-number">0</span>].<span class="hljs-property">center</span>; <span class="hljs-comment">//下层的geo的中心位置随着上层geo一起改变</span><br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-comment">//捕捉到拖曳时</span><br>                        option.<span class="hljs-property">geo</span>[<span class="hljs-number">0</span>].<span class="hljs-property">center</span> = option.<span class="hljs-property">series</span>[<span class="hljs-number">0</span>].<span class="hljs-property">center</span>; <span class="hljs-comment">//下层的geo的中心位置随着上层geo一起改变</span><br>                    &#125;<br>                    <span class="hljs-comment">// myChart.dispatchAction(&#123; //来用程序主动渲染选框</span><br>                    <span class="hljs-comment">//     type: &quot;restore&quot;,</span><br>                    <span class="hljs-comment">// &#125;);</span><br>                    myChart.<span class="hljs-title function_">setOption</span>(option); <span class="hljs-comment">//设置option</span><br>                &#125;);<br></code></pre></td></tr></table></figure><p>所有层记得加上 <code>animationDurationUpdate: 0</code></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>QT之qint64转int</title>
    <link href="/2024/10/19/2024-10-19-02/"/>
    <url>/2024/10/19/2024-10-19-02/</url>
    
    <content type="html"><![CDATA[<p>qint64与int进行数值比较时，如果不转换，编译器会发出警告。</p><p>解决办法是：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 从qint64 位转为 int类型</span><br>intValue = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">int</span>&gt;(qint64Value);<br></code></pre></td></tr></table></figure><p>或者：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 从int转为qint64类型</span><br>qint64Value = <span class="hljs-built_in">static_cast</span>&lt;qint64&gt;(intValue);<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>echarts字体模糊问题</title>
    <link href="/2024/10/19/2024-10-19-01/"/>
    <url>/2024/10/19/2024-10-19-01/</url>
    
    <content type="html"><![CDATA[<h3 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a>方法一：</h3><p>采用svg渲染，比canvans清晰度高</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-variable language_">this</span>.<span class="hljs-property">chart</span> = <span class="hljs-variable language_">this</span>.<span class="hljs-property">$echarts</span>.<span class="hljs-title function_">init</span>(<span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;id&#x27;</span>), <span class="hljs-literal">null</span>, &#123;<span class="hljs-attr">renderer</span>: <span class="hljs-string">&#x27;svg&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><h3 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h3><p>采用canvans渲染，devicePixelRatio调整清晰度</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-variable language_">this</span>.<span class="hljs-property">chart</span> = <span class="hljs-variable language_">this</span>.<span class="hljs-property">$echarts</span>.<span class="hljs-title function_">init</span>(<span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;id&#x27;</span>), <span class="hljs-literal">null</span>, &#123;<span class="hljs-attr">devicePixelRatio</span>: <span class="hljs-number">2.5</span>&#125;)<br></code></pre></td></tr></table></figure><p>建议使用方法二，在echart初始化的时候调节devicePixelRatio参数</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>出国一定能涨见识吗？</title>
    <link href="/2024/10/18/2024-10-19-04/"/>
    <url>/2024/10/18/2024-10-19-04/</url>
    
    <content type="html"><![CDATA[<p>本文的结论是：出国可能会涨见识，但也有可能会固化原生思维，甚至变得更蠢。</p><p>最近，朋友圈刮起了一股出国风，有鉴于此，我决定写一篇短文来阐述个人观点。  </p><p>在网上，一直有一种盛行观点：“欧洲大城市的高楼大厦不如国内”。提出并且认可这类观点的人，有不少是出过国的人，尤其有过欧洲游学经历的人。类似的，还有“台北的基建只相当于大陆三线城市”这种观点。</p><p>他们说的对吗？我没有去过欧洲，但我想，他们是对的，毕竟眼见为实嘛。</p><p>但是，这些见闻暗含了一个预设观念，也就是把发达和高楼大厦强行联系起来。</p><p>事实真的如此吗？</p><p>显然不是，关于这点，我不想阐述太多，只想说，世界上有两类发达国家，一种是基建型国家，例如日本、韩国、新加坡等国。一种是古典型发达国家，欧洲的大多数国家属于此类。</p><p>将发达与高楼大厦关联起来的人，不仅包括一些巨婴型暴发户（在机场大吵大闹），还包括很多高知分子。</p><p>而且，我普遍发现，<strong>由于强省会模式在国内是主流模式，这就造成了很多国人对于大城市之迷之向往。这种向往表现在，出国游玩要去大城市，去江苏游玩要去苏南。</strong></p><p>大城市病，源于根深蒂固的攀比心理和优绩主义、排名主义影响。而这种思维，只会让一个人错过很多。</p><p>想了解真正的中国，不应该只去北上广深、江浙沪，而应该去山河四省、中西部广大地区。</p><p>在世界上，笔者以西班牙为例，很多人想到的大城市是马德里和巴塞罗那。</p><p>历史上，伊比利亚半岛王国林立，形成了多个基督教王国和哈里发王国，这些王国的国都，尤其是格拉纳达、科尔多瓦、托莱多等城市，历史底蕴丝毫不逊色于马德里。</p><p>西班牙、德国在欧洲各国里属于散装模式，这一点和江苏比较相似。</p><p>象征西班牙穆斯林文化的地标—阿尔罕布拉宫就在格拉纳达。</p><p>中世纪欧洲四大名校—萨拉曼卡大学，在该国西部的萨拉曼卡古城。</p><img title="" src="file:///images/1.jpg" alt="@" data-align="center"><p>科尔多瓦是中世纪欧洲的学术中心，古希腊经典教义在这里被翻译，传播到欧洲各地 。</p><p>基督教三大朝圣地之一的圣地亚哥德孔波斯特拉，位于该国西北部。这座城市不太为中国人所熟知，但每年有成千上万的人延续中世纪古老的传统，徒步跋涉，风餐露宿，来此朝圣。</p><p>因此，文章开头提到的那些人，看到的只是事物的表象，而忽视了深度思考，到底什么能代表发达？发达和文化就一定强关联吗？</p><p>今天去西安旅游的人一定比去洛阳开封的人多。是洛阳开封比西安缺乏历史底蕴吗？显然不是。</p><p>所以国人旅游一般是买买买吃吃吃，哪里火去哪儿，很难做到深刻。他们所谓的“见世面”，不过是见识一下车水马龙和高楼大厦，再加几个地标罢了。还记得香港特区官方给大陆游客的建议：别光顾着消费，多关注一下香港当地的文化理念和内核。</p><p>另外，是否能说明，没出过国就不深刻，写不出好的作品？</p><p>《堂吉诃德》的译者杨绛老先生，50年代自学西班牙语，翻译了首版《堂吉诃德》，在这本书出版前，她未曾踏上过西班牙的国土。改开之初，胡安.卡洛斯国王访华，给她颁布奖章。</p><p>海外汉学家，尤其是史景迁、魏斐德、孔飞力等人，能写出比国内历史学者还要好的作品。是因为他们常居中国吗？显然不是。思维方式，独到的视角，比看多少书，见多少世面更有意义，人类文明的进步向来如此。</p><p>古人讲，读万卷书，行万里路，和今天的“世界那么大，我想去看看”，道理差不多。</p><p>如果不能深入了解当地的历史人文，目之所及之处，有如走马观花一般，这样的旅游，往往很累很空洞。别说出国游了，就是在国内，在博物馆里，拿着一副放大镜卖弄，附庸风雅，其实内心毫无笔墨。</p><p>当然，这种“做作”比那些炫富式出游还是“高雅”一些。</p><p>所以，不妨问问自己，貌似看了“很多”书，貌似去过“很多”地方，但自己怎么还是很“无知”呢？</p><hr><p>个人观点，仅供参考</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>旅游</tag>
      
      <tag>欧洲</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>贫穷、落后与萧条—康有为笔下的西班牙</title>
    <link href="/2023/10/08/2023-10-08/"/>
    <url>/2023/10/08/2023-10-08/</url>
    
    <content type="html"><![CDATA[<p>戊戌变法失败后，康、梁二人纷纷逃亡海外避难。趁此机会，康有为携家小游历了欧美各国，包括那些稍偏僻的国家，例如墨西哥、罗马尼亚、西班牙、葡萄牙、希腊等国。1907年康氏旅欧期间，留下了丰富的游记资料，这是近代中国思想家开眼看世界、救亡图存的明证。</p><p>从康氏笔下，我们也能了解到中外社会状况的对比。当时的欧美，并不都是想当然的清一色富国。例如，康从法国南部进入西班牙，看到的市井百态，认为其萧瑟状与华北同。当他到达西班牙首都马德里时，感慨其街道偏狭，多盗贼乞丐，市面污淖不堪，甚于意大利。这是一百年前的南欧社会，一百年后的南欧，与西北欧相比，这种<strong>扒手现象</strong>似乎也没有随着这些国家民主化工业化而得到有效解决。</p><p>同时，康也认识到，西葡离英法德等先进国家并不遥远，政令制度均效法之，却民困国穷，与中国殊同状类，不禁质疑民主共和是否适合于每一个国家？当然，康本身是个保皇派，幻想在中国实行君主立宪制，把希望寄托在没有实权的光绪帝身上，这就注定了维新的悲剧命运。1917年，他又支持张勋的辫子军，复辟紫禁城中的溥仪小朝廷，闹出了一幕又一幕的政治笑话。  </p><p>当然，康有为自有其时代的局限性，这种局限性连国学大师王国维、辜鸿铭都未能幸免。康认为，建立了民主制度的西葡墨三国，也不能免于民穷国颓的下场，便质疑民主共和的合理性，主张在中国恢复礼教旧秩序。这种观点，和今人认为的：苏东巨变后，东欧各国采用休克疗法，建立自由主义市场，却经济凋敝失业攀升；南美各国采用资本主义制度却走不出中等收入陷阱的观点，有异曲同工之处，那就是民主和自由市场不是万能药。答案是否真的如此？列位看官还需多读书多观察多辨析以明理，不可人云亦云也。  </p><p>康的西班牙游记中也包括了对西国自然风光和公共设施（银行、博物馆、政府大楼、皇宫）的描写，我这里侧重于对于西国世间百态的分析。在晚清的外交文献中，对于西班牙，常以大日国（日斯巴尼亚）或大吕宋（小吕宋指菲律宾）呼之。康的游记中则以班国称之。近代以降，晚清官员常艳羡英法德美等列强之富庶强大，船坚炮利，以至于很多人患有“恐洋症结”，对于那些边缘西方国家却毫无了解，以至于闹出“西班有牙,葡萄有牙,牙而成国,史所未闻”的笑话。所幸，康有为通过实际行动复原了这些边缘弱国在100年前的情况。</p><p>康旅居西班牙期间，主要游历了马德里、托莱多、塞维利亚三城。一年前，西班牙病理学家卡哈尔获得诺贝尔医学奖。九年前，西军在美西战争中败北，失去了古巴、菲律宾和波多黎各，被打回欧洲三流国家。话不多说，下面我将列举几个镜头，来呈现这种欧美边缘弱国的衰颓场景。  </p><h2 id="一、盗匪横生"><a href="#一、盗匪横生" class="headerlink" title="一、盗匪横生"></a>一、盗匪横生</h2><blockquote><p>旁舱客多如盗如丐，恶臭蒸熏。巡警数人，处处相随，持枪巡视，似警盗然。买酒支夜，益不敢寐。与家人拥足喂寒，终不能噤。旁客来往无常，有时无人，则巡警亦复可畏。幸竞夕月明，越山过野，景皆绝佳，足以消遣。既而审知班境多盗，常劫盗汽车中客物，故汽车中常派警吏持枪相从，有时并警吏亦被杀也。此夕千馀里荒山，其劫盗亦固其所，即大市密乡，汽车亦常见此事，班、葡交界处尤甚。</p></blockquote><p>评：乘客多像乞丐，车厢内恶臭熏天。车里扒手甚多，晚间不敢睡觉。车内多派警察维持治安，有时警察也会被劫匪偷袭杀害。如果没有其他乘客，觉得巡警都挺让人害怕，担心自己的财物。</p><blockquote><p>至下站遂行。响导者曰：在班、葡间多盗，有金银首饰宜别寄，否亦不可少露，行李上下宜戒慎，深夕尤宜检点，不宜熟寐，游班、葡者不可不知也。吾行遍欧美数巡，未闻有劫盗事，不意来班而闻此，班与诸欧比邻，政治皆同，民权立宪无异，而民贫多劫盗，行李多警，人视为畏途乃若此也。</p></blockquote><p>评：康去过欧美很多发达国家，从来没听说过劫盗之事，没想到在西葡竟是常态，可见治安之差，百姓甚穷。一百年前的西葡类似于今天的中美洲和东南亚。</p><h2 id="二、乞丐遍地"><a href="#二、乞丐遍地" class="headerlink" title="二、乞丐遍地"></a>二、乞丐遍地</h2><blockquote><p>马车驰间时丐者已遍地，随车行乞，上车、下车、出门、行路，无在非丐者攘臂低颜求乞之时，稍有所施，则塞门墐路不得行。其在中午，或在广场，或在游观要地，乞者连环百十，或高或下，或老或少，或男或女，跛者瞥者，逐车拦路而乞，施钱尽而不及给，或施不均则谩骂，必待御者探之以鞭乃去。吾昔游意大利讶其多丐，今游班益骇其多丐，比吾京师有过之。岂几旧国新政末行，机器未行，养民无术。其必不能免于此乎！班与德、英不远，观感至易，而绝不知采其政法，民无以为养，乃多堕为盗丐，亦可哀夫！同为欧民，苦乐何远也。</p></blockquote><p>评：遍地的乞丐，拥堵不得行。西班牙的乞丐数量甚于意大利，马德里的乞丐比北平还多。作者感慨西班牙对不起他欧洲国家的身份。同样是白人国家，为何相差那么远。</p><h2 id="三、市井萧条"><a href="#三、市井萧条" class="headerlink" title="三、市井萧条"></a>三、市井萧条</h2><blockquote><p>行百里，至素乌拉加市。班人屋虽四五层，甚污陋，白灰平直，无他饰，污乱触目，有极似中国北方者。瓦旧坏不堪，屋脊金字形，且泥砖，夹路以石。与欧北相比，有若天渊，但甫入其境游其野，而班之贫弱不治已可窥其概矣。</p></blockquote><p>评：西班牙的建筑低矮简陋，像华北一样，与西北欧相比，简直天上地下，感慨其贫穷不治。这和近代欧美旅行家们从法国南部进入西班牙所见大体类似，西班牙与欧洲差了二百年，社会结构仿佛还停留在中世纪。</p><blockquote><p>十六日早六时，至西班牙京马得理。停车场即在王宫前，御园旁扫夫若丐，执帚而扫街道。马车小而劣，街道狭而污，砌以小石，荤确殊甚。屋三四层，白灰方乎，无刻饰，道狭仅丈许，最广者亦仅二三丈。时有敞地立石像喷池者，亦复湫隘。客店皆偏小，且无炉。行遍数大街，遍入最大客店数处，吾暗其规模之小，街道之狭，皆以为偏僻之所，不欲止焉。</p></blockquote><p>评：作者到达马德里。御花园的清洁工像乞丐一样。街道狭小脏乱，客店规模不大。印象极差。</p><h2 id="四、美食之乡"><a href="#四、美食之乡" class="headerlink" title="四、美食之乡"></a>四、美食之乡</h2><blockquote><p>惟烹调颇美，能合数味为之，甚似中国。班、葡皆然，直有过于法焉。不知班师法耶？法师班耶？以文明之先后考之，班先觅新地，先开文明，法在其后。吾游遍大地，惟中国烹饪冠绝万国，大地各国皆不得其术，法国何以能产此，计必自葡萄牙得澳门而传中国饮食之法。吾观班、法之切卵为四块，又食生菜与其他调味，多类中国。葡人好茶,呼茶为茶本音，其饮食之味又同中国，故可推而得其祖所自出。吾常谓中国饮食之美，必混地球，今益信也。葡、班饮食本美，今欧美人盛称法，而不大称班、葡者，以国弱不显故耳。</p></blockquote><p>评：西人葡人善于烹调，和中国很像，均是美食大国。似乎拉丁民系皆有享受生活的特征。西餐三大菜就是法国蜗牛，西班牙海鲜饭，意大利面。这三个国家都是拉丁语国家，相反，英、德菜略显黯然。</p><h2 id="五、尊师重教"><a href="#五、尊师重教" class="headerlink" title="五、尊师重教"></a>五、尊师重教</h2><blockquote><p>班于尊师重士，有与中国同者二焉。学生三干人，教授百有四人，学科与英、德同。讲堂有数百坐，盖用方蓝花。人天文历算室，仪器颇多，学生皆无住舍，与德同。</p></blockquote><p>评：西班牙是个天主教保守到极点的欧洲国家，当时还未能实现政教分离。类似于中国的儒家对世俗的干预。因此康有为找到了共同之处，认为班国和中土一样尊师重教。</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>旅游</tag>
      
      <tag>欧洲</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>echarts使用中的跨域问题</title>
    <link href="/2020/12/11/echart-question-all/"/>
    <url>/2020/12/11/echart-question-all/</url>
    
    <content type="html"><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在运行Les-Miserables示例时，出现了浏览器一直<em>loading</em>不显示图表的问题。折腾了一天半，终于解决了问题的一般，为什么是一半呢？且听我娓娓道来。</p><span id="more"></span><h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><p>根据 <a href="https://segmentfault.com/a/1190000022173139">博客1</a> 的经验：</p><ul><li>引入工具包</li></ul><p>需要三个工具包，<strong>echarts、jquery、dataTool</strong>。前两个直接通过<strong>cdn</strong>引入即可，dataTool则去github上面复制下来自己新建一个即可。<br><code>dataTool.min.js</code>下载网址：(<a href="https://github.com/apache/incubator-echarts/blob/master/dist/extension/dataTool.min.js)%EF%BC%8C%E4%B8%8B%E8%BD%BD%E5%AE%8C%E5%90%8E%E5%B0%86%60dataTool.min.js%60%E6%94%BE%E5%9C%A8%60js%60%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E3%80%82">https://github.com/apache/incubator-echarts/blob/master/dist/extension/dataTool.min.js)，下载完后将`dataTool.min.js`放在`js`文件夹下。</a></p><p><code>test.html</code>中引用上述工具包代码如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">&lt;!-- 三个工具包缺一不可 --&gt;<br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.bootcss.com/echarts/4.1.0.rc2/echarts.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span> <br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span><br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;js/dataTool.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span>   <br></code></pre></td></tr></table></figure><ul><li>引入<code>les_miserables.gexf</code>数据文件</li></ul><p>该文件的在线url：<a href="https://www.echartsjs.com/examples/data/asset/data/les-miserables.gexf">https://www.echartsjs.com/examples/data/asset/data/les-miserables.gexf</a></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">$.<span class="hljs-title function_">get</span>(<span class="hljs-string">&#x27;在线url&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">xml</span>) <span class="hljs-comment">// url为les_miserables.gexf在线路径</span><br></code></pre></td></tr></table></figure><ul><li>完整代码</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><code class="hljs javascript">&lt;!<span class="hljs-variable constant_">DOCTYPE</span> html&gt;<br><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span></span><br><span class="language-xml">    <span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="language-xml">        <span class="hljs-comment">&lt;!-- 三个工具包缺一不可 --&gt;</span></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.bootcss.com/echarts/4.1.0.rc2/echarts.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span> </span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;js/dataTool.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>                                         </span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Les Miserables<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span></span><br><span class="language-xml">    <span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span></span><br><span class="language-xml">    <span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span></span><br><span class="language-xml"></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;main&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width: 1000px;height: 1000px;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span><br><span class="language-xml"></span><br><span class="language-xml">        <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text/javascript&quot;</span>&gt;</span><span class="language-javascript"></span></span><br><span class="language-javascript"><span class="language-xml">                    <span class="hljs-comment">// 基于准备好的dom，初始化echarts实例</span></span></span><br><span class="language-javascript"><span class="language-xml">                    <span class="hljs-keyword">var</span> myChart = echarts.<span class="hljs-title function_">init</span>(<span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;main&#x27;</span>));</span></span><br><span class="language-javascript"><span class="language-xml">                    <span class="hljs-keyword">var</span> option;</span></span><br><span class="language-javascript"><span class="language-xml">                    myChart.<span class="hljs-title function_">showLoading</span>();</span></span><br><span class="language-javascript"><span class="language-xml"></span></span><br><span class="language-javascript"><span class="language-xml">                    $.<span class="hljs-title function_">get</span>(<span class="hljs-string">&#x27;https://www.echartsjs.com/examples/data/asset/data/les-miserables.gexf&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">xml</span>) &#123;   <span class="hljs-comment">//读取本地文件</span></span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">&#x27;读取到数据文件&#x27;</span>) </span></span><br><span class="language-javascript"><span class="language-xml">                        myChart.<span class="hljs-title function_">hideLoading</span>();</span></span><br><span class="language-javascript"><span class="language-xml"></span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-keyword">var</span> graph = echarts.<span class="hljs-property">dataTool</span>.<span class="hljs-property">gexf</span>.<span class="hljs-title function_">parse</span>(xml);</span></span><br><span class="language-javascript"><span class="language-xml"></span></span><br><span class="language-javascript"><span class="language-xml"></span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-keyword">var</span> categories = [];</span></span><br><span class="language-javascript"><span class="language-xml">                        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span>; i++) &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                            categories[i] = &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;类目&#x27;</span> + i</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;;</span></span><br><span class="language-javascript"><span class="language-xml">                        &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                        graph.<span class="hljs-property">nodes</span>.<span class="hljs-title function_">forEach</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params">node</span>) &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">itemStyle</span> = <span class="hljs-literal">null</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">value</span> = node.<span class="hljs-property">symbolSize</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">symbolSize</span> /= <span class="hljs-number">1.5</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">label</span> = &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">normal</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">show</span>: node.<span class="hljs-property">symbolSize</span> &gt; <span class="hljs-number">30</span></span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;;</span></span><br><span class="language-javascript"><span class="language-xml">                            node.<span class="hljs-property">category</span> = node.<span class="hljs-property">attributes</span>.<span class="hljs-property">modularity_class</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                        &#125;);</span></span><br><span class="language-javascript"><span class="language-xml">                        option = &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">title</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">text</span>: <span class="hljs-string">&#x27;Les Miserables&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">subtext</span>: <span class="hljs-string">&#x27;Default layout&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">top</span>: <span class="hljs-string">&#x27;bottom&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">left</span>: <span class="hljs-string">&#x27;right&#x27;</span></span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">tooltip</span>: &#123;&#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">legend</span>: [&#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-comment">// selectedMode: &#x27;single&#x27;,</span></span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">data</span>: categories.<span class="hljs-title function_">map</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params">a</span>) &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-keyword">return</span> a.<span class="hljs-property">name</span>;</span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;)</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;],</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">animationDuration</span>: <span class="hljs-number">1500</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">animationEasingUpdate</span>: <span class="hljs-string">&#x27;quinticInOut&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                            <span class="hljs-attr">series</span>: [&#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;Les Miserables&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">type</span>: <span class="hljs-string">&#x27;graph&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">layout</span>: <span class="hljs-string">&#x27;none&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">data</span>: graph.<span class="hljs-property">nodes</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">links</span>: graph.<span class="hljs-property">links</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">categories</span>: categories,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">roam</span>: <span class="hljs-literal">true</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">focusNodeAdjacency</span>: <span class="hljs-literal">true</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">itemStyle</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">normal</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">borderColor</span>: <span class="hljs-string">&#x27;#fff&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">borderWidth</span>: <span class="hljs-number">1</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">shadowBlur</span>: <span class="hljs-number">10</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">shadowColor</span>: <span class="hljs-string">&#x27;rgba(0, 0, 0, 0.3)&#x27;</span></span></span><br><span class="language-javascript"><span class="language-xml">                                    &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">label</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">position</span>: <span class="hljs-string">&#x27;right&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">formatter</span>: <span class="hljs-string">&#x27;&#123;b&#125;&#x27;</span></span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">lineStyle</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">color</span>: <span class="hljs-string">&#x27;source&#x27;</span>,</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">curveness</span>: <span class="hljs-number">0.3</span></span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;,</span></span><br><span class="language-javascript"><span class="language-xml">                                <span class="hljs-attr">emphasis</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                    <span class="hljs-attr">lineStyle</span>: &#123;</span></span><br><span class="language-javascript"><span class="language-xml">                                        <span class="hljs-attr">width</span>: <span class="hljs-number">10</span></span></span><br><span class="language-javascript"><span class="language-xml">                                    &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                                &#125;</span></span><br><span class="language-javascript"><span class="language-xml">                            &#125;]</span></span><br><span class="language-javascript"><span class="language-xml">                        &#125;;</span></span><br><span class="language-javascript"><span class="language-xml"></span></span><br><span class="language-javascript"><span class="language-xml">                        myChart.<span class="hljs-title function_">setOption</span>(option);</span></span><br><span class="language-javascript"><span class="language-xml">                    &#125;, <span class="hljs-string">&#x27;xml&#x27;</span>);</span></span><br><span class="language-javascript"><span class="language-xml"></span></span><br><span class="language-javascript"><span class="language-xml">                </span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></span><br><span class="language-xml"></span><br><span class="language-xml">    <span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span></span><br><span class="language-xml"><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span></span><br></code></pre></td></tr></table></figure><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>但是按照上述方法还是会出现浏览器一直<em>loading</em>无法显示图标的问题。表现在：</p><p>引用在线的<code>les_miserables.gexf</code>文件的url，图表可以在IE浏览器中正常显示，但是在谷歌和火狐浏览器中则一直加载不出来，出现 <u>跨域问题</u>：</p><p><code>has been blocked by CORS policy: No &#39;Access-Control-Allow-Origin&#39; header is present</code></p><p>若将<code>les_miserables.gexf</code>文件下载下来，放在目录<code>&#39;data/les_miserables.gexf&#39;</code>，并在代码中写成：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">$.<span class="hljs-title function_">get</span>(<span class="hljs-string">&#x27;data/les_miserables.gexf&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">xml</span>)<br></code></pre></td></tr></table></figure><p>在这种情况下，不管什么浏览器，都无法加载出图表，故头疼中。。。</p><h3 id="办法"><a href="#办法" class="headerlink" title="办法"></a>办法</h3><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>根据<a href="https://blog.csdn.net/chenmoupeng/article/details/107317247">博客2</a><code>解决Cross origin requests are only supported for protocol schemes的三种办法</code> 中第三种方法的启发，我们使用<code>anywhere插件</code>，使得项目得以在服务器端而不是本地端运行。</p><h5 id="全局安装anywhere插件"><a href="#全局安装anywhere插件" class="headerlink" title="全局安装anywhere插件"></a>全局安装anywhere插件</h5><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">$ npm <span class="hljs-keyword">install</span> anywhere -g <br></code></pre></td></tr></table></figure><h5 id="然后切换到html文件所在的文件夹，运行"><a href="#然后切换到html文件所在的文件夹，运行" class="headerlink" title="然后切换到html文件所在的文件夹，运行"></a>然后切换到html文件所在的文件夹，运行</h5><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>anywhere <br></code></pre></td></tr></table></figure><p>运行后一般会自动跳转到浏览器(默认谷歌浏览器)上，终端上会显示一个运行的网址。下图是我的跳转后的效果(仅供参考)：</p><p><img src="/images/echarts_qs/pic1.png"></p><p align = 'center'>图1.1 我的work directory</p><p><img src="/images/echarts_qs/pic2.png"></p><p align = 'center'>图1.2 浏览器跳转后的界面</p><p>点击<code>test.html</code>文件，图表完美呈现，棒极了！</p><p><img src="/images/echarts_qs/pic3.png"></p><p align = 'center'>图1.3 图表界面</p><p>但是这个方法还是要依赖<code>anywhere插件</code>图表才能执行。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>echarts</tag>
      
      <tag>跨域</tag>
      
      <tag>javascript</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch的常用张量操作</title>
    <link href="/2020/07/30/pytorch_operation/"/>
    <url>/2020/07/30/pytorch_operation/</url>
    
    <content type="html"><![CDATA[<h3 id="1：torch-masked-select"><a href="#1：torch-masked-select" class="headerlink" title="1：torch.masked_select"></a>1：torch.masked_select</h3><p>用法：<code>torch.masked_select(x, mask)</code>，mask必须转化成torch.ByteTensor类型。</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.Tensor([[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">8</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])<br>b = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]]).<span class="hljs-built_in">type</span>(torch.ByteTensor)<br>c = torch.masked_select(a,b)<br><span class="hljs-built_in">print</span>(c)<br></code></pre></td></tr></table></figure><h3 id="2-torch-gather-x2F-scatter"><a href="#2-torch-gather-x2F-scatter" class="headerlink" title="2: torch.gather&#x2F;scatter_"></a>2: torch.gather&#x2F;scatter_</h3><p>说明：dim&#x3D;0（按照竖直方向操作，即↓），dim&#x3D;1（按照水平方向操作，即→）</p><p>gather是取的意思，scatter_是放的意思。</p><blockquote><p>用法：<code>output=torch.gather(input, dim, index)</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])<br>b = torch.gather(a, <span class="hljs-number">1</span>, torch.LongTensor([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]]))<br><span class="hljs-built_in">print</span>(b) <br></code></pre></td></tr></table></figure><blockquote><p>用法：<code>output = torch.Tensor.scatter_(dim, index, src)</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(a)<br>b = torch.zeros(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>).scatter_(<span class="hljs-number">0</span>, torch.tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]]), a)<br><span class="hljs-built_in">print</span>(b) <br></code></pre></td></tr></table></figure><h3 id="3-torch-cat与torch-chunk"><a href="#3-torch-cat与torch-chunk" class="headerlink" title="3: torch.cat与torch.chunk"></a>3: torch.cat与torch.chunk</h3><p>用法：</p><blockquote><ul><li><code>torch.cat ( (A, B), dim=0)</code>接受一个由两个（或多个）tensor组成的元组，按行拼接，所以两个（多个）tensor的列数要相同。</li><li><code>torch.cat ( (A, B), dim=1)</code>是按列拼接，所以两个tensor的行数要相同。</li><li><code>torch.chunk(tensor, chunk_num, dim)</code>与torch.cat()原理相反，它是将tensor按dim（行    或列）分割成chunk_num个tensor块，返回的是一个元组。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>]])<br>b = torch.Tensor([[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">8</span>], [<span class="hljs-number">9</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]])<br>c = torch.cat((a,b), dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(c)<br><span class="hljs-built_in">print</span>(c.size())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;********************&#x27;</span>)<br>d = torch.chunk(c,<span class="hljs-number">4</span>,dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(d)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(d))<br></code></pre></td></tr></table></figure><h3 id="4-torch-unsqueeze-x2F-squeeze"><a href="#4-torch-unsqueeze-x2F-squeeze" class="headerlink" title="4: torch.unsqueeze&#x2F;squeeze"></a>4: torch.unsqueeze&#x2F;squeeze</h3><p>注意：维均从0开始计数</p><p>用法：</p><p><strong>unsqueeze:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = t.Tensor([[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">7</span>], [<span class="hljs-number">6</span>, <span class="hljs-number">9</span>]]) <span class="hljs-comment"># 3*2</span><br>y1 = x.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># 1*3*2</span><br><span class="hljs-built_in">print</span>(y1.size())<br>y2 = x.unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># 3*1*2</span><br><span class="hljs-built_in">print</span>(y2.size())<br>y3 = x.unsqueeze(<span class="hljs-number">2</span>) <span class="hljs-comment"># 3*2*1`</span><br><span class="hljs-built_in">print</span>(y3.size())`<br></code></pre></td></tr></table></figure><p><strong>squeeze:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = t.ones(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br>y1 = x.squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># 1*2*3*1</span><br><span class="hljs-built_in">print</span>(y1.size())<br>y2 = x.squeeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># 1*2*3*1</span><br><span class="hljs-built_in">print</span>(y2.size())<br>y3 = x.squeeze() <span class="hljs-comment"># 2*3</span><br><span class="hljs-built_in">print</span>(y3.size())<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>张量计算</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>张量操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>二叉树的建立与遍历（C语言实现）</title>
    <link href="/2020/07/30/er-cha-shu-de-jian-li-yu-bian-li-c-yu-yan-shi-xian/"/>
    <url>/2020/07/30/er-cha-shu-de-jian-li-yu-bian-li-c-yu-yan-shi-xian/</url>
    
    <content type="html"><![CDATA[<p>1：二叉树结点的定义：</p><span id="more"></span><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span></span><br><span class="hljs-class">    &#123;</span><br>        <span class="hljs-type">int</span> data;<br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">pleft</span>;</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">pright</span>;</span><br>    &#125;Node;<br></code></pre></td></tr></table></figure><p>2：二叉树创造一个结点的函数，返回值是指向该节点的指针：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">struct</span> Node *<span class="hljs-title function_">createnode</span><span class="hljs-params">(<span class="hljs-type">int</span> value)</span><br>    &#123;<br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">pnode</span> =</span> (<span class="hljs-keyword">struct</span> Node *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">struct</span> Node));<br>        pnode-&gt;data = value;<br>        pnode-&gt;pleft = pnode-&gt;pright = <span class="hljs-literal">NULL</span>;<br>        <span class="hljs-keyword">return</span> pnode;<br>    &#125;    <br></code></pre></td></tr></table></figure><p>3：二叉树插入结点的函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">struct</span> Node *<span class="hljs-title function_">addnode</span><span class="hljs-params">(<span class="hljs-type">int</span> value, <span class="hljs-keyword">struct</span> Node *pnode)</span><br>    &#123;<br>        <span class="hljs-keyword">if</span>(pnode == <span class="hljs-literal">NULL</span>)<br>            <span class="hljs-keyword">return</span> createnode(value);<br><br>        <span class="hljs-keyword">if</span>(value == pnode-&gt;data)<br>        &#123;<br>            <span class="hljs-keyword">return</span> pnode;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span>(value &lt; pnode-&gt;data)<br>        &#123;<br>            <span class="hljs-keyword">if</span>(pnode-&gt;pleft == <span class="hljs-literal">NULL</span>)<br>            &#123;<br>                pnode-&gt;pleft = createnode(value);<br>                <span class="hljs-keyword">return</span> pnode-&gt;pleft;<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                <span class="hljs-keyword">return</span> addnode(value, pnode-&gt;pleft);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            <span class="hljs-keyword">if</span>(pnode-&gt;pright == <span class="hljs-literal">NULL</span>)<br>            &#123;<br>                pnode-&gt;pright = createnode(value);<br>                <span class="hljs-keyword">return</span> pnode-&gt;pright;<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                <span class="hljs-keyword">return</span> addnode(value, pnode-&gt;pright);<br>            &#125;<br><br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><p>4：二叉树的遍历（三种，此处为中序遍历），用到了递归：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">listnodes</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Node *pnode)</span><br>&#123;<br>    <span class="hljs-keyword">if</span>(pnode != <span class="hljs-literal">NULL</span>)<br>    &#123;<br>        listnodes(pnode-&gt;pleft);<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, pnode-&gt;data);<br>        listnodes(pnode-&gt;pright);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>5：求二叉树的深度，递归：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> <span class="hljs-title function_">Treeheight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Node *pnode)</span><br>&#123;<br>    <span class="hljs-type">int</span> LD, RD;<br>    <span class="hljs-keyword">if</span>(pnode == <span class="hljs-literal">NULL</span>)<br>    &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">else</span><br>    &#123;<br>        LD = Treeheight(pnode-&gt;pleft);<br>        RD = Treeheight(pnode-&gt;pright);<br>        <span class="hljs-keyword">return</span> (LD &gt;= RD? LD:RD) + <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>6：主函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    <span class="hljs-type">int</span> newvalue = <span class="hljs-number">0</span>;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> *<span class="hljs-title">proot</span> =</span> <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-type">char</span> answer = <span class="hljs-string">&#x27;n&#x27;</span>;<br>    <span class="hljs-keyword">do</span><br>    &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Enter the node value:\n&quot;</span>);<br>        <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;newvalue);<br>        <span class="hljs-keyword">if</span>(proot == <span class="hljs-literal">NULL</span>)<br>        &#123;<br>            proot = createnode(newvalue);<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            addnode(newvalue, proot);<br>        &#125;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\nDo you want to enter another (y or n)? &quot;</span>);<br>        <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot; %c&quot;</span>, &amp;answer);<br>    &#125; <span class="hljs-keyword">while</span>(<span class="hljs-built_in">tolower</span>(answer) == <span class="hljs-string">&#x27;y&#x27;</span>);<br><br>    listnodes(proot);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\nThe height of tree is %d!&quot;</span>, Treeheight(proot));<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>7：需要添加的头文件：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;ctype.h&gt;</span></span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C语言</tag>
      
      <tag>数据结构</tag>
      
      <tag>二叉树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读-The Numerics of GANs</title>
    <link href="/2018/03/31/the-numerics-of-gans/"/>
    <url>/2018/03/31/the-numerics-of-gans/</url>
    
    <content type="html"><![CDATA[<h3 id="论文标题"><a href="#论文标题" class="headerlink" title="论文标题"></a>论文标题</h3><p><strong>The Numerics of GANs</strong></p><span id="more"></span><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="实对称矩阵"><a href="#实对称矩阵" class="headerlink" title="实对称矩阵"></a>实对称矩阵</h4><p>如果一个矩阵是实对称矩阵，那么其所有的特征值是实数。如果它不是实对称矩阵，那么其特征值一般是复数：包含实部（real-part），虚部（imaginary-part）。</p><h4 id="正定矩阵"><a href="#正定矩阵" class="headerlink" title="正定矩阵"></a>正定矩阵</h4><ul><li><p>正定矩阵：对于任何非零向量X，都有 $ X^{T}AX &gt; 0 $，则称矩阵A为正定阵。</p></li><li><p>负定矩阵：对于任何非零向量X，都有 $ X^{T}AX &lt; 0 $，则称矩阵A为负定阵。</p></li><li><p>半正定矩阵：对于任何非零向量X，都有 $ X^{T}AX &gt;&#x3D; 0 $，则称矩阵A为半正定阵。</p></li><li><p>半负定矩阵：对于任何非零向量X，都有 $ X^{T}AX &lt;&#x3D; 0 $，则称矩阵A为半负定阵。</p></li></ul><h4 id="雅克比矩阵"><a href="#雅克比矩阵" class="headerlink" title="雅克比矩阵"></a>雅克比矩阵</h4><p>雅可比矩阵类似于单变数函数的导数。 假设 $F: R_{n} \rightarrow R_{m}$是一个从n维欧氏空间映射到到m维欧氏空间的函数。这个函数由m个实函数组成：$y_{1}\left(x_{1}, \ldots, x_{n}\right), \ldots y_{m}\left(x_{1}, \ldots, x_{n}\right)$ 。这些函数的偏导数(如果存在)可以组成一个m行n列的矩阵，这个矩阵就是所谓的雅可比矩阵：<br>$$<br>{<br>\left[\begin{array}{ccc}\frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}} \ \vdots &amp; \ddots &amp; \vdots \ \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}\end{array}\right]<br>}<br>$$</p><p>此外，雅克比矩阵的行列式称为雅克比行列式。</p><h4 id="黑塞矩阵"><a href="#黑塞矩阵" class="headerlink" title="黑塞矩阵"></a>黑塞矩阵</h4><p>黑塞矩阵（Hessian Matrix）与雅克比矩阵的不同之处在于，它是一个多元函数的二阶偏导数构成的方阵。<br>$$<br>{<br>H(f)&#x3D;\left[\begin{array}{cccc}\frac{\partial^{2} f}{\partial x_{1}^{2}} &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{n}} \ \frac{\partial^{2} f}{\partial x_{2} \partial x_{1}} &amp; \frac{\partial^{2} f}{\partial x_{2}^{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{2} \partial x_{n}} \ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \ \frac{\partial^{2} f}{\partial x_{n} \partial x_{1}} &amp; \frac{\partial^{2} f}{\partial x_{n} \partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{n}^{2}}\end{array}\right]<br>}<br>$$</p><p>通用计算公式：<br>$$<br>{<br>H_{i, j}&#x3D;\frac{\partial^{2} f}{\partial x_{i} \partial x_{j}} \tag{1.1}<br>}<br>$$</p><p>i和j分别表示行数和列数（均从1开始计数）。</p><h4 id="纳什均衡"><a href="#纳什均衡" class="headerlink" title="纳什均衡"></a>纳什均衡</h4><p>假设有n个局中人参与博弈，如果某情况下无一参与者可以独自行动而增加收益（即为了自身利益的最大化，没有任何单独的一方愿意改变其策略），则此策略组合被称为纳什均衡。</p><p>这篇论文中，作者分析了训练GAN的普通算法的数值。通过使用平滑双人游戏的方式，分析了GAN训练对象的关联梯度向量场。当前算法的收敛性受到两个因素的影响：i）具有零实部的梯度矢量场的雅可比矩阵的特征值的存在，以及ii）具有大的虚部的特征值。 利用这些发现，作者设计了一种克服了这些局限性并具有更好收敛特性的新算法。 通过实验，证明了其在训练普通GAN的结构的优越性并且展示了难以训练的GAN结构的收敛性。</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>GAN自从被提出以后已经成功地应用于各种领域任务，包括图像到图像的翻译，图像超分辨率，图像绘画域适应，概率推理等等。尽管如此，GAN还是普遍认为难以被训练。标准的策略使训练稳定的方法是仔细设计模型，要不就是改变结构，要不就是选择一个容易优化的函数。</p><p>作者从理论上证明，阻止算法收敛的主要因素是相关梯度矢量场的雅可比阵特征值的存在性，其中零实部和大的虚部的特征值。作者设计了一种克服这些问题的新算法。</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="散度方法和GANS"><a href="#散度方法和GANS" class="headerlink" title="散度方法和GANS"></a>散度方法和GANS</h4><p>给出一个函数D，其输入是一对概率分布，其输出是一个大于等于0的元素。并且对于所有的分布p，满足$D(p,p)&#x3D;0$。</p><p>假定给出一个目标概率分布 $p_{0}$，一个分布 $q_{θ}$（实际上被应用于一个神经网络，这个网络作用于一个取样自已知分布的的隐代码z，网络的输出是一个来自目标空间的元素）。我们的目标是：</p><p>$$<br>{<br>\min <em>{\theta} D\left(p</em>{0}, q_{\theta}\right)<br>}<br>$$<br>大部分实际应用的散度被表达成如下的式子：</p><p>$$<br>{<br>D(p, q)&#x3D;\max <em>{f \in F} E</em>{x \sim q}\left[g_{1}(f(x))\right]-E_{x \sim p}\left[g_{2}(f(x))\right] \tag{1.2}<br>}<br>$$<br>结合公式（1.2）和（1.3），最终得到最小最大化问题：</p><p>$$<br>{<br>\min <em>{\theta} \max <em>{f \in F} E</em>{x \sim q</em>{\theta}}\left[g_{1}(f(x))\right]-E_{x \sim p_{0}}\left[g_{2}(f(x))\right] \tag{1.3}<br>}<br>$$<br>函数类F近似于一个参数系列的函数，由一个神经网络参数化。</p><h4 id="平滑二玩家游戏"><a href="#平滑二玩家游戏" class="headerlink" title="平滑二玩家游戏"></a>平滑二玩家游戏</h4><p>一个可微分的二类游戏由两个效用函数$f(φ,θ)$和$g(φ,θ)$定义，基于一个普通空间<br>$$<br>{<br>(\varphi, \theta) \in \Omega_{1} \times \Omega_{2}<br>}<br>$$<br> 其中，Ω1对应玩家1的可能性动作，在GAN中是生成器的可能参数集。玩家1的目标是最大化函数f。Ω2对应玩家2的可能性动作，在GAN中是判别器的可能参数集，玩家2的目标是最大化函数g。当$f + g&#x3D;0$的时候，这就是一个零和游戏的状态。</p><p>我们的目标是找到这个游戏的一个纳什均衡点，即<br>$$<br>{<br>\bar{x}&#x3D;(\bar{\varphi}, \bar{\theta}) \tag{1.4}<br>}<br>$$</p><p>$$<br>{<br>\bar{\varphi} \in \underset{\varphi}{\arg \max } f(\varphi, \bar{\theta})<br>}<br>$$</p><p>$$<br>{<br>\bar{\theta} \in \underset{\theta}{\arg \max } g(\bar{\varphi}, \theta)<br>}<br>$$</p><p>定义一个向量场：</p><p>$$<br>{<br>v(\phi, \theta)&#x3D;\left(\begin{array}{c}\nabla_{\phi} f(\phi, \theta) \ \nabla_{\theta} g(\phi, \theta)\end{array}\right) \tag{1.5}<br>}<br>$$<br>在零和游戏的情况下再对其求导：</p><p>$$<br>{<br>v^{\prime}(\phi, \theta)&#x3D;\left(\begin{array}{cc}\nabla_{\phi}^{2} f(\phi, \theta) &amp; \nabla_{\phi, \theta} f(\phi, \theta) \ -\nabla_{\phi, \theta} f(\phi, \theta) &amp; -\nabla_{\theta}^{2} f(\phi, \theta)\end{array}\right) \tag{1.6}<br>}<br>$$</p><h4 id="同时梯度下降"><a href="#同时梯度下降" class="headerlink" title="同时梯度下降"></a>同时梯度下降</h4><p>该算法迭代更新两个玩家的参数，同时对两个玩家的效用函数应用梯度上升。</p><p>如果两个参与者的黑塞矩阵都是负定的，并且学习率足够小，那么同时梯度上升就会局部收敛到零和博弈的纳什均衡。</p><h3 id="收敛性理论"><a href="#收敛性理论" class="headerlink" title="收敛性理论"></a>收敛性理论</h3><p>这一节分析了最常用的训练GANs同时梯度上升方法的收敛性。证明这个算法的两个主要失效原因是具有零实部的相关梯度矢量场的雅可比阵的特征值以及具有大的虚部的特征值。</p><h4 id="Proposition-3"><a href="#Proposition-3" class="headerlink" title="Proposition 3"></a>Proposition 3</h4><p>$\Omega \in \mathbb{R}^{n}$ ，函数F： $\Omega \rightarrow \Omega$是一个连续的可微函数，$\bar{x}\in \Omega$</p><p>1：$F(\bar{x}) &#x3D; \bar{x} \tag{1.7}$</p><p>2：雅克比矩阵$F^{‘}(\bar{x})$的所有特征值的绝对值均小于1</p><p>设$\bar{x}$的某一领域为$U$，$x_{0} \in U$，$F^{(k)}(x_{0})$收敛于$\bar{x}$</p><p>误差$\left|F^{(k)}\left(x_{0}\right)-\bar{x}\right|$在$\mathcal{O}\left(\left|\lambda_{\max }\right|^{k}\right)$内，$k\rightarrow \infty$ ，并且$\lambda_{\max }$ 为$F^{‘}(\bar{x})$所有特征值的绝对值的最大值。</p><p>考虑以下函数形式：<br>$$<br>{<br>F(x)&#x3D;x+hG(x) \tag{1.8}<br>}<br>$$<br>求导：<br>$$<br>{<br>F^{‘}(x)&#x3D;I+hG^{‘}(x) \tag{1.9}<br>}<br>$$<br>$F^{‘}(x)$和$G^{‘}(x)$都不是对称的，故它们有复杂的特征值。</p><h4 id="Lemma-4"><a href="#Lemma-4" class="headerlink" title="Lemma 4"></a>Lemma 4</h4><p>矩阵A的特征值拥有负实部，并且让$h&gt;0$<br>$$<br>{<br>h&lt;\frac{1}{|\Re(\lambda)|} \frac{2}{1+\left(\frac{\Im(\lambda)}{\Re(\lambda)}\right)^{2}}<br>} \tag{2.0}<br>$$<br>上式表明有两个主要因子影响了h的最大可能值，即：</p><p>（1）$\Re(\lambda)$的最大值</p><p>（2）$|\Im(\lambda) &#x2F; \Re(\lambda)|$的最大值q</p><h3 id="一致性优化"><a href="#一致性优化" class="headerlink" title="一致性优化"></a>一致性优化</h3><h4 id="Derivation"><a href="#Derivation" class="headerlink" title="Derivation"></a>Derivation</h4><p>寻找向量场$v(x)$的稳定点等同于解方程<br>$$<br>{<br>v(x)&#x3D;0 \tag{2.1}<br>}<br>$$<br>在二类游戏的内容里意味着解一对方程<br>$$<br>{<br>\nabla_{\phi} f(\phi, \theta)&#x3D;0 \tag{2.2}<br>}<br>$$</p><p>$$<br>{<br>\nabla_{\theta} g(\phi, \theta)&#x3D;0 \tag{2.3}<br>}<br>$$</p><p>寻找类似稳定点的一个简单策略是最小化<br>$$<br>{<br>L(x)&#x3D;\frac{1}{2}|v(x)|^{2} \tag{2.4}<br>}<br>$$<br>但这可能会导致局部最小值。</p><p>现考虑一个修改过的向量场$w(x)$，它尽可能接近原始向量场$v(x)$，即<br>$$<br>{<br>w(x)&#x3D;v(x)-\gamma \nabla L(x) \tag{2.5}<br>}<br>$$</p><p>$$<br>{<br>\nabla L(x)&#x3D;v^{\prime}(x)^{\mathrm{T}} v(x) \tag{2.6}<br>}<br>$$</p><p>该向量场是由两个修改的效用函数给出的修改的双人游戏相关联的梯度向量场<br>$$<br>{<br>\tilde{f}(\phi, \theta)&#x3D;f(\phi, \theta)-\gamma L(\phi, \theta) \tag{2.7}<br>}<br>$$</p><p>$$<br>{<br>\tilde{g}(\phi, \theta)&#x3D;g(\phi, \theta)-\gamma L(\phi, \theta) \tag{2.8}<br>}<br>$$</p><p>其中正则化项$L(\phi, \theta)$鼓励两个玩家达成一致，因此称之为Consensus Optimization。</p><h4 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h4><p>考虑一个迭代使用函数F的算法<br>$$<br>{<br>F(x)&#x3D;x+hA(x)v(x) \tag{2.9}<br>}<br>$$<br>其中$h&gt;0$，$A(x)$是可逆矩阵。</p><p>Consensus优化是该算法在<br>$$<br>{<br>A(x)&#x3D;I-\gamma v^{\prime}(x)^{\top} \tag{3.0}<br>}<br>$$<br>的特殊情形。假定 $\frac{1}{\gamma}$不是 的特征值，所以$A(x)$是可逆的。</p><h5 id="Lemma-6"><a href="#Lemma-6" class="headerlink" title="Lemma 6"></a>Lemma 6</h5><p>假定$h&gt;0$且$A(x)$是可逆阵，$\bar{x}$是固定点，并且他是$v$的稳定点，我们有<br>$$<br>{<br>F^{\prime}(\bar{x})&#x3D;I+h A(\bar{x}) v^{\prime}(\bar{x}) \tag{3.1}<br>}<br>$$</p><h5 id="Lemma-7"><a href="#Lemma-7" class="headerlink" title="Lemma 7"></a>Lemma 7</h5><p>设<br>$$<br>{<br>A(x)&#x3D;I-\gamma v^{\prime}(x)^{\top} \tag{3.2}<br>}<br>$$<br>并假定$v^{\prime}(\bar{x})$是半负定且可逆的，所以$A(\bar{x}) v^{\prime}(\bar{x})$是负定的。</p><h5 id="Lemma-9"><a href="#Lemma-9" class="headerlink" title="Lemma 9"></a>Lemma 9</h5><p>假定$A\in \mathbb{R}^{n*n}$是半负定阵，$q(\gamma )$ 是 $\frac{|\mathfrak{G}(\lambda)|}{|\Re(\lambda)|}$的最大值。</p><p>$\lambda$表示$A-\lambda A^{T}A$的特征值，$\Re(\lambda)$和$\mathfrak{G}(\lambda)$分别表示特征值$\lambda$的实部与虚部。此外，假定A是可逆的，有$|Av|&gt;&#x3D;p|v|$，此时$p&gt;0$</p><p>令<br>$$<br>{<br>c&#x3D;\min _{v \in \mathbb{S}\left(\mathbb{C}^{n}\right)} \frac{\left|\bar{v}^{\top}\left(A+A^{\top}\right) v\right|}{\left|\bar{v}^{\top}\left(A-A^{\top}\right) v\right|} \tag{3.3}<br>}<br>$$<br>$S(C^{n})$表示在$C^{n}$中的单位球体，然后有：<br>$$<br>{<br>q(\gamma) \leq \frac{1}{c+2 \rho^{2} \gamma} \tag{3.4}<br>}<br>$$</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>第一个实验通过一个简单的二维实例来评估我们的方法，其中目标是学习8个标准差等于10的-2次方的高斯混合物。但即使在这样简单的示例中，训练GAN的算法也往往无法收敛，由于没有对体系结构和超参数进行微调。</p><p>对于生成器和评论家，两者都使用具有4个隐藏层的全连接神经网络，并且每层有16个隐藏单元。 对于所有的层，使用RELU非线性激活函数。对隐变量z使用16维高斯先验，并使用一个效用函数来设置生成器和评论者之间的游戏。为了测试方法，运行SimGA和RMSProp，一共是20000步，学习率为10的-4次方。 对于我们的方法，使用γ&#x3D; 10的正则化参数。</p><p>对SimGA方法和我们的方法进行0, 5000, 10000和20000次迭代的结果，虽然SimGA跳过分布模式并且未能收敛，但我们的方法平滑地收敛到目标分布。</p><p>实验结果还显示了$v(x)$的雅可比行列式和正则化向量场$w(x)$的特征值的经验分布，其中<br>$$<br>{<br>w(x)&#x3D;v(x)-\gamma \nabla L(x) \tag{3.5}<br>}<br>$$<br>在纳什均衡附近，大多数特征值确实非常接近虚轴，并且在一致优化中使用的向量场的所提出的修改将特征值向左移动。</p><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p>在第二个实验中，将我们的方法应用于cifar-10和celebAdatasets，在发生器或鉴别器中没有批量归一化的情况下使用类似DC-GAN的架构。 对于celebA，另外在每一层中使用恒定数量的<strong>滤波器</strong>并添加额外的RESNET层，与使用交替梯度上升不同，在训练期间，发生器和鉴别器损失几乎保持不变。</p><h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>在讨论中，作者认为之前的分析不能解释为什么训练期间发生器和鉴别器损失几乎保持不变。另外在实践中，如果正则化参数选择为高，提出的方法可能使梯度矢量场的以前不稳定的稳定点稳定。作者还发现，提出的方法对于更深的体系结构变得不太稳定，作者认为这种体系结构中梯度可能具有非常不同的尺度，所以第4节中的简单L2惩罚需要相应地重新调整。提出的方法可以认为是对隐式欧拉方法的积分梯度向量场的近似，还可以看作是二阶方法。</p><h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p><strong>鞍点问题</strong>不仅出现在训练GAN的情况下。在强化学习中流行的行动者 - 评论者模型也是鞍点问题的特例。</p><p>寻找稳定的GAN训练算法是一个长期存在的问题，并提出了多种解决方案。展开的GAN展开关于评论家的优化，从而为生成器提供更多信息性梯度。尽管展示优化被证明可以稳定训练，但实施起来可能很麻烦，并且还会产生一个很大的模型。所以工作重点是稳定各种架构和发散功能的训练。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从GAN目标函数出发，作者分析了在平滑双人游戏中寻找局部纳什均衡的主要难点。作者确定了当前最先进的算法中出现的主要数值问题，提出了一种用于训练生成对抗网络的新算法。</p><p>这个新算法在理论和实践上具有良好的性质：从理论的角度来看，即使雅可比矩阵的特征值存在问题，也能证明它是局部收敛于纳什均衡的。从实践的角度来看，新算法可以与任何GAN架构结合使用，其目标可以被定义为双人游戏以稳定训练。</p><p>最后作者通过实验证明了新算法能够稳定训练并成功地解决了<strong>模型崩溃</strong>等训练问题。</p>]]></content>
    
    
    <categories>
      
      <category>GANs</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GANs</tag>
      
      <tag>线性代数</tag>
      
      <tag>纳什均衡</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读-GANs用于离散序列生成</title>
    <link href="/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/"/>
    <url>/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/</url>
    
    <content type="html"><![CDATA[<p><strong>篇名</strong>：<em>GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution</em></p><p><strong>概要中提出的问题</strong>：当目标是生成离散元素构成的序列时 GAN 是存在限制的。</p><p><strong>出现问题的原因</strong> ：是来自服从离散对象分布的样本，例如多项式关于分布参数是不可区分的。</p><p><strong>解决方法</strong>：作者提出使用 Gumbel-softmax 分布可以避免这个问题，该分布是对 softmax 函数参数化的多项分布的连续逼近。</p><p><strong>本文所做的工作</strong>：评估基于 GS 输出分布的递归神经网络的GAN在生成离散元素组成的序列这一任务中的性能如何。</p><span id="more"></span><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p> GAN通过从鉴别器产生的样本后向传播到生成器来工作。如果产生的样本是连续的，例如图像生成的例子，这是可行的。但是如果大量数据以离散的形式存在，比如文本中的句子，以 SMILE语言编码的分子等。在这些情况下，离散数据是不可微分的（由高等数学的知识，可微一定连续，连续不一定可微，所以不连续一定不可微），反向传播的梯度总是0。</p><p>使用独热编码表示离散数据。这样就可以从多项分布中采样，其概率由softmax函数的输出给出。</p><p>用一个简单的例子来说明独热编码。例如有三个特征：</p><p>性别：[“男”，“女”] 爱好：[“篮球”，“足球”，“羽毛球”，“排球”]</p><p>国家：[“中国”，“美国”，“英国”，“俄罗斯”，“法国”]</p><p>对于某样本[“女”，“羽毛球”，“法国”]，用独热编码表示就是[01 0010 00001]。</p><p>何为softmax函数？</p><p>对于二分类问题，我们一般使用sigmoid函数将输入映射到 (0,1) 的区间中，从而得到某个类别的概率。推广到多类问题，我们使用softmax函数对输出的值归一化为概率值。</p><p>例如，假设输入数据是维度为 $d$ 的向量$\textbf {h}$，那么经过softmax函数的输出也是一个 $d$维度的向量 ，里面$\textbf {p}$的值都在0到1之间，也就是概率值。所以理解为一个归一化的指数函数：</p><p>$$<br>{<br>[s o f t \max (h)]<em>{i}&#x3D;\frac{e^{h</em>{i}}}{\sum_{j&#x3D;1}^{d} e^{z_{j}}} \tag{1.1}<br>}<br>$$</p><p>其中$ i \in (1, d) $ ；</p><p>观察上述公式，还可以得到：</p><p>$$<br>{<br>\sum_{i&#x3D;1}^{d}[s o f t \max (h)]_{i}&#x3D;1 \tag{1.2}<br>}<br>$$</p><p>个人通俗理解就是，先用指数函数 $ y&#x3D;e^{x} $ 作用于 $C$ 维输入向量中分量的每个值，得到一串新值。再将这些新值加起来。用每个新值除以这个和就是经过softmax函数处理后对应的输出向量分量的对应值。</p><p>现在又提出了在离散序列上训练 GAN 的另一种方法。 该方法将离散序列的生成建模为强化学习中的随机策略，并通过直接执行梯度策略更新来绕过生成器区分问题。</p><h4 id="Gumbel-softmax分布"><a href="#Gumbel-softmax分布" class="headerlink" title="Gumbel-softmax分布"></a>Gumbel-softmax分布</h4><p>上面我已经介绍了 softmax函数，然后引入 Gumbel-softmax分布：<br>$$<br>{<br>y &#x3D; onehot \left(\arg \max <em>{i}\left(h</em>{i}+g_{i}\right)\right) \tag{1.3}<br>}<br>$$<br>其中 $ g_{i} $ 是独立的并且遵循 Gumbel分布，具有零位和单位尺度。<br>$$<br>{<br>y&#x3D;\operatorname{soft} \max (1 &#x2F; \Gamma(h+g)) \tag{1.4}<br>}<br>$$<br>$\Gamma$是一个逆向温度参数。当它趋于0时，由公式（1.4）生成的样本和公式（1.3）生成的样本有着相同的分布。而当它趋于无穷时，样本总是一致的概率向量。对于${\Gamma}$的正值和有限值，由（1.4）生成的样本相对于是平$\textbf {h}$滑和可微的。</p><p>公式（1.4）的概率分布就叫Gumbel-softmax分布。一个基于离散数据的GAN可以用（1.4）来训练了，从一些比较大的$\Gamma$开始，然后在训练期间将其回零。</p><h4 id="离散序列的递归神经网络"><a href="#离散序列的递归神经网络" class="headerlink" title="离散序列的递归神经网络"></a>离散序列的递归神经网络</h4><p>这个部分描述的是怎样建立一个能够从随机的噪音样本中生成文本的GAN模型。将给出一个简单的算法。</p><p>$$<br>{<br> S \rightarrow x|S+S| S-S|S * S| S &#x2F; S \tag{1.5}<br>}<br>$$</p><p>上面这个公式用来描述学习生成简单的单变量算术序列。两竖线用来划分语法的可能产生。</p><p>生成模型基于LSTM循环神经网络，它被训练用来在每个时间步预测一个隐藏状态的向量 $\textbf {h}$，然后再对这个向量使用softmax函数归一化。训练结束后，网络通过从softmax分布中取样来生成数据。</p><p>训练LSTM模型以预测未来特征的一种方法是通过最大似然估计（MLE）将softmax分布与输入数据的独热编码进行匹配。构建一个离散序列的生成模型，通过LSTM进行采样来完成。生成模型以一个样本对为输入，有效地替换了初始细胞和隐藏状态。生成器通过连续地将其预测作为输入反馈到下面的LSTM单元来构建序列。目标是设计一种方法来训练这个生成器来产生真实的离散序列。</p><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-1.png"></p><p align = 'center'>图 1.1 一个经典的LSTM模型</p><p>上图是一个经典的LSTM模型，每个LSTM单元（蓝色盒子）根据过去看到的输入进行预测，然后这个预测被用作下一个单元的输入，以此类推。</p><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-2.png"></p><p align = 'center'>图 1.2 离散序列的生成模型</p><p>上图是离散序列的生成模型。一开始画一对样本并将它们送入网络，代替初始单元状态$C_{0}$ 和隐藏状态$h_{0}$ 。训练好的网络取这些样本并且使用它们生成一个初始特征，这个生成的特征被送到LSTM的下一个单元作为输入，以此类推。</p><h3 id="对抗生成模型"><a href="#对抗生成模型" class="headerlink" title="对抗生成模型"></a>对抗生成模型</h3><p>给出一个由$n$个独立同分布的数据点组成的集合，它们服从$d$维分布$p(x)$。对抗模型的目标就是学习一个$q(x)$分布，该分布能精确接近 $p(x)$ 分布。生成对抗模型的架构是迫使$q(x)$生成真实的样本点。首先，学习一个将服从简单已知分布的样本（例如均匀或高斯分布）转换为接近$p(x)$的样本的模型，称之为生成器 <em>G</em> 。我们定义$q(x):&#x3D;G(\textbf{z})$，$\textbf{z}$服从（0,1）均匀分布。 <strong>这段话的意思就是说生成器的随机输入向量 z 服从均匀分布（也可以是高斯分布或者其他简单分布），我们的目标就是要通过生成器<em>G</em>的作用将其变为一个十分接近真实数据 <em>p(x)</em> 分布的分布 <em>q(x)</em> ，显然 <em>q(x)</em> 分布相对来说应该比 <em>z</em> 初始分布复杂得多。</strong>  其次，鉴别器的是将任何真实的$d$维向量作为输入，并且它能预测输入是否服从$p(x)$的概率。同时生成器也被训练以愚弄鉴别器。一开始，鉴别器能够很容易区别真假数据，但是随着训练的不断进行生成器采用来自鉴别器发出的信号决定如何生成更真实的数据。最终，生成器生成的数据太过逼真以至于鉴别器会对生成数据是否真实给出一个随意的猜测。以上就是 GAN的核心思想，虽然在本文中提到，但我再顺便回顾加深一下。</p><h4 id="使用GS分布"><a href="#使用GS分布" class="headerlink" title="使用GS分布"></a>使用<em>GS</em>分布</h4><p>G和D分别采用服从参数<em>Θ</em>和<em>Φ</em>的LSTM。目的是通过采样输入$x$和生成点$z$学习<em>G</em>和<em>D</em>，并且最小化<em>G</em>和<em>D</em>更新参数<em>Θ</em>和<em>Φ</em>的可微分的损失函数。不幸的是，采样生成点$z$对于隐藏态$h$是不可微的。所以需要使用公式（1.4）提出的策略。步骤在下面的算法中阐述，这个算法的目标是最小化$q(z)$和$p(x)$之间的KL散度。</p><h5 id="算法1：生成对抗网络"><a href="#算法1：生成对抗网络" class="headerlink" title="算法1：生成对抗网络"></a>算法1：生成对抗网络</h5><p>1：服从 $p(x)$ 分布的数据集 $\left\lbrace x_{1},\ldots x_{n} \right \rbrace$</p><p>2：生成器采用携带参数 <em>Θ</em> 的LSTM网络</p><p>3：鉴别器采用携带参数 <em>Φ</em> 的LSTM网络</p><p>4：一直循环迭代直到收敛</p><p>{</p><p style="text-indent:2em">4.1：小批量样本输入集*B*，*B*中样本个数为 *m* ，即  $\left \lbrace x_{B_{1}}, \ldots x_{B_{m}} \right \rbrace$</p><p style="text-indent:2em">4.2：样本噪声*N* :   $\left \lbrace z_{N_{1}}, \ldots z_{N_{m}} \right \rbrace$</p><p style="text-indent:2em">4.3：更新鉴别器参数 *Φ*</p><p style="text-indent:2em">4.4：更新生成器参数 *Θ* </p><p>}                </p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-3.png"></p><p align = 'center'>图 1.3 生成loss和判别loss的变化</p><p>上图是训练过程中生成损失和鉴别损失随迭代次数的变化。理想情况下鉴别器的损失应当提高而生成器的损失应当减小正如生成器在接近真实数据时表现得更好。（a）图是使用GS温度训练的神经网络。（b）图和前一张图设定一样但是将生成样本的大小扩大到1000，可以看到这张图中鉴别器的损失有小于生成器的损失了。(c) 图仅改变了输入向量温度值，可以看到生成器的损失在几乎所有迭代下是大于鉴别器的损失的。（d）只将随机噪声引入隐藏状态并且允许网络学习一个初始的细胞状态。</p><h4 id="学习一个CFG"><a href="#学习一个CFG" class="headerlink" title="学习一个CFG"></a>学习一个<em>CFG</em></h4><p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-4.png"></p><p align = 'center'>图 1.4 MLE模型生成的结果</p><p>上图中第一幅图是MLE模型生成的文本。（a）到（d）对应实验部分第一张图的四个GAN模型生成文本的样例。每一行都是来自任意模型的样本，每一行包含12个特征（如果少于12个特征则用空格把缺少的特征补上）。我们将MLE LSTM作为GAN LSTM的参考。可以观察到，（a）图中第4,10,17行显示样本十分接近训练数据。</p><p>最后，作者认为结合最近GANs的进展，如使用变分散最小化训练GANs或通过密度比估计可以进一步的改善它。</p>]]></content>
    
    
    <categories>
      
      <category>文本生成</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GANs</tag>
      
      <tag>Gumbel-softmax分布</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读-对抗训练文本生成</title>
    <link href="/2018/01/21/Text-Generation-using-Generative-Adversarial-Training/"/>
    <url>/2018/01/21/Text-Generation-using-Generative-Adversarial-Training/</url>
    
    <content type="html"><![CDATA[<h2 id="论文名："><a href="#论文名：" class="headerlink" title="论文名："></a>论文名：</h2><p><em>Text Generation using Generative Adversarial Training</em></p><ul><li><p>LSTM初步学习</p></li><li><p>一种改进的GAN</p></li></ul><span id="more"></span><h3 id="Wasserstein-GANs"><a href="#Wasserstein-GANs" class="headerlink" title="Wasserstein GANs"></a>Wasserstein GANs</h3><p>由于原始GANs存在着训练困难、生成器和鉴别器的loss无法指示训练进程、生成样本缺乏多样性等问题，所以提出了WGANs的概念。它的优点有：彻底解决了GANs训练不稳定的问题；确保了生成样本的多样性；训练过程中有一个可以指示训练进程的数值；不需要精心设计的网络架构，最简单的多层全连接网络就可以做到。</p><p>实际上，对比原始GANs算法，WGANs做了如下改进：</p><ol><li><p>鉴别器最后一层不使用sigmoid激活函数</p></li><li><p>生成器和鉴别器的loss不取log</p></li><li><p>每次更新鉴别器的参数之后把它们的绝对值截断到不超过一个固定常数c</p></li><li><p>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</p></li></ol><h3 id="LSTMs"><a href="#LSTMs" class="headerlink" title="LSTMs"></a>LSTMs</h3><p><strong>LSTMs</strong>是一种特别的RNNs，比标准的 RNNs 在很多的任务上都表现得更好。</p><p>如果相关信息和当前预测位置之间的间隔不断增加得相当大，RNNs 会丧失学习到连接如此远的信息的能力。但是LSTMs并不存在这样的问题，它可以学习长期依赖信息。</p><p>LSTMs的核心是元胞，a它是一条穿过LSTMs图表的水平线。也可以将元胞理解为一条链，信息能够很容易流过这个链并且不发生大的改变。</p><p>LSTMs有能力对元胞添加或删除信息，这个行为由一个叫做“门”的结构来控制。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-1.png"></p><p>$$图1.1 \qquad LSTM元胞的门结构$$</p><p>上图称为LSTMs中称为“门”的结构，是一种让信息选择性通过的方法，它包含一个sigmoid神经网络层和一个pointwise乘法操作。</p><p>Sigmoid 层输出 0 到 1 之间的数值，描述每个部分有多少量可以通过。0代表“不许任何量通过”，1 就指“允许任意量通过”！一般情况下，LSTMs 拥有三个类似门，以保护和控制细胞状态。</p><h4 id="分布详解LSTM"><a href="#分布详解LSTM" class="headerlink" title="分布详解LSTM"></a>分布详解LSTM</h4><p>第一步是决定需要从元胞忽略掉什么样的信息，该决定由一个叫做“遗忘门”的sigmoid层控制。它观察$h_{t-1}$和$x_{t}$这两个值，并且对于元胞状态$C_{t-1}$中的每个数字输出一个介于01之间的值。1表示完全保留信息，0表示完全丢弃信息，即：</p><p>$f_{t}&#x3D;\sigma\left(W_{f} \cdot\left[h_{t-1}, x_{t}\right]+b_{f}\right) \tag{1.1}$</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-2.png"></p><p align = 'center'>图1.2</p><p>下一步是决定我们将会把哪些新信息存储到元胞状态中。这步分为两部分。首先，有一个叫做“输入门”的Sigmoid层决定我们要更新哪些信息。接下来，一个tanh层创造了一个新的候选值$\tilde{C}_{t}$。该值可能被加入到元胞状态中。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-3.png"></p><p align = 'center'>图1.3</p><p>$i_{t}&#x3D;\sigma\left(W_{i} \cdot\left[h_{t-1}, x_{t}\right]+b_{i}\right. \tag{1.2}$</p><p>$\tilde{C}<em>{t}&#x3D;\tanh \left(W</em>{C} \cdot\left[h_{t-1}, x_{t}\right]+b_{C}\right) \tag{1.3}$</p><p>第三步：</p><p>按照之前的决定，扔掉了旧的主语的性别信息，并且添加了新的信息。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-4.png"></p><p align = 'center'>图1.4</p><p>$C_{t}&#x3D;f_{t} * C_{t-1}+i_{t} * \tilde{C}_{t} \tag{1.4}$</p><p>最后一步，需要决定最终的输出。首先建立一个Sigmoid层的输出门，来决定我们将输出元胞的哪些部分。然后将元胞状态通过tanh之后（使得输出值在-1到1之间），与输出门相乘，这样只会输出我们想输出的部分。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-5.png"></p><p align = 'center'>图1.5</p><p>$o_{t}&#x3D;\sigma\left(W_{o}\left[h_{t-1}, x_{t}\right]+b_{o}\right) \tag{1.5}$</p><p>$h_{t}&#x3D;o_{t} * \tanh \left(C_{t}\right) \tag{1.6}$</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>基于RNN的模型已经被广泛应用于语言建模，机器翻译，语音识别和图像字幕等类似的生成任务中。<strong>RNNs最显著的能力是获取时间序列中的重要特征</strong>。(查阅资料知，时序数据是同一种现象在不同时间上的相继观察值排列而成的一组数字值序列，其时间轴上的采样值通常又被称为特征。一般情况下，对时序的特征提取是在分类前对数据时间采样值上进行适量的归约，以达到减少数据量同时提高分类准确率。而RNNs对于时序重要特征的提取十分方便。)</p><p>在生成好的RNNs模型中，来自前一时间步的单词被迭代到下一个时间步，但是，由于训练期间只有训练数据被模型看到，而且在优化过程中可能出现采样过程中的偏移，这会导致生成的句子在语法上有误。</p><p>论文提出的<strong>问题是通过GANs中的对抗训练策略是否会应用于文本的生成，抑或是改进文本的生成</strong>。作者研究了生成器和鉴别器的不同结构，并且最终会<strong>根据生成的文本来评估训练的得到的模型</strong>。</p><h3 id="需要做的工作"><a href="#需要做的工作" class="headerlink" title="需要做的工作"></a>需要做的工作</h3><p>GANs相比较其他深度生成模型具有一些优势，例如，与玻尔兹曼机（简称BM，是一种随机递归神经网络，其样本分布遵循玻尔兹曼分布。它由二值神经元构成，每个神经元只取0或1两种状态，1表示接通，0表示断开。）和非线性独立分量分析对比，GANs对生成器功能的限制较少，它不需要马尔科夫链。还有，变分自动编码器对模型的假设较弱，而GANs被设计为无偏的，最起码在视觉领域它生成的样本质量更好。</p><p>基于RNNs的语言模型可以获得长期的依赖关系。 使用门控循环单元（GRUs）作为发生器和鉴别器来训练GANs，与vanilla RNNs相比。由于图像数据是一堆像素的乘积，而文本生成本质上是离散的，因为文本是由一系列字词标点组成，这使得来自鉴别器的梯度难以反向传播到生成器。</p><p>现在提出了一种使用对抗目标训练RNNs的技术。对抗目标具有正则化效应，并且有助于RNNs训练的收敛。</p><p>SeqGANs将数据生成器建模为强化学习中的随机策略，奖励信号来自在完整序列上判断的鉴别器，并使用蒙特卡洛搜索传递到中间状态步骤。WGANs提供了严格的理论分析并且通过使用EM距离来提高GANs的表现。训练WGANs的优点是不需要对网络结构仔细设计的要求。我们的目标就是平衡生成器和鉴别器两者，防止他们一个压制另一个。</p><h3 id="具体方法"><a href="#具体方法" class="headerlink" title="具体方法"></a>具体方法</h3><h4 id="训练设置"><a href="#训练设置" class="headerlink" title="训练设置"></a>训练设置</h4><p>主要使用GRUs作为构建块，并使用vanilla RNNs作为比较。GRUs在计算上比LSTMs便宜，但在对序列建模中具有相当的性能。</p><p><strong>更新门</strong>：</p><p>$z_{t}&#x3D;\sigma\left(W_{t} x_{t}+U_{z} h_{t-1}\right) \tag{1.7}$</p><p><strong>重置门</strong>：</p><p>$r_{t}&#x3D;\sigma\left(W_{r} x_{t}+U_{r} h_{t-1}\right) \tag{1.8}$</p><p><strong>新记忆</strong>：</p><p>$\tilde{h}<em>{t}&#x3D;\tanh \left(r</em>{t} \circ U h_{t-1}+W x_{t}\right) \tag{1.9}$</p><p><strong>隐藏状态</strong>：</p><p>$h_{t}&#x3D;\left(1-z_{t}\right) \circ \tilde{h}<em>{t}+z</em>{t} \circ h_{t-1} \tag{2.0}$</p><p>在循环模型的每个时间步，网络从输入序列中取出$x_{t}$，并且从先前时间步的输出序列中取出$y_{t}$，然后更新隐藏态$h_{t}$作为之前隐藏态$h_{t-1}$以及$(x_{t},y_{t})$对的函数。然后计算一个以前面元素为先验条件的下一个元素的概率分布。通过在隐藏状态之上添加softmax层来生成离散输出。输出序列$Y$由生成器通过一个根据分布$P_{\theta_{g}}(y \mid x)$的输入序列$X$生成。</p><p>添加一个总结函数$B\left(x, y, \theta_{g}\right)$在生成器和输入嵌入的隐藏状态之上，并且该函数的输出是鉴别器的输入。</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-6.png"></p><p align = 'center'>图1.6 G和D都为RNNs</p><p>上图的是一个生成器和鉴别器的结构都使用RNNs的GANs。$H$代表隐藏层。G中的$b$代表在隐藏状态上$B$的输出。而D中的$b$代表在$x$上的$B$和来自训练的$y$的输出。</p><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><p>当生成器的训练损耗低于一个明确的数值时，生成器的训练暂停，鉴别器的训练开始。反之，当鉴别器的训练损耗低于一个明确的值时，鉴别器的训练停止，生成器的训练开始。这一过程不断重复直到一批具有明确数量的时间戳到达。</p><p>在不同的实验背景下，生成器和鉴别器既可以由GRUs组成，也可以由RNNs组成。生成器和鉴别器拥有可比性的大小规模。鉴别器在隐藏层之顶有一个充分连接层，还有一个针对输出概率的sigmoid层。两者都通过<strong>Adam优化</strong>（Adam是一种可以替代传统随机梯度下降过程的一阶优化算法，它能基于训练数据迭代地更新神经网络权重。）以小批次随机梯度下降来训练。这些工作都在TensorFlow下完成。</p><h4 id="具体的实验"><a href="#具体的实验" class="headerlink" title="具体的实验"></a>具体的实验</h4><h5 id="有关数据集"><a href="#有关数据集" class="headerlink" title="有关数据集"></a>有关数据集</h5><p>预备的数据集包含2万到3万用来训练的单词，还有5万用来测试的单词。在数据集被分离前句子被随意混杂在一起。模型是单词-标准的模型。在预处理阶段，各种各样的标记被清除。</p><h5 id="超参数调整"><a href="#超参数调整" class="headerlink" title="超参数调整"></a>超参数调整</h5><p>如果G和D采用的是GRUs或者RNNs，那么这样的组合有4中情况：</p><table><thead><tr><th align="center">生成器</th><th align="center">结构</th><th align="center">判别器</th><th align="center">结构</th></tr></thead><tbody><tr><td align="center">G</td><td align="center">GRUs</td><td align="center">D</td><td align="center">GRUs</td></tr><tr><td align="center">G</td><td align="center">GRUs</td><td align="center">D</td><td align="center">RNNs</td></tr><tr><td align="center">G</td><td align="center">RNNs</td><td align="center">D</td><td align="center">RNNs</td></tr><tr><td align="center">G</td><td align="center">RNNs</td><td align="center">D</td><td align="center">GRUs</td></tr></tbody></table><p>如果加上不同的隐藏层的总层数或者总词汇大小，则类似的组合数会更多。可以从论文的Table1中看到这一结果。</p><p><strong>采用GRUs的结构总体上比采用RNNs的结构要表现得更好，而来自GANs的生成内容总体上比没有对抗训练表现得更好。在大批量的训练数据下，通过GANs方法的生成文本更加结构化。而如果隐藏层数非常少，那么这一现象表现得就不明显了。</strong></p><p>设定循环模型的层数固定为2.，batch size为50，序列长度为30。学习率开始时为0.02，并且以90%的衰减率不断减小。Adam策略决定了合适的学习率。生成器的损耗低于0.5时停止训练，而鉴别器的损耗低于0.3时就停止训练。所有的训练终止于50次epochs后。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-7.png"></p><p align = 'center'>图1.7</p><p>可以看到，有监督生成损失随着迭代次数的不断增加逐渐变小，个人猜测20000次以后趋于0.</p><p><img src="/images/Text_Generation_using_Generative_Adversarial_Training/pic1-8.png"></p><p align = 'center'>图1.8 生成器和鉴别器loss随迭代次数增长的变化</p><p>这是GANs中生成器和鉴别器随迭代次数增长的变化。可以看到，监督模型的训练接近收敛，不像我之前看到的第一幅图那样曲线呈下坡的样子。 GANs中鉴别器和发生器的损耗曲线由于损耗限幅而不太平滑。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这个项目中生成器和鉴别器都是循环的模型，并且生成器被一个通过监督学习训练过的模型初始化。通过GANs产生的文本具有合理的语法和逻辑性，这比没有对抗训练的情况要表现得好。</p><p>当前的训练集仍然很小对比生成文本来说，并且可以添加更多的超参数，最后，强化学习和WGANs可以被进一步研究以用于生成文本。</p>]]></content>
    
    
    <categories>
      
      <category>文本生成</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GANs</tag>
      
      <tag>零和博弈</tag>
      
      <tag>LSTMs</tag>
      
      <tag>GRUs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Skip-gram模型之训练理解</title>
    <link href="/2018/01/18/skip-gram-model/"/>
    <url>/2018/01/18/skip-gram-model/</url>
    
    <content type="html"><![CDATA[<p><strong>Skip-gram模型的训练步骤：</strong></p><p>训练样本的形式是（input word,output word），其中output word 是input word 的上下文。首先进行采样，剔除停用词等噪声因素。</p><span id="more"></span><ol><li><strong>首先要清洗数据</strong>。删除任何标点、数字，并将医疗文本拆分为单个单词。通过创建一个单词到int字典来将每个单词映射到int。</li><li>进行<strong>抽样</strong>，剔除高频的停用词来减少模型的噪音，并加速训练。通过以下公式来计算每个单词被剔除的概率大小：</li></ol><p>$P\left(w_{i}\right)&#x3D;1-\sqrt{\frac{t}{f\left(w_{i}\right)}} \tag{1.1}$</p><p>​其中，$f(w_{i})$代表单词$w_{i}$出现的频次，$t$代表阈值，介于1e-3到1e-5之间。</p><p>​通过计算每一个单词被删除的概率，并且基于概率进行采样，得到采样过的单词列表。</p><ol start="3"><li><p>设定<em>skip_window</em> &#x3D; 2，对于句子”He has been a cancer patient for about two months”。那么单词for的上下文就是[cancer, patient, about, two]。如果设定<em>batch_size</em> &#x3D; 1，则一个batch中包含4个训练样本，分别是[for, cancer], [for, patient], [for, about], [for, two]。</p><p>首先定义一个函数，它接收一个单词的索引号，然后根据这个索引号去查找单词表中对应的上下文。然后根据这些上下文构建<em>batch</em>。</p></li><li><p><strong>构建模型</strong>，采用负采样方式进行权重更新。通过以下公式得到每个单词被选为“negative words”的概率：</p></li></ol><p>$p\left(w_{i}\right)&#x3D;\frac{f\left(w_{i}\right)^{3 &#x2F; 4}}{\sum_{j&#x3D;0}^{n}\left(f\left(w_{j}\right)^{3 &#x2F; 4}\right)} \tag{1.2}$</p><p>​对于输入层到隐层的权重矩阵，设置<em>embeding_size</em>为300。最后Softmax的维度为词汇表大小乘以    <em>embedding_size</em>。</p><ol start="5"><li><strong>训练结束后保存模型</strong>。</li></ol>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>语言模型</tag>
      
      <tag>skip-gram</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Q学习算法探究及迷宫应用</title>
    <link href="/2017/12/25/q-xuexi-migong/"/>
    <url>/2017/12/25/q-xuexi-migong/</url>
    
    <content type="html"><![CDATA[<h3 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a><strong>摘要：</strong></h3><p>强化学习是一种不同于监督学习和无监督学习的学习技术，它将学习看成一个试探评估的过程。一般来说，一个智能体感知环境状态，并且采取某个action作用于环境，环境接受到这个action后再给出一个reward反馈给学习系统，智能体根据reward再判断下一个动作，如此进行下去。</p><p>Q-learning是强化学习的主要算法，它属于无模型的学习算法。它在博弈论，围棋，国际象棋等方面应用较广。</p><p>本文将首先介绍Q-learning算法的具体步骤，最后通过一个绵羊走迷宫的小例子来更直观地理解该算法,并且给出实现的代码。</p><p><strong>关键词：</strong> 强化学习； 无监督学习； Q-learning； 走迷宫</p><span id="more"></span><h4 id="1-Q-learning算法介绍"><a href="#1-Q-learning算法介绍" class="headerlink" title="1.  Q-learning算法介绍"></a><strong>1.  Q-learning算法介绍</strong></h4><p>强化学习领域一个最重要的突破就是一种叫做Q-learning的off-policy TD控制方法（SARSA方法是on-policy TD控制方法），它是由Watkins于1989年提出。它的最简单的形式，例如单步的Q-learning，被定义为如下：</p><p>$Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{i}\right)+\alpha\left[R_{t+1}+\gamma \max_{a} Q\left(S_{t+1}, a\right)-Q\left(S_{t}, A_{t}\right)\right] \tag{1.1}$</p><p>有的时候也被简写为(本篇后面的例子以这个公式为准)：</p><p>$Q(s, a)&#x3D;R(s, a)+\gamma \max _{a^{\prime}}\left\lbrace Q\left(s^{\prime}, a^{\prime} \right)\right \rbrace \tag{1.2}$</p><p>Q-Learning算法下，目标是达到目标状态(Goal State)并获取最高收益，一旦到达目标状态，最终收益保持不变。因此，目标状态又称之为吸收态。</p><p>Q-Learning算法下的agent，不知道整体的环境，知道当前状态下可以选择哪些动作。</p><p>通常，我们需要构建一个即时奖励矩阵<em>R</em>，用于表示从状态<em>s</em>到下一个状态<em>s’</em></p><p>的动作奖励值。由即时奖励矩阵<em>R</em>计算得出指导agent行动的<em>Q</em>矩阵。Q矩阵是agent的大脑。</p><p>初始时，Q矩阵元素全部初始化为0，表示当前的agent大脑一片空白，什么也不知道。具体算法步骤见下文：</p><p>任意初始化 $Q(s,a)$</p><p><em><strong>Repeat</strong></em>（对每个情节）：</p><p style="text-indent:4em">初始化 *s*</p><p style="text-indent:4em">***Repeat***（对情节的每一步）：</p><p style="text-indent:6em">用源自*Q*中的策略（例如$\varepsilon$ -greedy）在*s*中选择 *a*</p><p>​<p style="text-indent:6em">采用动作 <em>a</em>，观察<em>r</em>，<em>s’</em></p></p><p style="text-indent:6em">$Q(s, a)=R(s, a)+\gamma \max \lbrace Q(s^{\prime}, a^{\prime})\rbrace$</p><p>​<p style="text-indent:4em">$s \leftarrow s^{\prime}$</p></p><p><em><strong>Until</strong></em> <em>s</em>是终止状态</p><h5 id="具体步骤："><a href="#具体步骤：" class="headerlink" title="具体步骤："></a>具体步骤：</h5><ol><li>初始化Q-table矩阵</li><li>选择起始状态<em>s</em></li><li>选择当前状态<em>s</em>下的一个可能动作<em>a</em></li><li>选择动作<em>a​</em>后转移到下一个状态<em>s’</em></li><li>使用Bellman Equation（贝尔曼方程），更新Q-table</li><li>将下一个状态作为当前state，直到达到目标状态，一个episode结束</li><li>迭代尽可能无限多次episode，就可以得到最终收敛的Q矩阵了。</li></ol><p>Q-learning的核心是Q-table。Q-table的行和列分别表示state和action的值，Q-table的值 $Q(s,a)$衡量当前state采取action到底有多好。</p><h4 id="2-绵羊走迷宫"><a href="#2-绵羊走迷宫" class="headerlink" title="2.  绵羊走迷宫"></a><strong>2.  绵羊走迷宫</strong></h4><h5 id="2-1-初始条件"><a href="#2-1-初始条件" class="headerlink" title="2.1  初始条件"></a><strong>2.1  初始条件</strong></h5><p>这个例子描述了一个利用无监督训练学习未知环境的agent。现在假设一个迷宫有5个房间，房间之间通过门相连，将这五个房间按照从0至4进行编号，且迷宫的外围是一个大的房间（里面是草地），编号为5。因绵羊要吃草，设定5号房间为绵羊的目标房间。房间结构如下：</p><p><img src="/images/Q_learning/pic2_1.png"></p><p align = 'center'>图2.1 房间结构​</p><p>现在通过一个图来表示，用房间来表示节点，如果两个房间有门相连，那么两个节点之间对应一条边。如下图所示。</p><p><img src="/images/Q_learning/pic2_2.png"></p><p align = 'center'>图2.2 用直观图表示房间结构</p><p>接下来先将绵羊放在迷宫中的任意一个房间，然后从该房间开始走到目标房间（即5号房间）。接着为每一扇门（即对应的边）设定一个奖赏（reward）值。直接连接到5号房间的奖赏值为100，其他门的奖赏值为0。然后我们可以在每个箭头上表注权重，这个权重就是奖赏值。</p><p>值得留意的是5号房间有一个指向其本身的箭头，奖赏值为100，其他所有指向5号房间的奖赏值也为100。我们这个例子的目标是使绵羊达到奖赏值最大的状态，故而绵羊到达5号房间后将一直停在那里。</p><p>在这个例子中，我们将一个房间对应于一种<strong>状态</strong>，将绵羊从一个房间走到另外一个房间，即从一个状态达到另外一个状态称为一个<strong>行为。</strong></p><p>比如绵羊现在处于状态2，它可以转到状态0，但是不能转到状态1。</p><p>因此，同样地，我们有：</p><p>从状态0，只能转到状态4；从状态1，可以转到状态3或者状态5；从状态3，可以转到状态1和4，也可以转到状态2；从状态4，可以转到状态0,5或者3。</p><p>上面的内容都是这个实例的初始条件以及需要做的一些简要工作。接下来就是要将Q-learning算法应用于这个实例，我们将一步一步迭代几个episode。</p><h5 id="2-2-算法应用"><a href="#2-2-算法应用" class="headerlink" title="2.2 算法应用"></a><strong>2.2 算法应用</strong></h5><p>先令学习参数 $γ &#x3D; 0.8$，初始state为1号房间，如何将Q初始化为一个零矩阵。</p><p><img src="/images/Q_learning/pic2_3.png"></p><p align = 'center'>图2.3 初始化Q为一个零矩阵</p><p><img src="/images/Q_learning/pic2_4.png"></p><p align = 'center'>图2.4  奖赏矩阵</p><p>注意到矩阵R的第二行（state1），它有两个非负值，也就是说，状态1的下一步动作有两种选择：转向状态3或者状态5。此时我们选择状态5。假象绵羊位于状态5以后，观察R的第六行，它有三种可能的行为选择：转向状态1或4或5。由第一节的公式：</p><p>$Q(1,5)&#x3D;R(1,5)+0.8 * \max \lbrace Q(5,1), Q(5,4), Q(5,5) \rbrace &#x3D; 100 \tag{1.3}$</p><p>现在状态5变成了当前状态，而且达到了目标状态，完成了一次episode，矩阵Q也相应地更新了！</p><p><img src="/images/Q_learning/pic2_5.png"></p><p align = 'center'>图2.5  一次episode后的Q</p><p>接下来选取3为初始状态，它有转向1或2或4的三种动作选择。我们随机地选择转向状态1。而状态1有可能转向状态3或者5。由第一节公式：</p><p>$Q(3,1)&#x3D;R(3,1)+0.8 * \max \lbrace Q(1,3), Q(1,5)\rbrace &#x3D;80 \tag{1.4}$</p><p>同样地，刷新Q(3,1)。</p><p><img src="/images/Q_learning/pic2_6.png"></p><p align = 'center'>图2.6  刷新 Q(1,3)</p><p>由于状态1还不是目标状态，因此第二次episode还没有结束。现在在状态1，有两种动作选择：转向3或5。假定我们运气好，选择了状态5。由前面的分析，我们有：$Q(1,5) &#x3D; 100$。刷新矩阵Q，但是Q没有发生变化。第二次episode结束啦！</p><p>基于我们分析的两个episode过程的经验，还可以继续执行更多的episode。最终Q将收敛成如下一个矩阵：</p><p><img src="/images/Q_learning/pic2_7.png"></p><p align = 'center'>图2.7  最终的Q</p><p>最后对Q进行规范化，每个非零元素除以Q中最大的元素（这里省略了百分号）。</p><p><img src="/images/Q_learning/pic2_8.png"></p><p align = 'center'>图2.8  规范化后的Q</p><p>我们可以更改箭头的权重得到我们最终想要的图了：</p><p><img src="/images/Q_learning/pic2_9.png"></p><p align = 'center'>图2.9 最终得到的路径图</p><p>如果以3号房间为初始状态，根据Q表，reward最大的路径是3-﹥1-﹥5或者3-﹥4-﹥5，总的reward都为100。</p><p>总结一下，这个例子是Q-learning算法的简单应用。事实上，实际中的情况要更加复杂，例如可能是两个，三个甚至多个绵羊。本例中我们简化了奖赏矩阵R，实际上那些奖赏设为0的奖赏可以为其他大于0的数，为了方便计算，故而将它们设为0。</p><h5 id="2-3-代码实现"><a href="#2-3-代码实现" class="headerlink" title="2.3 代码实现"></a><strong>2.3 代码实现</strong></h5><p><strong>2.3.1 首先训练数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 学习率</span><br>rate = <span class="hljs-number">0.8</span><br><br><span class="hljs-comment"># 初始化Q矩阵为零矩阵并初始化奖赏矩阵R</span><br>q = np.zeros((<span class="hljs-number">6</span>, <span class="hljs-number">6</span>))<br>q = np.matrix(q)<br><br>r = np.array([[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">100</span>], <br>[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], <br>[<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">100</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">100</span>]])<br>r = np.matrix(r)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br><span class="hljs-comment"># 随机选取一个初始状态</span><br>state = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>)<br><span class="hljs-comment"># state不能为目标状态</span><br><span class="hljs-keyword">while</span> state != <span class="hljs-number">5</span>:<br><span class="hljs-comment"># 选取r表中第state行非负的值</span><br>r_pos_action = []<br><span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>            <span class="hljs-keyword">if</span> r[state, action] &gt;= <span class="hljs-number">0</span>:<br>next_state = r_pos_action[random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(r_pos_action)-<span class="hljs-number">1</span>)]<br>q[state, next_state] = r[state, next_state] + rate*q[next_state].<span class="hljs-built_in">max</span>()<br>state = next_state<br><br><span class="hljs-built_in">print</span>(q)<br></code></pre></td></tr></table></figure><p><strong>下图是训练好的<em>Q</em>表（最终<em>Q</em>表收敛）</strong></p><p><img src="/images/Q_learning/pic2_11.png"></p><p align = 'center'>图2.10</p><p><strong>2.3.2 再根据<em>Q</em>表进行路径选择</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第&#123;&#125;次验证&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br><br>state = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;绵羊处于状态&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(state))<br>count = <span class="hljs-number">0</span><br><span class="hljs-keyword">while</span> state != <span class="hljs-number">5</span>:<br><span class="hljs-keyword">if</span> count &gt; <span class="hljs-number">20</span>:<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;fail&#x27;</span>)<br><span class="hljs-keyword">break</span><br><span class="hljs-comment"># 选择最大的q_max</span><br>q_max = q[state].<span class="hljs-built_in">max</span>()<br><br>q_max_action = []<br><span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br><span class="hljs-keyword">if</span> q[state, action] == q_max:<br>q_max_action.append(action)<br><br>next_state = q_max_action[random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(q_max_action) - <span class="hljs-number">1</span>)]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;the sheep goes to &quot;</span> + <span class="hljs-built_in">str</span>(next_state) + <span class="hljs-string">&#x27;.&#x27;</span>)<br>state = next_state<br>count += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>2.3.3 选择后的结果</strong></p><p><img src="/images/Q_learning/pic2_13.png"></p><p align = 'center'>图2.11</p><h4 id="3-总结与反思"><a href="#3-总结与反思" class="headerlink" title="3.  总结与反思"></a><strong>3.  总结与反思</strong></h4><p>本篇小论文首先简单介绍了Q-learning算法，再通过一个小例子实现了该算法的简单应用。我们通过1000多次训练数据使得Q表收敛，接着再验证我们的训练结果。事实上，Q-learning算法是一种off-policy TD 控制算法，与之相对的是Sarsa算法，一种on-policy TD控制算法，它是基于每一步一个总结，探索时较为“保守”，与之相对的则是Q-learning较为“勇敢”。</p><p>但是，Q-learning也存在着学习时间过长、收敛速度慢的缺陷的特征。但是可以通过从环境中提取特征，借助人的经验和问题的背景知识可以很好的设计启发函数并融入到强化学习中，提高算法的学习效率，加快算法的收敛，可以改进智能体从环境中学习知识的能力，最后再进行仿真验证即可。</p><h4 id="4-相关应用"><a href="#4-相关应用" class="headerlink" title="4.  相关应用"></a><strong>4.  相关应用</strong></h4><p>近年来，该算法应用也较为广泛，主要是基于博弈论方面的，例如：围棋，国际象棋等。比方说，我们可以在上下文老虎机问题中利用Q函数学习过的代理预估长期在特定行为的值。</p><p>Q-Learning算法从90年代被提出至今，它已经历了一系列重大的改进，Q学习可被应用于更加多变的动态场景中。例如与神经网络的结合，Deepmind的深度Q网络的一个主要示例，就是用于学习直接从像素中进行几十种不同的ATARI游戏，像这里仅用一个查找表根本不可能实现的壮举。为了实现这个目标，他们用到了一个由Deep Neural Network(DNN)网络控制的代理。通过神经网络，它可以学习将广义Q函数应用于完全不可见的状态，例如显示器上少见的像素组合。</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>强化学习</tag>
      
      <tag>Q学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
